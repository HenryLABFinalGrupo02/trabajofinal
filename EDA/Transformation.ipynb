{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOqN8Mzs++ICHhOn3NNLenq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kLuZucOHpMp0","executionInfo":{"status":"ok","timestamp":1668605772860,"user_tz":180,"elapsed":21092,"user":{"displayName":"Thiago Ferster","userId":"05395617784714591236"}},"outputId":"094f3639-433a-4d93-831a-6cbed1bf2938"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Conectamos con el google drive \n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# Instalamos las dependencias de nuestro entorno de trabajo \n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","!wget -q https://apache.osuosl.org/spark/spark-3.1.3/spark-3.1.3-bin-hadoop2.7.tgz\n","!tar xf spark-3.1.3-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","!pip install koalas"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-je98hd0qB4c","executionInfo":{"status":"ok","timestamp":1668605901511,"user_tz":180,"elapsed":82808,"user":{"displayName":"Thiago Ferster","userId":"05395617784714591236"}},"outputId":"29cae451-1850-4ba6-98f9-dd314b173576"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting koalas\n","  Downloading koalas-1.8.2-py3-none-any.whl (390 kB)\n","\u001b[K     |████████████████████████████████| 390 kB 4.8 MB/s \n","\u001b[?25hRequirement already satisfied: pyarrow>=0.10 in /usr/local/lib/python3.7/dist-packages (from koalas) (6.0.1)\n","Requirement already satisfied: pandas>=0.23.2 in /usr/local/lib/python3.7/dist-packages (from koalas) (1.3.5)\n","Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.7/dist-packages (from koalas) (1.21.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.2->koalas) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.2->koalas) (2022.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23.2->koalas) (1.15.0)\n","Installing collected packages: koalas\n","Successfully installed koalas-1.8.2\n"]}]},{"cell_type":"code","source":["import os\n","\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.3-bin-hadoop2.7\""],"metadata":{"id":"TnqQj3CbqERE","executionInfo":{"status":"ok","timestamp":1668605901511,"user_tz":180,"elapsed":6,"user":{"displayName":"Thiago Ferster","userId":"05395617784714591236"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import findspark\n","findspark.init()\n","\n","from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"],"metadata":{"id":"JWRTXXnYqGHO","executionInfo":{"status":"ok","timestamp":1668605909420,"user_tz":180,"elapsed":7913,"user":{"displayName":"Thiago Ferster","userId":"05395617784714591236"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import seaborn as sns\n","import matplotlib as plt\n","%matplotlib inline\n","import databricks.koalas as ks\n","from pathlib import Path"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pFdRReXOqHp8","executionInfo":{"status":"ok","timestamp":1668605911271,"user_tz":180,"elapsed":1854,"user":{"displayName":"Thiago Ferster","userId":"05395617784714591236"}},"outputId":"4c1f9e33-1d97-47a2-bb0d-d7727594a711"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. Koalas will set it for you but it does not work if there is a Spark context already launched.\n"]}]}]}