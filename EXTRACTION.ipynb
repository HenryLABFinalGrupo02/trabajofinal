{"cells":[{"cell_type":"code","source":["# Conectamos con el google drive \n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YL4CKQzFZM3i","executionInfo":{"status":"ok","timestamp":1668530698946,"user_tz":360,"elapsed":22381,"user":{"displayName":"Acidminded","userId":"15042557332774087261"}},"outputId":"2a8b7280-bfbc-4d19-bb7a-cfbc0bf572ee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Instalamos las dependencias de nuestro entorno de trabajo \n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","!wget -q https://apache.osuosl.org/spark/spark-3.1.3/spark-3.1.3-bin-hadoop2.7.tgz\n","!tar xf spark-3.1.3-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","! pip install koalas"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"97-HiTKrsgNn","executionInfo":{"status":"ok","timestamp":1668530737674,"user_tz":360,"elapsed":31145,"user":{"displayName":"Acidminded","userId":"15042557332774087261"}},"outputId":"6fa668f3-aba1-402d-e202-000d225e94a7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting koalas\n","  Downloading koalas-1.8.2-py3-none-any.whl (390 kB)\n","\u001b[K     |████████████████████████████████| 390 kB 4.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.7/dist-packages (from koalas) (1.21.6)\n","Requirement already satisfied: pandas>=0.23.2 in /usr/local/lib/python3.7/dist-packages (from koalas) (1.3.5)\n","Requirement already satisfied: pyarrow>=0.10 in /usr/local/lib/python3.7/dist-packages (from koalas) (6.0.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.2->koalas) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.2->koalas) (2022.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23.2->koalas) (1.15.0)\n","Installing collected packages: koalas\n","Successfully installed koalas-1.8.2\n"]}]},{"cell_type":"code","source":["!ls -a"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XSswhzZasi8X","executionInfo":{"status":"ok","timestamp":1668530737935,"user_tz":360,"elapsed":274,"user":{"displayName":"Acidminded","userId":"15042557332774087261"}},"outputId":"f6334421-1fba-4628-a25f-a52419d1bfb4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[".   .config  sample_data\t\tspark-3.1.3-bin-hadoop2.7.tgz\n","..  drive    spark-3.1.3-bin-hadoop2.7\n"]}]},{"cell_type":"code","source":["import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.3-bin-hadoop2.7\""],"metadata":{"id":"m0u649jasnvN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import findspark\n","findspark.init()\n","\n","from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"],"metadata":{"id":"0h5DURjkskr9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import databricks.koalas as ks"],"metadata":{"id":"4Q8oilOuxzVf","executionInfo":{"status":"ok","timestamp":1668530774697,"user_tz":360,"elapsed":678,"user":{"displayName":"Acidminded","userId":"15042557332774087261"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a65bcf70-06c9-47a6-dc20-0e23eef84485"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. Koalas will set it for you but it does not work if there is a Spark context already launched.\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import databricks.koalas as ks"],"metadata":{"id":"eO8slMhLx5Rd"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D9y3095Zdbdb"},"outputs":[],"source":["review = spark.read.load(\"/content/drive/MyDrive/HENRY_TRABAJO_GRUPAL/Dataset_Yelp/review.json\", format=\"json\")\n","user = spark.read.load(\"/content/drive/MyDrive/HENRY_TRABAJO_GRUPAL/Dataset_Yelp/user.json\", format=\"json\")\n","business = spark.read.load(\"/content/drive/MyDrive/HENRY_TRABAJO_GRUPAL/Dataset_Yelp/business.json\", format=\"json\")\n","chechin = spark.read.load(\"/content/drive/MyDrive/HENRY_TRABAJO_GRUPAL/Dataset_Yelp/checkin.json\", format=\"json\")\n","tip= spark.read.load('/content/drive/MyDrive/HENRY_TRABAJO_GRUPAL/Dataset_Yelp/tip.json', format=\"json\")"]},{"cell_type":"code","source":["k_review = review.to_koalas() # David\n","k_user = user.to_koalas() # Maico\n","k_business = business.to_koalas() # Julieta\n","k_chechin = chechin.to_koalas() # Thiago\n","k_tip = tip.to_koalas() # Lila"],"metadata":{"id":"qK_fUJJj2OKh"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3.8.10 64-bit (microsoft store)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"cde544f8739533cebef63bf12999052a10729ddf7c121822866b350ee78941c5"}}},"nbformat":4,"nbformat_minor":0}