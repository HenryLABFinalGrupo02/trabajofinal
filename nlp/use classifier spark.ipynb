{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kl6fW8Fkf3vN"
      },
      "source": [
        "## Text Classification with ClassifierDL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUAgkEOqOnJh"
      },
      "source": [
        "**Relevant blogpost:** https://towardsdatascience.com/text-classification-in-spark-nlp-with-bert-and-universal-sentence-encoders-e644d618ca32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "Get:1 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Get:2 https://deb.nodesource.com/node_16.x focal InRelease [4583 B]            \u001b[0m\u001b[33m\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal InRelease [265 kB]                \u001b[0m\u001b[33m\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Get:6 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease [18.1 kB]\n",
            "Get:7 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [966 kB]\n",
            "Get:8 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2313 kB]\n",
            "Get:9 https://deb.nodesource.com/node_16.x focal/main amd64 Packages [774 B]   \u001b[0m\n",
            "Get:10 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [1712 kB]\n",
            "Get:11 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [27.5 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal/universe amd64 Packages [11.3 MB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu focal/restricted amd64 Packages [33.4 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu focal/multiverse amd64 Packages [177 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu focal/main amd64 Packages [1275 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [30.2 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [1829 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1268 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [2786 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu focal-backports/universe amd64 Packages [27.4 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu focal-backports/main amd64 Packages [55.2 kB]\n",
            "Get:22 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 Packages [29.5 kB]\n",
            "Fetched 24.5 MB in 1s (18.6 MB/s)[33m                        \u001b[0m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "103 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  ca-certificates-java fonts-dejavu-extra java-common libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libfontenc1 libice-dev libnspr4 libnss3 libpcsclite1\n",
            "  libpthread-stubs0-dev libsm-dev libx11-dev libxau-dev libxcb1-dev\n",
            "  libxdmcp-dev libxkbfile1 libxmuu1 libxt-dev libxtst6 libxxf86dga1\n",
            "  openjdk-17-jdk-headless openjdk-17-jre openjdk-17-jre-headless x11-utils\n",
            "  x11proto-core-dev x11proto-dev xorg-sgml-doctools xtrans-dev\n",
            "Suggested packages:\n",
            "  default-jre libice-doc pcscd libsm-doc libx11-doc libxcb-doc libxt-doc\n",
            "  openjdk-17-demo openjdk-17-source visualvm libnss-mdns fonts-ipafont-gothic\n",
            "  fonts-ipafont-mincho fonts-wqy-microhei | fonts-wqy-zenhei fonts-indic\n",
            "  mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  ca-certificates-java fonts-dejavu-extra java-common libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libfontenc1 libice-dev libnspr4 libnss3 libpcsclite1\n",
            "  libpthread-stubs0-dev libsm-dev libx11-dev libxau-dev libxcb1-dev\n",
            "  libxdmcp-dev libxkbfile1 libxmuu1 libxt-dev libxtst6 libxxf86dga1\n",
            "  openjdk-17-jdk openjdk-17-jdk-headless openjdk-17-jre\n",
            "  openjdk-17-jre-headless x11-utils x11proto-core-dev x11proto-dev\n",
            "  xorg-sgml-doctools xtrans-dev\n",
            "0 upgraded, 30 newly installed, 0 to remove and 103 not upgraded.\n",
            "Need to get 292 MB of archives.\n",
            "After this operation, 466 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/main amd64 libxmuu1 amd64 2:1.1.3-0ubuntu1 [9728 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/main amd64 java-common all 0.72 [6816 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/main amd64 libnspr4 amd64 2:4.25-1 [107 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libnss3 amd64 2:3.49.1-1ubuntu1.8 [1256 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu focal/main amd64 libpcsclite1 amd64 1.8.26-3 [22.0 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 openjdk-17-jre-headless amd64 17.0.5+8-2ubuntu1~20.04 [43.6 MB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal/main amd64 ca-certificates-java all 20190405ubuntu1 [12.2 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu focal/main amd64 fonts-dejavu-extra all 2.37-1 [1953 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu focal/main amd64 libfontenc1 amd64 1:1.1.4-0ubuntu1 [14.0 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu focal/main amd64 libxkbfile1 amd64 1:1.1.0-1 [65.3 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu focal/main amd64 libxtst6 amd64 2:1.2.3-1 [12.8 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu1 [12.0 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu focal/main amd64 x11-utils amd64 7.7+5 [199 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu focal/main amd64 libatk-wrapper-java all 0.37.1-1 [53.0 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu focal/main amd64 libatk-wrapper-java-jni amd64 0.37.1-1 [45.1 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu focal/main amd64 xorg-sgml-doctools all 1:1.11-1 [12.9 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu focal/main amd64 x11proto-dev all 2019.2-1ubuntu1 [594 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu focal/main amd64 x11proto-core-dev all 2019.2-1ubuntu1 [2620 B]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu focal/main amd64 libice-dev amd64 2:1.0.10-0ubuntu1 [47.8 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu focal/main amd64 libpthread-stubs0-dev amd64 0.4-1 [5384 B]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu focal/main amd64 libsm-dev amd64 2:1.2.3-1 [17.0 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu focal/main amd64 libxau-dev amd64 1:1.0.9-0ubuntu1 [9552 B]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu focal/main amd64 libxdmcp-dev amd64 1:1.1.3-0ubuntu1 [25.3 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu focal/main amd64 xtrans-dev all 1.4.0-1 [68.9 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu focal/main amd64 libxcb1-dev amd64 1.14-2 [80.5 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libx11-dev amd64 2:1.6.9-2ubuntu1.2 [647 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu focal/main amd64 libxt-dev amd64 1:1.1.5-1 [395 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 openjdk-17-jre amd64 17.0.5+8-2ubuntu1~20.04 [166 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 openjdk-17-jdk-headless amd64 17.0.5+8-2ubuntu1~20.04 [243 MB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 openjdk-17-jdk amd64 17.0.5+8-2ubuntu1~20.04 [10.5 kB]\n",
            "Fetched 292 MB in 3s (86.4 MB/s)            \u001b[0m\u001b[33m\n",
            "\n",
            "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package libxmuu1:amd64.\n",
            "(Reading database ... 78556 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libxmuu1_2%3a1.1.3-0ubuntu1_amd64.deb ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8Unpacking libxmuu1:amd64 (2:1.1.3-0ubuntu1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  2%]\u001b[49m\u001b[39m [..........................................................] \u001b8Selecting previously unselected package java-common.\n",
            "Preparing to unpack .../01-java-common_0.72_all.deb ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  2%]\u001b[49m\u001b[39m [#.........................................................] \u001b8Unpacking java-common (0.72) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  3%]\u001b[49m\u001b[39m [#.........................................................] \u001b8Selecting previously unselected package libnspr4:amd64.\n",
            "Preparing to unpack .../02-libnspr4_2%3a4.25-1_amd64.deb ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  4%]\u001b[49m\u001b[39m [##........................................................] \u001b8Unpacking libnspr4:amd64 (2:4.25-1) ...\n",
            "Selecting previously unselected package libnss3:amd64.\n",
            "Preparing to unpack .../03-libnss3_2%3a3.49.1-1ubuntu1.8_amd64.deb ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  6%]\u001b[49m\u001b[39m [###.......................................................] \u001b8Unpacking libnss3:amd64 (2:3.49.1-1ubuntu1.8) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  7%]\u001b[49m\u001b[39m [###.......................................................] \u001b8Selecting previously unselected package libpcsclite1:amd64.\n",
            "Preparing to unpack .../04-libpcsclite1_1.8.26-3_amd64.deb ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  7%]\u001b[49m\u001b[39m [####......................................................] \u001b8Unpacking libpcsclite1:amd64 (1.8.26-3) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  8%]\u001b[49m\u001b[39m [####......................................................] \u001b8Selecting previously unselected package openjdk-17-jre-headless:amd64.\n",
            "Preparing to unpack .../05-openjdk-17-jre-headless_17.0.5+8-2ubuntu1~20.04_amd64.deb ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  9%]\u001b[49m\u001b[39m [#####.....................................................] \u001b8Unpacking openjdk-17-jre-headless:amd64 (17.0.5+8-2ubuntu1~20.04) ...\n",
            "Selecting previously unselected package ca-certificates-java.\n",
            "Preparing to unpack .../06-ca-certificates-java_20190405ubuntu1_all.deb ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 11%]\u001b[49m\u001b[39m [######....................................................] \u001b8Unpacking ca-certificates-java (20190405ubuntu1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 12%]\u001b[49m\u001b[39m [######....................................................] \u001b8Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../07-fonts-dejavu-extra_2.37-1_all.deb ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 12%]\u001b[49m\u001b[39m [#######...................................................] \u001b8Unpacking fonts-dejavu-extra (2.37-1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 13%]\u001b[49m\u001b[39m [#######...................................................] \u001b8Selecting previously unselected package libfontenc1:amd64.\n",
            "Preparing to unpack .../08-libfontenc1_1%3a1.1.4-0ubuntu1_amd64.deb ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 14%]\u001b[49m\u001b[39m [########..................................................] \u001b8Unpacking libfontenc1:amd64 (1:1.1.4-0ubuntu1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../09-libxkbfile1_1%3a1.1.0-1_amd64.deb ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 16%]\u001b[49m\u001b[39m [#########.................................................] \u001b8Unpacking libxkbfile1:amd64 (1:1.1.0-1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 17%]\u001b[49m\u001b[39m [#########.................................................] \u001b8Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../10-libxtst6_2%3a1.2.3-1_amd64.deb ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 17%]\u001b[49m\u001b[39m [##########................................................] \u001b8Unpacking libxtst6:amd64 (2:1.2.3-1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 18%]\u001b[49m\u001b[39m [##########................................................] \u001b8Selecting previously unselected package libxxf86dga1:amd64.\n",
            "Preparing to unpack .../11-libxxf86dga1_2%3a1.1.5-0ubuntu1_amd64.deb ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 19%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu1) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../12-x11-utils_7.7+5_amd64.deb ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 21%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Unpacking x11-utils (7.7+5) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 21%]\u001b[49m\u001b[39m [############..............................................] \u001b8Selecting previously unselected package libatk-wrapper-java.\n",
            "Preparing to unpack .../13-libatk-wrapper-java_0.37.1-1_all.deb ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 22%]\u001b[49m\u001b[39m [############..............................................] \u001b8Unpacking libatk-wrapper-java (0.37.1-1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 23%]\u001b[49m\u001b[39m [#############.............................................] \u001b8Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
            "Preparing to unpack .../14-libatk-wrapper-java-jni_0.37.1-1_amd64.deb ...\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.37.1-1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 25%]\u001b[49m\u001b[39m [##############............................................] \u001b8Selecting previously unselected package xorg-sgml-doctools.\n",
            "Preparing to unpack .../15-xorg-sgml-doctools_1%3a1.11-1_all.deb ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 26%]\u001b[49m\u001b[39m [##############............................................] \u001b8Unpacking xorg-sgml-doctools (1:1.11-1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 26%]\u001b[49m\u001b[39m [###############...........................................] \u001b8Selecting previously unselected package x11proto-dev.\n",
            "Preparing to unpack .../16-x11proto-dev_2019.2-1ubuntu1_all.deb ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 27%]\u001b[49m\u001b[39m [###############...........................................] \u001b8Unpacking x11proto-dev (2019.2-1ubuntu1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 28%]\u001b[49m\u001b[39m [################..........................................] \u001b8Selecting previously unselected package x11proto-core-dev.\n",
            "Preparing to unpack .../17-x11proto-core-dev_2019.2-1ubuntu1_all.deb ...\n",
            "Unpacking x11proto-core-dev (2019.2-1ubuntu1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 30%]\u001b[49m\u001b[39m [#################.........................................] \u001b8Selecting previously unselected package libice-dev:amd64.\n",
            "Preparing to unpack .../18-libice-dev_2%3a1.0.10-0ubuntu1_amd64.deb ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 31%]\u001b[49m\u001b[39m [#################.........................................] \u001b8Unpacking libice-dev:amd64 (2:1.0.10-0ubuntu1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 31%]\u001b[49m\u001b[39m [##################........................................] \u001b8Selecting previously unselected package libpthread-stubs0-dev:amd64.\n",
            "Preparing to unpack .../19-libpthread-stubs0-dev_0.4-1_amd64.deb ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 32%]\u001b[49m\u001b[39m [##################........................................] \u001b8Unpacking libpthread-stubs0-dev:amd64 (0.4-1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 33%]\u001b[49m\u001b[39m [###################.......................................] \u001b8Selecting previously unselected package libsm-dev:amd64.\n",
            "Preparing to unpack .../20-libsm-dev_2%3a1.2.3-1_amd64.deb ...\n",
            "Unpacking libsm-dev:amd64 (2:1.2.3-1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 35%]\u001b[49m\u001b[39m [####################......................................] \u001b8Selecting previously unselected package libxau-dev:amd64.\n",
            "Preparing to unpack .../21-libxau-dev_1%3a1.0.9-0ubuntu1_amd64.deb ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 36%]\u001b[49m\u001b[39m [####################......................................] \u001b8Unpacking libxau-dev:amd64 (1:1.0.9-0ubuntu1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 36%]\u001b[49m\u001b[39m [#####################.....................................] \u001b8Selecting previously unselected package libxdmcp-dev:amd64.\n",
            "Preparing to unpack .../22-libxdmcp-dev_1%3a1.1.3-0ubuntu1_amd64.deb ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 37%]\u001b[49m\u001b[39m [#####################.....................................] \u001b8Unpacking libxdmcp-dev:amd64 (1:1.1.3-0ubuntu1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 38%]\u001b[49m\u001b[39m [######################....................................] \u001b8Selecting previously unselected package xtrans-dev.\n",
            "Preparing to unpack .../23-xtrans-dev_1.4.0-1_all.deb ...\n",
            "Unpacking xtrans-dev (1.4.0-1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 40%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Selecting previously unselected package libxcb1-dev:amd64.\n",
            "Preparing to unpack .../24-libxcb1-dev_1.14-2_amd64.deb ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 40%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Unpacking libxcb1-dev:amd64 (1.14-2) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 41%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Selecting previously unselected package libx11-dev:amd64.\n",
            "Preparing to unpack .../25-libx11-dev_2%3a1.6.9-2ubuntu1.2_amd64.deb ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 42%]\u001b[49m\u001b[39m [########################..................................] \u001b8Unpacking libx11-dev:amd64 (2:1.6.9-2ubuntu1.2) ...\n",
            "Selecting previously unselected package libxt-dev:amd64.\n",
            "Preparing to unpack .../26-libxt-dev_1%3a1.1.5-1_amd64.deb ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 44%]\u001b[49m\u001b[39m [#########################.................................] \u001b8Unpacking libxt-dev:amd64 (1:1.1.5-1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 45%]\u001b[49m\u001b[39m [#########################.................................] \u001b8Selecting previously unselected package openjdk-17-jre:amd64.\n",
            "Preparing to unpack .../27-openjdk-17-jre_17.0.5+8-2ubuntu1~20.04_amd64.deb ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 45%]\u001b[49m\u001b[39m [##########################................................] \u001b8Unpacking openjdk-17-jre:amd64 (17.0.5+8-2ubuntu1~20.04) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 46%]\u001b[49m\u001b[39m [##########################................................] \u001b8Selecting previously unselected package openjdk-17-jdk-headless:amd64.\n",
            "Preparing to unpack .../28-openjdk-17-jdk-headless_17.0.5+8-2ubuntu1~20.04_amd64.deb ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 47%]\u001b[49m\u001b[39m [###########################...............................] \u001b8Unpacking openjdk-17-jdk-headless:amd64 (17.0.5+8-2ubuntu1~20.04) ...\n",
            "Selecting previously unselected package openjdk-17-jdk:amd64.\n",
            "Preparing to unpack .../29-openjdk-17-jdk_17.0.5+8-2ubuntu1~20.04_amd64.deb ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 49%]\u001b[49m\u001b[39m [############################..............................] \u001b8Unpacking openjdk-17-jdk:amd64 (17.0.5+8-2ubuntu1~20.04) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 50%]\u001b[49m\u001b[39m [############################..............................] \u001b8Setting up java-common (0.72) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 50%]\u001b[49m\u001b[39m [#############################.............................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 51%]\u001b[49m\u001b[39m [#############################.............................] \u001b8Setting up libxtst6:amd64 (2:1.2.3-1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 52%]\u001b[49m\u001b[39m [##############################............................] \u001b8Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 54%]\u001b[49m\u001b[39m [###############################...........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 55%]\u001b[49m\u001b[39m [###############################...........................] \u001b8Setting up libpthread-stubs0-dev:amd64 (0.4-1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 55%]\u001b[49m\u001b[39m [################################..........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 56%]\u001b[49m\u001b[39m [################################..........................] \u001b8Setting up xtrans-dev (1.4.0-1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 57%]\u001b[49m\u001b[39m [#################################.........................] \u001b8Setting up libfontenc1:amd64 (1:1.1.4-0ubuntu1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 59%]\u001b[49m\u001b[39m [##################################........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 60%]\u001b[49m\u001b[39m [##################################........................] \u001b8Setting up libnspr4:amd64 (2:4.25-1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 60%]\u001b[49m\u001b[39m [##################################........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 61%]\u001b[49m\u001b[39m [###################################.......................] \u001b8Setting up libpcsclite1:amd64 (1.8.26-3) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 63%]\u001b[49m\u001b[39m [####################################......................] \u001b8Setting up fonts-dejavu-extra (2.37-1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 64%]\u001b[49m\u001b[39m [####################################......................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 64%]\u001b[49m\u001b[39m [#####################################.....................] \u001b8Setting up xorg-sgml-doctools (1:1.11-1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 65%]\u001b[49m\u001b[39m [#####################################.....................] \u001b8Setting up libxkbfile1:amd64 (1:1.1.0-1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 66%]\u001b[49m\u001b[39m [######################################....................] \u001b8Setting up libxmuu1:amd64 (2:1.1.3-0ubuntu1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 68%]\u001b[49m\u001b[39m [#######################################...................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 69%]\u001b[49m\u001b[39m [#######################################...................] \u001b8Setting up libnss3:amd64 (2:3.49.1-1ubuntu1.8) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 69%]\u001b[49m\u001b[39m [########################################..................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 70%]\u001b[49m\u001b[39m [########################################..................] \u001b8Setting up x11-utils (7.7+5) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 71%]\u001b[49m\u001b[39m [#########################################.................] \u001b8Setting up libatk-wrapper-java (0.37.1-1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 73%]\u001b[49m\u001b[39m [##########################################................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 74%]\u001b[49m\u001b[39m [##########################################................] \u001b8Setting up libatk-wrapper-java-jni:amd64 (0.37.1-1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 74%]\u001b[49m\u001b[39m [###########################################...............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 75%]\u001b[49m\u001b[39m [###########################################...............] \u001b8Setting up openjdk-17-jre-headless:amd64 (17.0.5+8-2ubuntu1~20.04) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 76%]\u001b[49m\u001b[39m [############################################..............] \u001b8update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/java to provide /usr/bin/java (java) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jpackage to provide /usr/bin/jpackage (jpackage) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/keytool to provide /usr/bin/keytool (keytool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/rmiregistry to provide /usr/bin/rmiregistry (rmiregistry) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/lib/jexec to provide /usr/bin/jexec (jexec) in auto mode\n",
            "Setting up ca-certificates-java (20190405ubuntu1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 78%]\u001b[49m\u001b[39m [#############################################.............] \u001b8head: cannot open '/etc/ssl/certs/java/cacerts' for reading: No such file or directory\n",
            "Adding debian:Autoridad_de_Certificacion_Firmaprofesional_CIF_A62634068.pem\n",
            "Adding debian:Trustwave_Global_ECC_P256_Certification_Authority.pem\n",
            "Adding debian:GTS_Root_R2.pem\n",
            "Adding debian:Starfield_Root_Certificate_Authority_-_G2.pem\n",
            "Adding debian:Hellenic_Academic_and_Research_Institutions_ECC_RootCA_2015.pem\n",
            "Adding debian:Certigna_Root_CA.pem\n",
            "Adding debian:CA_Disig_Root_R2.pem\n",
            "Adding debian:AC_RAIZ_FNMT-RCM.pem\n",
            "Adding debian:SwissSign_Gold_CA_-_G2.pem\n",
            "Adding debian:emSign_ECC_Root_CA_-_G3.pem\n",
            "Adding debian:GlobalSign_ECC_Root_CA_-_R4.pem\n",
            "Adding debian:NetLock_Arany_=Class_Gold=_Főtanúsítvány.pem\n",
            "Adding debian:certSIGN_ROOT_CA.pem\n",
            "Adding debian:TrustCor_RootCert_CA-1.pem\n",
            "Adding debian:SecureSign_RootCA11.pem\n",
            "Adding debian:Amazon_Root_CA_2.pem\n",
            "Adding debian:GlobalSign_Root_CA_-_R6.pem\n",
            "Adding debian:DigiCert_Trusted_Root_G4.pem\n",
            "Adding debian:Hellenic_Academic_and_Research_Institutions_RootCA_2011.pem\n",
            "Adding debian:GDCA_TrustAUTH_R5_ROOT.pem\n",
            "Adding debian:COMODO_RSA_Certification_Authority.pem\n",
            "Adding debian:D-TRUST_Root_Class_3_CA_2_2009.pem\n",
            "Adding debian:Certigna.pem\n",
            "Adding debian:ACCVRAIZ1.pem\n",
            "Adding debian:QuoVadis_Root_CA_2_G3.pem\n",
            "Adding debian:Certum_Trusted_Network_CA.pem\n",
            "Adding debian:Go_Daddy_Class_2_CA.pem\n",
            "Adding debian:TeliaSonera_Root_CA_v1.pem\n",
            "Adding debian:Network_Solutions_Certificate_Authority.pem\n",
            "Adding debian:Baltimore_CyberTrust_Root.pem\n",
            "Adding debian:DigiCert_Global_Root_G3.pem\n",
            "Adding debian:T-TeleSec_GlobalRoot_Class_2.pem\n",
            "Adding debian:AffirmTrust_Premium_ECC.pem\n",
            "Adding debian:GlobalSign_Root_CA.pem\n",
            "Adding debian:EC-ACC.pem\n",
            "Adding debian:GTS_Root_R1.pem\n",
            "Adding debian:GlobalSign_Root_CA_-_R2.pem\n",
            "Adding debian:Entrust_Root_Certification_Authority.pem\n",
            "Adding debian:emSign_Root_CA_-_C1.pem\n",
            "Adding debian:Cybertrust_Global_Root.pem\n",
            "Adding debian:Secure_Global_CA.pem\n",
            "Adding debian:Amazon_Root_CA_4.pem\n",
            "Adding debian:E-Tugra_Certification_Authority.pem\n",
            "Adding debian:NAVER_Global_Root_Certification_Authority.pem\n",
            "Adding debian:ePKI_Root_Certification_Authority.pem\n",
            "Adding debian:Certum_Trusted_Network_CA_2.pem\n",
            "Adding debian:D-TRUST_Root_Class_3_CA_2_EV_2009.pem\n",
            "Adding debian:QuoVadis_Root_CA_3_G3.pem\n",
            "Adding debian:QuoVadis_Root_CA_2.pem\n",
            "Adding debian:TWCA_Root_Certification_Authority.pem\n",
            "Adding debian:COMODO_Certification_Authority.pem\n",
            "Adding debian:emSign_Root_CA_-_G1.pem\n",
            "Adding debian:AffirmTrust_Commercial.pem\n",
            "Adding debian:Buypass_Class_3_Root_CA.pem\n",
            "Adding debian:QuoVadis_Root_CA_1_G3.pem\n",
            "Adding debian:Entrust_Root_Certification_Authority_-_G2.pem\n",
            "Adding debian:DigiCert_Assured_ID_Root_G2.pem\n",
            "Adding debian:TUBITAK_Kamu_SM_SSL_Kok_Sertifikasi_-_Surum_1.pem\n",
            "Adding debian:USERTrust_RSA_Certification_Authority.pem\n",
            "Adding debian:Go_Daddy_Root_Certificate_Authority_-_G2.pem\n",
            "Adding debian:Security_Communication_Root_CA.pem\n",
            "Adding debian:GTS_Root_R3.pem\n",
            "Adding debian:TrustCor_ECA-1.pem\n",
            "Adding debian:QuoVadis_Root_CA_3.pem\n",
            "Adding debian:OISTE_WISeKey_Global_Root_GB_CA.pem\n",
            "Adding debian:IdenTrust_Public_Sector_Root_CA_1.pem\n",
            "Adding debian:SZAFIR_ROOT_CA2.pem\n",
            "Adding debian:IdenTrust_Commercial_Root_CA_1.pem\n",
            "Adding debian:SSL.com_Root_Certification_Authority_RSA.pem\n",
            "Adding debian:Microsoft_RSA_Root_Certificate_Authority_2017.pem\n",
            "Adding debian:ISRG_Root_X1.pem\n",
            "Adding debian:DigiCert_Assured_ID_Root_CA.pem\n",
            "Adding debian:Buypass_Class_2_Root_CA.pem\n",
            "Adding debian:SSL.com_EV_Root_Certification_Authority_ECC.pem\n",
            "Adding debian:SSL.com_Root_Certification_Authority_ECC.pem\n",
            "Adding debian:e-Szigno_Root_CA_2017.pem\n",
            "Adding debian:GlobalSign_ECC_Root_CA_-_R5.pem\n",
            "Adding debian:SSL.com_EV_Root_Certification_Authority_RSA_R2.pem\n",
            "Adding debian:TrustCor_RootCert_CA-2.pem\n",
            "Adding debian:Microsoft_ECC_Root_Certificate_Authority_2017.pem\n",
            "Adding debian:Staat_der_Nederlanden_EV_Root_CA.pem\n",
            "Adding debian:Actalis_Authentication_Root_CA.pem\n",
            "Adding debian:AffirmTrust_Premium.pem\n",
            "Adding debian:T-TeleSec_GlobalRoot_Class_3.pem\n",
            "Adding debian:Hongkong_Post_Root_CA_1.pem\n",
            "Adding debian:Entrust.net_Premium_2048_Secure_Server_CA.pem\n",
            "Adding debian:Hongkong_Post_Root_CA_3.pem\n",
            "Adding debian:AffirmTrust_Networking.pem\n",
            "Adding debian:Entrust_Root_Certification_Authority_-_G4.pem\n",
            "Adding debian:DigiCert_High_Assurance_EV_Root_CA.pem\n",
            "Adding debian:GlobalSign_Root_CA_-_R3.pem\n",
            "Adding debian:Microsec_e-Szigno_Root_CA_2009.pem\n",
            "Adding debian:USERTrust_ECC_Certification_Authority.pem\n",
            "Adding debian:Hellenic_Academic_and_Research_Institutions_RootCA_2015.pem\n",
            "Adding debian:DigiCert_Global_Root_CA.pem\n",
            "Adding debian:Comodo_AAA_Services_root.pem\n",
            "Adding debian:UCA_Extended_Validation_Root.pem\n",
            "Adding debian:Trustwave_Global_ECC_P384_Certification_Authority.pem\n",
            "Adding debian:Izenpe.com.pem\n",
            "Adding debian:Atos_TrustedRoot_2011.pem\n",
            "Adding debian:Starfield_Services_Root_Certificate_Authority_-_G2.pem\n",
            "Adding debian:XRamp_Global_CA_Root.pem\n",
            "Adding debian:Amazon_Root_CA_1.pem\n",
            "Adding debian:Starfield_Class_2_CA.pem\n",
            "Adding debian:GTS_Root_R4.pem\n",
            "Adding debian:CFCA_EV_ROOT.pem\n",
            "Adding debian:OISTE_WISeKey_Global_Root_GC_CA.pem\n",
            "Adding debian:SecureTrust_CA.pem\n",
            "Adding debian:COMODO_ECC_Certification_Authority.pem\n",
            "Adding debian:emSign_ECC_Root_CA_-_C3.pem\n",
            "Adding debian:DigiCert_Assured_ID_Root_G3.pem\n",
            "Adding debian:certSIGN_Root_CA_G2.pem\n",
            "Adding debian:SwissSign_Silver_CA_-_G2.pem\n",
            "Adding debian:Security_Communication_RootCA2.pem\n",
            "Adding debian:Entrust_Root_Certification_Authority_-_EC1.pem\n",
            "Adding debian:TWCA_Global_Root_CA.pem\n",
            "Adding debian:UCA_Global_G2_Root.pem\n",
            "Adding debian:Trustwave_Global_Certification_Authority.pem\n",
            "Adding debian:Amazon_Root_CA_3.pem\n",
            "Adding debian:DigiCert_Global_Root_G2.pem\n",
            "Adding debian:ANF_Secure_Server_Root_CA.pem\n",
            "Adding debian:GLOBALTRUST_2020.pem\n",
            "Adding debian:GlobalSign_Root_R46.pem\n",
            "Adding debian:AC_RAIZ_FNMT-RCM_SERVIDORES_SEGUROS.pem\n",
            "Adding debian:Certum_EC-384_CA.pem\n",
            "Adding debian:Certum_Trusted_Root_CA.pem\n",
            "Adding debian:GlobalSign_Root_E46.pem\n",
            "done.\n",
            "Setting up openjdk-17-jre:amd64 (17.0.5+8-2ubuntu1~20.04) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 79%]\u001b[49m\u001b[39m [#############################################.............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 79%]\u001b[49m\u001b[39m [##############################################............] \u001b8Setting up openjdk-17-jdk-headless:amd64 (17.0.5+8-2ubuntu1~20.04) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 80%]\u001b[49m\u001b[39m [##############################################............] \u001b8update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jar to provide /usr/bin/jar (jar) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jarsigner to provide /usr/bin/jarsigner (jarsigner) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javac to provide /usr/bin/javac (javac) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javadoc to provide /usr/bin/javadoc (javadoc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javap to provide /usr/bin/javap (javap) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jcmd to provide /usr/bin/jcmd (jcmd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdb to provide /usr/bin/jdb (jdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdeprscan to provide /usr/bin/jdeprscan (jdeprscan) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdeps to provide /usr/bin/jdeps (jdeps) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jfr to provide /usr/bin/jfr (jfr) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jimage to provide /usr/bin/jimage (jimage) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jinfo to provide /usr/bin/jinfo (jinfo) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jlink to provide /usr/bin/jlink (jlink) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jmap to provide /usr/bin/jmap (jmap) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jmod to provide /usr/bin/jmod (jmod) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jps to provide /usr/bin/jps (jps) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jrunscript to provide /usr/bin/jrunscript (jrunscript) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jshell to provide /usr/bin/jshell (jshell) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstack to provide /usr/bin/jstack (jstack) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstat to provide /usr/bin/jstat (jstat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstatd to provide /usr/bin/jstatd (jstatd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/serialver to provide /usr/bin/serialver (serialver) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jhsdb to provide /usr/bin/jhsdb (jhsdb) in auto mode\n",
            "Setting up openjdk-17-jdk:amd64 (17.0.5+8-2ubuntu1~20.04) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 82%]\u001b[49m\u001b[39m [###############################################...........] \u001b8update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 83%]\u001b[49m\u001b[39m [###############################################...........] \u001b8Processing triggers for ca-certificates (20211016~20.04.1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 83%]\u001b[49m\u001b[39m [################################################..........] \u001b8Updating certificates in /etc/ssl/certs...\n",
            "0 added, 0 removed; done.\n",
            "Running hooks in /etc/ca-certificates/update.d...\n",
            "\n",
            "done.\n",
            "done.\n",
            "Processing triggers for sgml-base (1.29.1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 84%]\u001b[49m\u001b[39m [################################################..........] \u001b8Setting up x11proto-dev (2019.2-1ubuntu1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 85%]\u001b[49m\u001b[39m [#################################################.........] \u001b8Processing triggers for fontconfig (2.13.1-2ubuntu3) ...\n",
            "Processing triggers for mime-support (3.64ubuntu1) ...\n",
            "Setting up libxau-dev:amd64 (1:1.0.9-0ubuntu1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 87%]\u001b[49m\u001b[39m [##################################################........] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 88%]\u001b[49m\u001b[39m [##################################################........] \u001b8Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Setting up libice-dev:amd64 (2:1.0.10-0ubuntu1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 88%]\u001b[49m\u001b[39m [###################################################.......] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 89%]\u001b[49m\u001b[39m [###################################################.......] \u001b8Setting up libsm-dev:amd64 (2:1.2.3-1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 90%]\u001b[49m\u001b[39m [####################################################......] \u001b8Processing triggers for libc-bin (2.31-0ubuntu9.7) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Setting up libxdmcp-dev:amd64 (1:1.1.3-0ubuntu1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 92%]\u001b[49m\u001b[39m [#####################################################.....] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 93%]\u001b[49m\u001b[39m [#####################################################.....] \u001b8Setting up x11proto-core-dev (2019.2-1ubuntu1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 93%]\u001b[49m\u001b[39m [######################################################....] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 94%]\u001b[49m\u001b[39m [######################################################....] \u001b8Setting up libxcb1-dev:amd64 (1.14-2) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 95%]\u001b[49m\u001b[39m [#######################################################...] \u001b8Setting up libx11-dev:amd64 (2:1.6.9-2ubuntu1.2) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 97%]\u001b[49m\u001b[39m [########################################################..] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 98%]\u001b[49m\u001b[39m [########################################################..] \u001b8Setting up libxt-dev:amd64 (1:1.1.5-1) ...\n",
            "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 98%]\u001b[49m\u001b[39m [#########################################################.] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 99%]\u001b[49m\u001b[39m [#########################################################.] \u001b8\n",
            "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  285M  100  285M    0     0  5919k      0  0:00:49  0:00:49 --:--:-- 5849k\n",
            "spark-3.3.1-bin-hadoop3/\n",
            "spark-3.3.1-bin-hadoop3/LICENSE\n",
            "spark-3.3.1-bin-hadoop3/NOTICE\n",
            "spark-3.3.1-bin-hadoop3/R/\n",
            "spark-3.3.1-bin-hadoop3/R/lib/\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/DESCRIPTION\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/INDEX\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/Meta/\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/Meta/Rd.rds\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/Meta/features.rds\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/Meta/hsearch.rds\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/Meta/links.rds\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/Meta/nsInfo.rds\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/Meta/package.rds\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/Meta/vignette.rds\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/NAMESPACE\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/R/\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/R/SparkR\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/R/SparkR.rdb\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/R/SparkR.rdx\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/doc/\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/doc/index.html\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/doc/sparkr-vignettes.R\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/doc/sparkr-vignettes.Rmd\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/doc/sparkr-vignettes.html\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/help/\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/help/AnIndex\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/help/SparkR.rdb\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/help/SparkR.rdx\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/help/aliases.rds\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/help/paths.rds\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/html/\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/html/00Index.html\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/html/R.css\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/profile/\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/profile/general.R\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/profile/shell.R\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/tests/\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/tests/testthat/\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/tests/testthat/test_basic.R\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/worker/\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/worker/daemon.R\n",
            "spark-3.3.1-bin-hadoop3/R/lib/SparkR/worker/worker.R\n",
            "spark-3.3.1-bin-hadoop3/R/lib/sparkr.zip\n",
            "spark-3.3.1-bin-hadoop3/README.md\n",
            "spark-3.3.1-bin-hadoop3/RELEASE\n",
            "spark-3.3.1-bin-hadoop3/bin/\n",
            "spark-3.3.1-bin-hadoop3/bin/beeline\n",
            "spark-3.3.1-bin-hadoop3/bin/beeline.cmd\n",
            "spark-3.3.1-bin-hadoop3/bin/docker-image-tool.sh\n",
            "spark-3.3.1-bin-hadoop3/bin/find-spark-home\n",
            "spark-3.3.1-bin-hadoop3/bin/find-spark-home.cmd\n",
            "spark-3.3.1-bin-hadoop3/bin/load-spark-env.cmd\n",
            "spark-3.3.1-bin-hadoop3/bin/load-spark-env.sh\n",
            "spark-3.3.1-bin-hadoop3/bin/pyspark\n",
            "spark-3.3.1-bin-hadoop3/bin/pyspark.cmd\n",
            "spark-3.3.1-bin-hadoop3/bin/pyspark2.cmd\n",
            "spark-3.3.1-bin-hadoop3/bin/run-example\n",
            "spark-3.3.1-bin-hadoop3/bin/run-example.cmd\n",
            "spark-3.3.1-bin-hadoop3/bin/spark-class\n",
            "spark-3.3.1-bin-hadoop3/bin/spark-class.cmd\n",
            "spark-3.3.1-bin-hadoop3/bin/spark-class2.cmd\n",
            "spark-3.3.1-bin-hadoop3/bin/spark-shell\n",
            "spark-3.3.1-bin-hadoop3/bin/spark-shell.cmd\n",
            "spark-3.3.1-bin-hadoop3/bin/spark-shell2.cmd\n",
            "spark-3.3.1-bin-hadoop3/bin/spark-sql\n",
            "spark-3.3.1-bin-hadoop3/bin/spark-sql.cmd\n",
            "spark-3.3.1-bin-hadoop3/bin/spark-sql2.cmd\n",
            "spark-3.3.1-bin-hadoop3/bin/spark-submit\n",
            "spark-3.3.1-bin-hadoop3/bin/spark-submit.cmd\n",
            "spark-3.3.1-bin-hadoop3/bin/spark-submit2.cmd\n",
            "spark-3.3.1-bin-hadoop3/bin/sparkR\n",
            "spark-3.3.1-bin-hadoop3/bin/sparkR.cmd\n",
            "spark-3.3.1-bin-hadoop3/bin/sparkR2.cmd\n",
            "spark-3.3.1-bin-hadoop3/conf/\n",
            "spark-3.3.1-bin-hadoop3/conf/fairscheduler.xml.template\n",
            "spark-3.3.1-bin-hadoop3/conf/log4j2.properties.template\n",
            "spark-3.3.1-bin-hadoop3/conf/metrics.properties.template\n",
            "spark-3.3.1-bin-hadoop3/conf/spark-defaults.conf.template\n",
            "spark-3.3.1-bin-hadoop3/conf/spark-env.sh.template\n",
            "spark-3.3.1-bin-hadoop3/conf/workers.template\n",
            "spark-3.3.1-bin-hadoop3/data/\n",
            "spark-3.3.1-bin-hadoop3/data/graphx/\n",
            "spark-3.3.1-bin-hadoop3/data/graphx/followers.txt\n",
            "spark-3.3.1-bin-hadoop3/data/graphx/users.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/als/\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/als/sample_movielens_ratings.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/als/test.data\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/gmm_data.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/images/\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/images/license.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/kittens/\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/kittens/54893.jpg\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/kittens/DP153539.jpg\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/kittens/DP802813.jpg\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/kittens/not-image.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/license.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/multi-channel/\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/multi-channel/BGRA.png\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/multi-channel/chr30.4.184.jpg\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/multi-channel/grayscale.jpg\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/kmeans_data.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/pagerank_data.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/pic_data.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/ridge-data/\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/ridge-data/lpsa.data\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/sample_binary_classification_data.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/sample_fpgrowth.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/sample_isotonic_regression_libsvm_data.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/sample_kmeans_data.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/sample_lda_data.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/sample_lda_libsvm_data.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/sample_libsvm_data.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/sample_linear_regression_data.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/sample_movielens_data.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/sample_multiclass_classification_data.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/sample_svm_data.txt\n",
            "spark-3.3.1-bin-hadoop3/data/mllib/streaming_kmeans_data_test.txt\n",
            "spark-3.3.1-bin-hadoop3/data/streaming/\n",
            "spark-3.3.1-bin-hadoop3/data/streaming/AFINN-111.txt\n",
            "spark-3.3.1-bin-hadoop3/examples/\n",
            "spark-3.3.1-bin-hadoop3/examples/jars/\n",
            "spark-3.3.1-bin-hadoop3/examples/jars/scopt_2.12-3.7.1.jar\n",
            "spark-3.3.1-bin-hadoop3/examples/jars/spark-examples_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/examples/src/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaTC.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFMClassifierExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFMRegressorExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaUnivariateFeatureSelectorExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVarianceThresholdSelectorExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedScalar.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/hive/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredComplexSessionization.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/als.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/avro_inputformat.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/kmeans.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/logistic_regression.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/__init__,py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/aft_survival_regression.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/als_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/binarizer_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/bisecting_k_means_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/bucketizer_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/chi_square_test_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/chisq_selector_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/correlation_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/count_vectorizer_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/cross_validator.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/dataframe_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/dct_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/decision_tree_classification_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/decision_tree_regression_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/elementwise_product_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/estimator_transformer_param_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/feature_hasher_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/fm_classifier_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/fm_regressor_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/fpgrowth_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/gaussian_mixture_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/generalized_linear_regression_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/imputer_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/index_to_string_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/interaction_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/isotonic_regression_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/kmeans_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/lda_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/linear_regression_with_elastic_net.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/linearsvc.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/logistic_regression_summary_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/logistic_regression_with_elastic_net.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/max_abs_scaler_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/min_hash_lsh_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/min_max_scaler_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/multilayer_perceptron_classification.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/n_gram_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/naive_bayes_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/normalizer_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/one_vs_rest_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/onehot_encoder_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/pca_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/pipeline_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/polynomial_expansion_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/power_iteration_clustering_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/prefixspan_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/quantile_discretizer_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/random_forest_classifier_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/random_forest_regressor_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/rformula_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/robust_scaler_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/sql_transformer.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/standard_scaler_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/stopwords_remover_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/string_indexer_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/summarizer_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/tf_idf_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/tokenizer_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/train_validation_split.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/univariate_feature_selector_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/variance_threshold_selector_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/vector_assembler_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/vector_indexer_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/vector_size_hint_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/vector_slicer_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/word2vec_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/binary_classification_metrics_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/bisecting_k_means_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/correlations.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/correlations_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/decision_tree_classification_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/decision_tree_regression_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/elementwise_product_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/fpgrowth_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/gaussian_mixture_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/gaussian_mixture_model.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/gradient_boosting_classification_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/gradient_boosting_regression_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/hypothesis_testing_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/isotonic_regression_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/k_means_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/kernel_density_estimation_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/kmeans.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/linear_regression_with_sgd_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/logistic_regression.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/multi_class_metrics_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/multi_label_metrics_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/naive_bayes_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/normalizer_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/pca_rowmatrix_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/power_iteration_clustering_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/random_forest_classification_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/random_forest_regression_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/random_rdd_generation.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/ranking_metrics_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/recommendation_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/regression_metrics_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/sampled_rdds.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/standard_scaler_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/stratified_sampling_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/streaming_k_means_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/streaming_linear_regression_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/summary_statistics_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/svd_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/svm_with_sgd_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/tf_idf_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/word2vec.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/word2vec_example.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/pagerank.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/parquet_inputformat.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/pi.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/sort.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/arrow.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/basic.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/datasource.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/hive.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/streaming/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/streaming/__init__,py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/streaming/structured_network_wordcount.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/streaming/structured_sessionization.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/status_api_demo.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/streaming/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/streaming/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/streaming/hdfs_wordcount.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/streaming/network_wordcount.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/streaming/network_wordjoinsentiments.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/streaming/queue_stream.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/streaming/recoverable_network_wordcount.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/streaming/sql_network_wordcount.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/streaming/stateful_network_wordcount.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/transitive_closure.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/python/wordcount.py\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/RSparkSQLExample.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/data-manipulation.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/dataframe.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/als.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/bisectingKmeans.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/decisionTree.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/fmClassifier.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/fmRegressor.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/fpm.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/gaussianMixture.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/gbt.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/glm.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/isoreg.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/kmeans.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/kstest.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/lda.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/lm_with_elastic_net.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/logit.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/ml.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/mlp.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/naiveBayes.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/powerIterationClustering.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/prefixSpan.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/randomForest.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/survreg.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/svmLinear.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/streaming/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/r/streaming/structured_network_wordcount.R\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/META-INF/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/META-INF/services/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/META-INF/services/org.apache.spark.sql.SparkSessionExtensionsProvider\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/META-INF/services/org.apache.spark.sql.jdbc.JdbcConnectionProvider\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/dir1/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/dir1/dir2/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/dir1/dir2/file2.parquet\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/dir1/file1.parquet\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/dir1/file3.json\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/employees.json\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/full_user.avsc\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/kv1.txt\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/people.csv\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/people.json\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/people.txt\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/user.avsc\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/users.avro\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/users.orc\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/resources/users.parquet\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/MiniReadWriteTest.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/AgeExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithLoader.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithoutLoader.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/SparkSessionExtensionsTest.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FMClassifierExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FMRegressorExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/UnivariateFeatureSelectorExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VarianceThresholdSelectorExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/pythonconverters/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedScalar.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/hive/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/ExampleJdbcConnectionProvider.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredComplexSessionization.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scripts/\n",
            "spark-3.3.1-bin-hadoop3/examples/src/main/scripts/getGpusResources.sh\n",
            "spark-3.3.1-bin-hadoop3/jars/\n",
            "spark-3.3.1-bin-hadoop3/jars/HikariCP-2.5.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/JLargeArrays-1.5.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/JTransforms-3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/RoaringBitmap-0.9.25.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/ST4-4.0.4.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/activation-1.1.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/aircompressor-0.21.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/algebra_2.12-2.0.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/annotations-17.0.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/antlr-runtime-3.5.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/antlr4-runtime-4.8.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/aopalliance-repackaged-2.6.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/arpack-2.2.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/arpack_combined_all-0.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/arrow-format-7.0.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/arrow-memory-core-7.0.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/arrow-memory-netty-7.0.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/arrow-vector-7.0.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/audience-annotations-0.5.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/automaton-1.11-8.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/avro-1.11.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/avro-ipc-1.11.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/avro-mapred-1.11.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/blas-2.2.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/bonecp-0.8.0.RELEASE.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/breeze-macros_2.12-1.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/breeze_2.12-1.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/cats-kernel_2.12-2.1.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/chill-java-0.10.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/chill_2.12-0.10.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/commons-cli-1.5.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/commons-codec-1.15.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/commons-collections-3.2.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/commons-collections4-4.4.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/commons-compiler-3.0.16.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/commons-compress-1.21.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/commons-crypto-1.1.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/commons-dbcp-1.4.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/commons-io-2.11.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/commons-lang-2.6.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/commons-lang3-3.12.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/commons-logging-1.1.3.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/commons-math3-3.6.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/commons-pool-1.5.4.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/commons-text-1.9.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/compress-lzf-1.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/core-1.1.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/curator-client-2.13.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/curator-framework-2.13.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/curator-recipes-2.13.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/datanucleus-api-jdo-4.2.4.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/datanucleus-core-4.1.17.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/datanucleus-rdbms-4.1.19.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/derby-10.14.2.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/flatbuffers-java-1.12.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/generex-1.0.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/gson-2.2.4.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/guava-14.0.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hadoop-client-api-3.3.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hadoop-client-runtime-3.3.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hadoop-shaded-guava-1.1.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hadoop-yarn-server-web-proxy-3.3.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hive-beeline-2.3.9.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hive-cli-2.3.9.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hive-common-2.3.9.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hive-exec-2.3.9-core.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hive-jdbc-2.3.9.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hive-llap-common-2.3.9.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hive-metastore-2.3.9.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hive-serde-2.3.9.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hive-service-rpc-3.1.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hive-shims-0.23-2.3.9.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hive-shims-2.3.9.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hive-shims-common-2.3.9.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hive-shims-scheduler-2.3.9.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hive-storage-api-2.7.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hive-vector-code-gen-2.3.9.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hk2-api-2.6.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hk2-locator-2.6.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/hk2-utils-2.6.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/httpclient-4.5.13.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/httpcore-4.4.14.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/istack-commons-runtime-3.0.8.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/ivy-2.5.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jackson-annotations-2.13.4.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jackson-core-2.13.4.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jackson-core-asl-1.9.13.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jackson-databind-2.13.4.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jackson-dataformat-yaml-2.13.4.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jackson-datatype-jsr310-2.13.4.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jackson-mapper-asl-1.9.13.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jackson-module-scala_2.12-2.13.4.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jakarta.annotation-api-1.3.5.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jakarta.inject-2.6.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jakarta.servlet-api-4.0.3.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jakarta.validation-api-2.0.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jakarta.ws.rs-api-2.1.6.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jakarta.xml.bind-api-2.3.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/janino-3.0.16.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/javassist-3.25.0-GA.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/javax.jdo-3.2.0-m3.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/javolution-5.5.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jaxb-runtime-2.3.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jcl-over-slf4j-1.7.32.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jdo-api-3.0.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jersey-client-2.36.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jersey-common-2.36.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jersey-container-servlet-2.36.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jersey-container-servlet-core-2.36.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jersey-hk2-2.36.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jersey-server-2.36.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jline-2.14.6.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/joda-time-2.10.13.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jodd-core-3.5.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jpam-1.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/json-1.8.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/json4s-ast_2.12-3.7.0-M11.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/json4s-core_2.12-3.7.0-M11.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/json4s-jackson_2.12-3.7.0-M11.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/json4s-scalap_2.12-3.7.0-M11.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jsr305-3.0.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jta-1.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/jul-to-slf4j-1.7.32.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kryo-shaded-4.0.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-client-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-admissionregistration-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-apiextensions-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-apps-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-autoscaling-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-batch-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-certificates-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-common-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-coordination-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-core-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-discovery-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-events-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-extensions-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-flowcontrol-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-metrics-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-networking-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-node-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-policy-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-rbac-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-scheduling-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-storageclass-5.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/lapack-2.2.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/leveldbjni-all-1.8.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/libfb303-0.9.3.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/libthrift-0.12.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/log4j-1.2-api-2.17.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/log4j-api-2.17.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/log4j-core-2.17.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/log4j-slf4j-impl-2.17.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/logging-interceptor-3.12.12.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/lz4-java-1.8.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/mesos-1.4.3-shaded-protobuf.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/metrics-core-4.2.7.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/metrics-graphite-4.2.7.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/metrics-jmx-4.2.7.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/metrics-json-4.2.7.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/metrics-jvm-4.2.7.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/minlog-1.3.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/netty-all-4.1.74.Final.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/netty-buffer-4.1.74.Final.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/netty-codec-4.1.74.Final.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/netty-common-4.1.74.Final.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/netty-handler-4.1.74.Final.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/netty-resolver-4.1.74.Final.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/netty-tcnative-classes-2.0.48.Final.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/netty-transport-4.1.74.Final.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/netty-transport-classes-epoll-4.1.74.Final.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/netty-transport-classes-kqueue-4.1.74.Final.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/netty-transport-native-epoll-4.1.74.Final-linux-aarch_64.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/netty-transport-native-epoll-4.1.74.Final-linux-x86_64.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/netty-transport-native-kqueue-4.1.74.Final-osx-aarch_64.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/netty-transport-native-kqueue-4.1.74.Final-osx-x86_64.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/netty-transport-native-unix-common-4.1.74.Final.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/objenesis-3.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/okhttp-3.12.12.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/okio-1.14.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/opencsv-2.3.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/orc-core-1.7.6.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/orc-mapreduce-1.7.6.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/orc-shims-1.7.6.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/oro-2.0.8.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/osgi-resource-locator-1.0.3.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/paranamer-2.8.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/parquet-column-1.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/parquet-common-1.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/parquet-encoding-1.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/parquet-format-structures-1.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/parquet-hadoop-1.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/parquet-jackson-1.12.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/pickle-1.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/protobuf-java-2.5.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/py4j-0.10.9.5.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/rocksdbjni-6.20.3.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/scala-collection-compat_2.12-2.1.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/scala-compiler-2.12.15.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/scala-library-2.12.15.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/scala-parser-combinators_2.12-1.1.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/scala-reflect-2.12.15.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/scala-xml_2.12-1.2.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/shapeless_2.12-2.3.7.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/shims-0.9.25.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/slf4j-api-1.7.32.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/snakeyaml-1.31.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/snappy-java-1.1.8.4.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-catalyst_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-core_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-graphx_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-hive-thriftserver_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-hive_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-kubernetes_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-kvstore_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-launcher_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-mesos_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-mllib-local_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-mllib_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-network-common_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-network-shuffle_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-repl_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-sketch_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-sql_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-streaming_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-tags_2.12-3.3.1-tests.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-tags_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-unsafe_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spark-yarn_2.12-3.3.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spire-macros_2.12-0.17.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spire-platform_2.12-0.17.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spire-util_2.12-0.17.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/spire_2.12-0.17.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/stax-api-1.0.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/stream-2.9.6.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/super-csv-2.2.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/threeten-extra-1.5.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/tink-1.6.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/transaction-api-1.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/univocity-parsers-2.9.1.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/velocity-1.5.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/xbean-asm9-shaded-4.20.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/xz-1.8.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/zjsonpatch-0.3.0.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/zookeeper-3.6.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/zookeeper-jute-3.6.2.jar\n",
            "spark-3.3.1-bin-hadoop3/jars/zstd-jni-1.5.2-1.jar\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/Dockerfile\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/Dockerfile.java17\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/R/\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/R/Dockerfile\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/python/\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/python/Dockerfile\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/decom.sh\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/entrypoint.sh\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/tests/\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/tests/autoscale.py\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/tests/decommissioning.py\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/tests/decommissioning_cleanup.py\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/tests/py_container_checks.py\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/tests/pyfiles.py\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/tests/python_executable_check.py\n",
            "spark-3.3.1-bin-hadoop3/kubernetes/tests/worker_memory_check.py\n",
            "spark-3.3.1-bin-hadoop3/licenses/\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-AnchorJS.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-CC0.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-JLargeArrays.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-JTransforms.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-antlr.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-arpack.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-automaton.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-blas.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-bootstrap.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-cloudpickle.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-d3.min.js.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-dagre-d3.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-datatables.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-dnsjava.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-f2j.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-graphlib-dot.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-istack-commons-runtime.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-jakarta-annotation-api\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-jakarta-ws-rs-api\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-jakarta.activation-api.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-jakarta.xml.bind-api.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-janino.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-javassist.html\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-javax-transaction-transaction-api.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-javolution.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-jaxb-runtime.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-jline.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-jodd.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-join.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-jquery.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-json-formatter.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-jsp-api.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-kryo.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-leveldbjni.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-machinist.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-matchMedia-polyfill.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-minlog.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-modernizr.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-mustache.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-netlib.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-paranamer.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-pmml-model.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-protobuf.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-py4j.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-pyrolite.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-re2j.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-reflectasm.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-respond.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-sbt-launch-lib.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-scala.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-scopt.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-slf4j.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-sorttable.js.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-spire.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-vis-timeline.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-xmlenc.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-zstd-jni.txt\n",
            "spark-3.3.1-bin-hadoop3/licenses/LICENSE-zstd.txt\n",
            "spark-3.3.1-bin-hadoop3/python/\n",
            "spark-3.3.1-bin-hadoop3/python/.coveragerc\n",
            "spark-3.3.1-bin-hadoop3/python/.gitignore\n",
            "spark-3.3.1-bin-hadoop3/python/MANIFEST.in\n",
            "spark-3.3.1-bin-hadoop3/python/README.md\n",
            "spark-3.3.1-bin-hadoop3/python/dist/\n",
            "spark-3.3.1-bin-hadoop3/python/docs/\n",
            "spark-3.3.1-bin-hadoop3/python/docs/Makefile\n",
            "spark-3.3.1-bin-hadoop3/python/docs/make.bat\n",
            "spark-3.3.1-bin-hadoop3/python/docs/make2.bat\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/_static/\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/_static/copybutton.js\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/_static/css/\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/_static/css/pyspark.css\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/_templates/\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/_templates/autosummary/\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/_templates/autosummary/class.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/_templates/autosummary/class_with_docs.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/conf.py\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/development/\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/development/contributing.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/development/debugging.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/development/index.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/development/setting_ide.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/development/testing.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/getting_started/\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/getting_started/index.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/getting_started/install.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/getting_started/quickstart_df.ipynb\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/getting_started/quickstart_ps.ipynb\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/index.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/index.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/koalas_to_pyspark.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/pyspark_1.0_1.2_to_1.3.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/pyspark_1.4_to_1.5.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/pyspark_2.2_to_2.3.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/pyspark_2.3.0_to_2.3.1_above.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/pyspark_2.3_to_2.4.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/pyspark_2.4_to_3.0.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/pyspark_3.1_to_3.2.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/pyspark_3.2_to_3.3.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/index.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.ml.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.mllib.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/extensions.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/frame.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/general_functions.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/groupby.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/index.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/indexing.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/io.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/ml.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/series.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/window.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.resource.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/avro.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/catalog.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/column.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/configuration.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/core_classes.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/data_types.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/dataframe.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/functions.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/grouping.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/index.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/io.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/observation.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/row.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/spark_session.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/window.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/core_classes.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/index.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/io.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/query_management.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.streaming.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/arrow_pandas.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/index.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/best_practices.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/faq.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/from_to_dbms.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/index.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/options.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/pandas_pyspark.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/supported_pandas_api.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/transform_apply.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/typehints.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/types.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/python_packaging.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/sql/\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/sql/arrow_pandas.rst\n",
            "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/sql/index.rst\n",
            "spark-3.3.1-bin-hadoop3/python/lib/\n",
            "spark-3.3.1-bin-hadoop3/python/lib/PY4J_LICENSE.txt\n",
            "spark-3.3.1-bin-hadoop3/python/lib/py4j-0.10.9.5-src.zip\n",
            "spark-3.3.1-bin-hadoop3/python/lib/pyspark.zip\n",
            "spark-3.3.1-bin-hadoop3/python/mypy.ini\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/__pycache__/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/__pycache__/install.cpython-38.pyc\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/_globals.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/_typing.pyi\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/accumulators.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/broadcast.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/cloudpickle/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/cloudpickle/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/cloudpickle/cloudpickle.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/cloudpickle/cloudpickle_fast.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/cloudpickle/compat.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/conf.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/context.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/daemon.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/files.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/find_spark_home.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/install.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/instrumentation_utils.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/java_gateway.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/join.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/_typing.pyi\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/base.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/classification.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/clustering.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/common.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/evaluation.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/feature.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/fpm.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/functions.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/image.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/linalg/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/linalg/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/param/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/param/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/param/_shared_params_code_gen.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/param/shared.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/pipeline.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/recommendation.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/regression.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/stat.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_algorithms.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_base.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_evaluation.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_feature.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_image.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_linalg.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_param.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_persistence.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_pipeline.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_stat.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_training_summary.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_tuning.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_util.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_wrapper.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/typing/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_classification.yml\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_clustering.yaml\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_evaluation.yml\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_feature.yml\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_param.yml\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_readable.yml\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_regression.yml\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tree.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tuning.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/util.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/ml/wrapper.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/_typing.pyi\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/classification.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/clustering.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/common.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/evaluation.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/feature.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/fpm.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/linalg/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/linalg/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/linalg/distributed.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/random.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/random.pyi\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/recommendation.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/recommendation.pyi\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/regression.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/stat/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/stat/KernelDensity.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/stat/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/stat/_statistics.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/stat/distribution.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/stat/test.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/tests/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/tests/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/tests/test_algorithms.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/tests/test_feature.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/tests/test_linalg.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/tests/test_stat.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/tests/test_streaming_algorithms.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/tests/test_util.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/tree.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/util.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/_typing.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/accessors.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/base.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/categorical.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/config.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/base.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/binary_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/boolean_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/categorical_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/complex_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/date_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/datetime_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/null_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/num_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/string_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/timedelta_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/udt_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/datetimes.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/exceptions.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/extensions.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/frame.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/generic.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/groupby.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/indexes/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/indexes/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/indexes/base.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/indexes/category.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/indexes/datetimes.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/indexes/multi.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/indexes/numeric.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/indexes/timedelta.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/indexing.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/internal.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/missing/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/missing/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/missing/common.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/missing/frame.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/missing/general_functions.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/missing/groupby.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/missing/indexes.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/missing/series.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/missing/window.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/ml.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/mlflow.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/namespace.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/numpy_compat.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/plot/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/plot/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/plot/core.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/plot/matplotlib.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/plot/plotly.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/series.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/spark/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/spark/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/spark/accessors.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/spark/functions.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/spark/utils.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/sql_formatter.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/sql_processor.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/strings.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_base.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_binary_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_boolean_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_categorical_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_complex_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_date_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_datetime_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_null_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_num_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_string_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_timedelta_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_udt_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/testing_utils.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_base.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_category.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_datetime.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_timedelta.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/plot/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/plot/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_frame_plot.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_frame_plot_matplotlib.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_frame_plot_plotly.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_series_plot.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_series_plot_matplotlib.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_series_plot_plotly.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_categorical.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_config.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_csv.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_dataframe.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_dataframe_conversion.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_dataframe_spark_io.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_default_index.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_expanding.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_extension.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_frame_spark.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_groupby.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_indexing.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_indexops_spark.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_internal.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_namespace.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_numpy_compat.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby_expanding.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby_rolling.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_repr.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_reshape.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_rolling.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_series.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_series_conversion.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_series_datetime.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_series_string.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_spark_functions.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_sql.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_stats.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_typedef.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_utils.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_window.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/typedef/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/typedef/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/typedef/typehints.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/usage_logging/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/usage_logging/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/usage_logging/usage_logger.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/utils.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/window.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/profiler.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/py.typed\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/python/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/python/pyspark/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/python/pyspark/shell.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/rdd.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/rddsampler.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/resource/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/resource/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/resource/information.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/resource/profile.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/resource/requests.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/resource/tests/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/resource/tests/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/resource/tests/test_resources.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/resultiterable.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/serializers.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/shell.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/shuffle.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/_typing.pyi\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/avro/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/avro/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/avro/functions.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/catalog.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/column.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/conf.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/context.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/dataframe.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/functions.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/group.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/observation.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/__init__.pyi\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/__init__.pyi\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/frame.pyi\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/series.pyi\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/conversion.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/functions.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/functions.pyi\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/group_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/map_ops.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/serializers.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/typehints.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/types.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/utils.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/readwriter.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/session.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/sql_formatter.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/streaming.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_arrow.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_arrow_map.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_catalog.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_column.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_conf.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_context.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_dataframe.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_datasources.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_functions.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_group.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_cogrouped_map.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_grouped_map.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_map.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_udf.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_udf_grouped_agg.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_udf_scalar.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_udf_typehints.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_udf_typehints_with_future_annotations.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_udf_window.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_readwriter.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_serde.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_session.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_streaming.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_types.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_udf.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_udf_profiler.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_utils.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/typing/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_column.yml\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_dataframe.yml\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_functions.yml\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_readwriter.yml\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_session.yml\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_udf.yml\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/types.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/udf.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/utils.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/sql/window.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/statcounter.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/status.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/storagelevel.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/context.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/dstream.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/kinesis.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/listener.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/tests/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/tests/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/tests/test_context.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/tests/test_dstream.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/tests/test_kinesis.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/tests/test_listener.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/util.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/taskcontext.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/testing/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/testing/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/testing/mllibutils.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/testing/mlutils.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/testing/pandasutils.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/testing/sqlutils.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/testing/streamingutils.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/testing/utils.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/__init__.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_appsubmit.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_broadcast.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_conf.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_context.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_daemon.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_install_spark.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_join.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_pin_thread.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_profiler.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_rdd.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_rddbarrier.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_readwrite.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_serializers.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_shuffle.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_statcounter.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_taskcontext.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_util.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_worker.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/typing/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/typing/test_context.yml\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/typing/test_core.yml\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/typing/test_rdd.yml\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/tests/typing/test_resultiterable.yml\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/traceback_utils.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/util.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/version.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark/worker.py\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark.egg-info/\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark.egg-info/PKG-INFO\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark.egg-info/SOURCES.txt\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark.egg-info/dependency_links.txt\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark.egg-info/requires.txt\n",
            "spark-3.3.1-bin-hadoop3/python/pyspark.egg-info/top_level.txt\n",
            "spark-3.3.1-bin-hadoop3/python/run-tests\n",
            "spark-3.3.1-bin-hadoop3/python/run-tests-with-coverage\n",
            "spark-3.3.1-bin-hadoop3/python/run-tests.py\n",
            "spark-3.3.1-bin-hadoop3/python/setup.cfg\n",
            "spark-3.3.1-bin-hadoop3/python/setup.py\n",
            "spark-3.3.1-bin-hadoop3/python/test_coverage/\n",
            "spark-3.3.1-bin-hadoop3/python/test_coverage/conf/\n",
            "spark-3.3.1-bin-hadoop3/python/test_coverage/conf/spark-defaults.conf\n",
            "spark-3.3.1-bin-hadoop3/python/test_coverage/coverage_daemon.py\n",
            "spark-3.3.1-bin-hadoop3/python/test_coverage/sitecustomize.py\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/SimpleHTTPServer.py\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/hello/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/hello/hello.txt\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/hello/sub_hello/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/hello/sub_hello/sub_hello.txt\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/ages.csv\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/ages_newlines.csv\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/_SUCCESS\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/c=0/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/c=0/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/c=0/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/c=1/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/c=1/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/c=1/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/_SUCCESS\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/_common_metadata\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/_metadata\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2014/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2014/month=9/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/.part-r-00008.gz.parquet.crc\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/part-r-00008.gz.parquet\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=10/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00002.gz.parquet.crc\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00004.gz.parquet.crc\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00002.gz.parquet\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00004.gz.parquet\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/.part-r-00005.gz.parquet.crc\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/part-r-00005.gz.parquet\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=9/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/.part-r-00007.gz.parquet.crc\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/part-r-00007.gz.parquet\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/people.json\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/people1.json\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/people_array.json\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/people_array_utf16le.json\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/streaming/\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/streaming/text-test.txt\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/sql/text-test.txt\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/userlib-0.1.zip\n",
            "spark-3.3.1-bin-hadoop3/python/test_support/userlibrary.py\n",
            "spark-3.3.1-bin-hadoop3/sbin/\n",
            "spark-3.3.1-bin-hadoop3/sbin/decommission-slave.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/decommission-worker.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/slaves.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/spark-config.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/spark-daemon.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/spark-daemons.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/start-all.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/start-history-server.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/start-master.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/start-mesos-dispatcher.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/start-mesos-shuffle-service.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/start-slave.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/start-slaves.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/start-thriftserver.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/start-worker.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/start-workers.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/stop-all.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/stop-history-server.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/stop-master.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/stop-mesos-dispatcher.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/stop-mesos-shuffle-service.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/stop-slave.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/stop-slaves.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/stop-thriftserver.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/stop-worker.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/stop-workers.sh\n",
            "spark-3.3.1-bin-hadoop3/sbin/workers.sh\n",
            "spark-3.3.1-bin-hadoop3/yarn/\n",
            "spark-3.3.1-bin-hadoop3/yarn/spark-3.3.1-yarn-shuffle.jar\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845500 sha256=cfb38a51efcf0ec10bb2001493d109642975d605387ae27104ed3c9bfa6000aa\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/c8/18/298a4ced8ebb3ab8a7d26a7198c0cc7035abb906bde94a4c4b\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "#### INSTALLATION OF LIBRARIES FOR SPARK\n",
        "!pip install findspark\n",
        "!sudo apt update\n",
        "!sudo apt install openjdk-17-jdk -y\n",
        "!curl -JLO 'https://apache.osuosl.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz'\n",
        "!tar xvf spark-3.3.1-bin-hadoop3.tgz\n",
        "!mv spark-3.3.1-bin-hadoop3 /opt/spark\n",
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sparknlp\n",
            "  Downloading sparknlp-1.0.0-py3-none-any.whl (1.4 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from sparknlp) (1.23.1)\n",
            "Collecting spark-nlp\n",
            "  Downloading spark_nlp-4.2.3-py2.py3-none-any.whl (648 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m648.6/648.6 kB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: spark-nlp, sparknlp\n",
            "Successfully installed spark-nlp-4.2.3 sparknlp-1.0.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install sparknlp\n",
        "!pip install happytransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "KjcBNzFVgoky",
        "outputId": "957b5779-7d0a-4a79-e0ec-05b0e050e4b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ":: loading settings :: url = jar:file:/usr/local/lib/python3.9/dist-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ivy Default Cache set to: /root/.ivy2/cache\n",
            "The jars for the packages stored in: /root/.ivy2/jars\n",
            "com.johnsnowlabs.nlp#spark-nlp-gpu_2.12 added as a dependency\n",
            ":: resolving dependencies :: org.apache.spark#spark-submit-parent-2efde278-0898-4d48-8980-53329a102edb;1.0\n",
            "\tconfs: [default]\n",
            "\tfound com.johnsnowlabs.nlp#spark-nlp-gpu_2.12;4.2.3 in central\n",
            "\tfound com.typesafe#config;1.4.2 in central\n",
            "\tfound org.rocksdb#rocksdbjni;6.29.5 in central\n",
            "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.828 in central\n",
            "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
            "\tfound com.google.code.findbugs#annotations;3.0.1 in central\n",
            "\tfound net.jcip#jcip-annotations;1.0 in central\n",
            "\tfound com.google.code.findbugs#jsr305;3.0.1 in central\n",
            "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
            "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
            "\tfound com.google.code.gson#gson;2.3 in central\n",
            "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
            "\tfound org.projectlombok#lombok;1.16.8 in central\n",
            "\tfound org.slf4j#slf4j-api;1.7.21 in central\n",
            "\tfound com.navigamez#greex;1.0 in central\n",
            "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
            "\tfound com.johnsnowlabs.nlp#tensorflow-gpu_2.12;0.4.3 in central\n",
            "downloading https://repo1.maven.org/maven2/com/johnsnowlabs/nlp/spark-nlp-gpu_2.12/4.2.3/spark-nlp-gpu_2.12-4.2.3.jar ...\n",
            "\t[SUCCESSFUL ] com.johnsnowlabs.nlp#spark-nlp-gpu_2.12;4.2.3!spark-nlp-gpu_2.12.jar (615ms)\n",
            "downloading https://repo1.maven.org/maven2/com/typesafe/config/1.4.2/config-1.4.2.jar ...\n",
            "\t[SUCCESSFUL ] com.typesafe#config;1.4.2!config.jar(bundle) (9ms)\n",
            "downloading https://repo1.maven.org/maven2/org/rocksdb/rocksdbjni/6.29.5/rocksdbjni-6.29.5.jar ...\n",
            "\t[SUCCESSFUL ] org.rocksdb#rocksdbjni;6.29.5!rocksdbjni.jar (224ms)\n",
            "downloading https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.11.828/aws-java-sdk-bundle-1.11.828.jar ...\n",
            "\t[SUCCESSFUL ] com.amazonaws#aws-java-sdk-bundle;1.11.828!aws-java-sdk-bundle.jar (469ms)\n",
            "downloading https://repo1.maven.org/maven2/com/github/universal-automata/liblevenshtein/3.0.0/liblevenshtein-3.0.0.jar ...\n",
            "\t[SUCCESSFUL ] com.github.universal-automata#liblevenshtein;3.0.0!liblevenshtein.jar (15ms)\n",
            "downloading https://repo1.maven.org/maven2/com/navigamez/greex/1.0/greex-1.0.jar ...\n",
            "\t[SUCCESSFUL ] com.navigamez#greex;1.0!greex.jar (8ms)\n",
            "downloading https://repo1.maven.org/maven2/com/johnsnowlabs/nlp/tensorflow-gpu_2.12/0.4.3/tensorflow-gpu_2.12-0.4.3.jar ...\n",
            "\t[SUCCESSFUL ] com.johnsnowlabs.nlp#tensorflow-gpu_2.12;0.4.3!tensorflow-gpu_2.12.jar (2741ms)\n",
            "downloading https://repo1.maven.org/maven2/com/google/code/findbugs/annotations/3.0.1/annotations-3.0.1.jar ...\n",
            "\t[SUCCESSFUL ] com.google.code.findbugs#annotations;3.0.1!annotations.jar (7ms)\n",
            "downloading https://repo1.maven.org/maven2/com/google/protobuf/protobuf-java-util/3.0.0-beta-3/protobuf-java-util-3.0.0-beta-3.jar ...\n",
            "\t[SUCCESSFUL ] com.google.protobuf#protobuf-java-util;3.0.0-beta-3!protobuf-java-util.jar(bundle) (6ms)\n",
            "downloading https://repo1.maven.org/maven2/com/google/protobuf/protobuf-java/3.0.0-beta-3/protobuf-java-3.0.0-beta-3.jar ...\n",
            "\t[SUCCESSFUL ] com.google.protobuf#protobuf-java;3.0.0-beta-3!protobuf-java.jar(bundle) (35ms)\n",
            "downloading https://repo1.maven.org/maven2/it/unimi/dsi/fastutil/7.0.12/fastutil-7.0.12.jar ...\n",
            "\t[SUCCESSFUL ] it.unimi.dsi#fastutil;7.0.12!fastutil.jar (86ms)\n",
            "downloading https://repo1.maven.org/maven2/org/projectlombok/lombok/1.16.8/lombok-1.16.8.jar ...\n",
            "\t[SUCCESSFUL ] org.projectlombok#lombok;1.16.8!lombok.jar (17ms)\n",
            "downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.21/slf4j-api-1.7.21.jar ...\n",
            "\t[SUCCESSFUL ] org.slf4j#slf4j-api;1.7.21!slf4j-api.jar (8ms)\n",
            "downloading https://repo1.maven.org/maven2/net/jcip/jcip-annotations/1.0/jcip-annotations-1.0.jar ...\n",
            "\t[SUCCESSFUL ] net.jcip#jcip-annotations;1.0!jcip-annotations.jar (7ms)\n",
            "downloading https://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/3.0.1/jsr305-3.0.1.jar ...\n",
            "\t[SUCCESSFUL ] com.google.code.findbugs#jsr305;3.0.1!jsr305.jar (6ms)\n",
            "downloading https://repo1.maven.org/maven2/com/google/code/gson/gson/2.3/gson-2.3.jar ...\n",
            "\t[SUCCESSFUL ] com.google.code.gson#gson;2.3!gson.jar (6ms)\n",
            "downloading https://repo1.maven.org/maven2/dk/brics/automaton/automaton/1.11-8/automaton-1.11-8.jar ...\n",
            "\t[SUCCESSFUL ] dk.brics.automaton#automaton;1.11-8!automaton.jar (7ms)\n",
            ":: resolution report :: resolve 1554ms :: artifacts dl 4290ms\n",
            "\t:: modules in use:\n",
            "\tcom.amazonaws#aws-java-sdk-bundle;1.11.828 from central in [default]\n",
            "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
            "\tcom.google.code.findbugs#annotations;3.0.1 from central in [default]\n",
            "\tcom.google.code.findbugs#jsr305;3.0.1 from central in [default]\n",
            "\tcom.google.code.gson#gson;2.3 from central in [default]\n",
            "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 from central in [default]\n",
            "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 from central in [default]\n",
            "\tcom.johnsnowlabs.nlp#spark-nlp-gpu_2.12;4.2.3 from central in [default]\n",
            "\tcom.johnsnowlabs.nlp#tensorflow-gpu_2.12;0.4.3 from central in [default]\n",
            "\tcom.navigamez#greex;1.0 from central in [default]\n",
            "\tcom.typesafe#config;1.4.2 from central in [default]\n",
            "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
            "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
            "\tnet.jcip#jcip-annotations;1.0 from central in [default]\n",
            "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
            "\torg.rocksdb#rocksdbjni;6.29.5 from central in [default]\n",
            "\torg.slf4j#slf4j-api;1.7.21 from central in [default]\n",
            "\t---------------------------------------------------------------------\n",
            "\t|                  |            modules            ||   artifacts   |\n",
            "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
            "\t---------------------------------------------------------------------\n",
            "\t|      default     |   17  |   17  |   17  |   0   ||   17  |   17  |\n",
            "\t---------------------------------------------------------------------\n",
            ":: retrieving :: org.apache.spark#spark-submit-parent-2efde278-0898-4d48-8980-53329a102edb\n",
            "\tconfs: [default]\n",
            "\t17 artifacts copied, 0 already retrieved (966795kB/767ms)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/11/21 19:26:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spark NLP version 4.2.3\n",
            "Apache Spark version: 3.3.1\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://npe0nsr735:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.3.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f873c810cd0>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import sparknlp\n",
        "\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from pyspark.ml import Pipeline\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "spark = sparknlp.start(gpu = True)# for GPU training >> sparknlp.start(gpu = True)\n",
        "\n",
        "print(\"Spark NLP version\", sparknlp.version())\n",
        "print(\"Apache Spark version:\", spark.version)\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VTK1AsahOpz"
      },
      "source": [
        "### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.9/dist-packages (4.5.1)\n",
            "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from gdown) (1.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from gdown) (3.7.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from gdown) (4.11.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.9/dist-packages (from gdown) (2.28.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from gdown) (4.64.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->gdown) (2.3.2.post1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests[socks]->gdown) (2.8)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests[socks]->gdown) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (1.26.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mmkdir: cannot create directory ‘data’: File exists\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QhtF1UAbVMJyAcqVJDucYwmib0hHCP1A\n",
            "To: /notebooks/Dataset Yelp.zip\n",
            "100%|██████████████████████████████████████| 4.23G/4.23G [00:59<00:00, 71.2MB/s]\n",
            "Archive:  data.zip\n",
            "   creating: Dataset Yelp/\n",
            "  inflating: Dataset Yelp/business.json  \n",
            "  inflating: Dataset Yelp/checkin.json  \n",
            "  inflating: Dataset Yelp/review.json  \n",
            "  inflating: Dataset Yelp/tip.json   \n",
            "  inflating: Dataset Yelp/user.json  \n",
            "mv: cannot stat '/notebooks/data/Dataset Yelp/*': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown\n",
        "!mkdir data\n",
        "!cd data\n",
        "!gdown 1QhtF1UAbVMJyAcqVJDucYwmib0hHCP1A\n",
        "!mv 'Dataset Yelp.zip' data.zip\n",
        "!unzip data.zip\n",
        "!mv  -v /notebooks/data/Dataset\\ Yelp/* /notebooks/data/\n",
        "!rm -rf /notebooks/data/Dataset\\ Yelp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/11/21 19:33:34 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
          ]
        }
      ],
      "source": [
        "#### SPARK\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "#import pyspark.pandas as ps\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Spark NLP\")\\\n",
        "    .master(\"local[*]\")\\\n",
        "    .config(\"spark.driver.memory\",\"16G\")\\\n",
        "    .config(\"spark.driver.maxResultSize\", \"0\") \\\n",
        "    .config(\"spark.kryoserializer.buffer.max\", \"2000M\")\\\n",
        "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:4.2.3\")\\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark.sparkContext.setLogLevel(\"OFF\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "for device in gpu_devices:\n",
        "    tf.config.experimental.set_memory_growth(device, True)\n",
        "    \n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "a = tf.zeros(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoTE46WThUz2",
        "outputId": "d9f3dcf0-2b5f-4f49-8b2c-97f89fade6a8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 8:===================================================>     (36 + 4) / 40]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------+\n",
            "|           text|\n",
            "+---------------+\n",
            "|If you decid...|\n",
            "|I've taken a...|\n",
            "|Family diner...|\n",
            "|Wow!  Yummy,...|\n",
            "|Cute interio...|\n",
            "|I am a long ...|\n",
            "|Loved this t...|\n",
            "|Amazingly am...|\n",
            "|This easter ...|\n",
            "|Had a party ...|\n",
            "|My experienc...|\n",
            "|Locals recom...|\n",
            "|Love going h...|\n",
            "|Good food--l...|\n",
            "|The bun make...|\n",
            "|Great place ...|\n",
            "|Tremendous s...|\n",
            "|The hubby an...|\n",
            "|I go to blow...|\n",
            "|My absolute ...|\n",
            "+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "AllData = spark.read \\\n",
        "      .option(\"header\", True) \\\n",
        "      .json(\"./data/review.json\")\n",
        "\n",
        "AllData = AllData.select(\"text\")\n",
        "AllData.show(truncate=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from happytransformer import HappyTextClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at VictorSanh/roberta-base-finetuned-yelp-polarity were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "happy_tc = HappyTextClassification(model_type=\"ROBERTA\", model_name=\"VictorSanh/roberta-base-finetuned-yelp-polarity\", num_labels=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LABEL_0\n"
          ]
        }
      ],
      "source": [
        "result = happy_tc.classify_text(\"I hate AI\")\n",
        "print(result.label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
          ]
        }
      ],
      "source": [
        "import pyspark.pandas as ps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pyspark/pandas/utils.py:975: PandasAPIOnSparkAdviceWarning: If `index_col` is not specified for `read_json`, the default index is attached which can cause additional overhead.\n",
            "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n",
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "reviews = ps.read_json(\"./data/review.json\", lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "reviews_tiny = ps.DataFrame(reviews.loc[0:7000, \"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reviews_tiny['score'] = reviews_tiny.apply(lambda x: happy_tc.classify_text(x).label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_label(text):\n",
        "    result = happy_tc.classify_text(text)\n",
        "    return result.label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'text'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32m/Users/maico/Desktop/Proyectos/trabajofinal/nlp/use classifier spark.ipynb Celda 19\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/maico/Desktop/Proyectos/trabajofinal/nlp/use%20classifier%20spark.ipynb#X63sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m reviews_tiny[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m reviews_tiny[\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mapply(get_label)\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/pandas/series.py:6419\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   6412\u001b[0m     \u001b[39mif\u001b[39;00m (\u001b[39misinstance\u001b[39m(key, \u001b[39mslice\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39mtype\u001b[39m(n) \u001b[39m==\u001b[39m \u001b[39mint\u001b[39m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m [key\u001b[39m.\u001b[39mstart, key\u001b[39m.\u001b[39mstop])) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   6413\u001b[0m         \u001b[39mtype\u001b[39m(key) \u001b[39m==\u001b[39m \u001b[39mint\u001b[39m\n\u001b[1;32m   6414\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mspark\u001b[39m.\u001b[39mdata_type, (IntegerType, LongType))\n\u001b[1;32m   6415\u001b[0m     ):\n\u001b[1;32m   6416\u001b[0m         \u001b[39m# Seems like pandas Series always uses int as positional search when slicing\u001b[39;00m\n\u001b[1;32m   6417\u001b[0m         \u001b[39m# with ints, searches based on index values when the value is int.\u001b[39;00m\n\u001b[1;32m   6418\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miloc[key]\n\u001b[0;32m-> 6419\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloc[key]\n\u001b[1;32m   6420\u001b[0m \u001b[39mexcept\u001b[39;00m SparkPandasIndexingError:\n\u001b[1;32m   6421\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\n\u001b[1;32m   6422\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mKey length (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) exceeds index depth (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   6423\u001b[0m             \u001b[39mlen\u001b[39m(key), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal\u001b[39m.\u001b[39mindex_level\n\u001b[1;32m   6424\u001b[0m         )\n\u001b[1;32m   6425\u001b[0m     )\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/pandas/indexing.py:566\u001b[0m, in \u001b[0;36mLocIndexerLike.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    564\u001b[0m length \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(pdf_or_pser)\n\u001b[1;32m    565\u001b[0m \u001b[39mif\u001b[39;00m length \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 566\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(name_like_string(key))\n\u001b[1;32m    567\u001b[0m \u001b[39melif\u001b[39;00m length \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    568\u001b[0m     \u001b[39mreturn\u001b[39;00m pdf_or_pser\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m]\n",
            "\u001b[0;31mKeyError\u001b[0m: 'text'"
          ]
        }
      ],
      "source": [
        "reviews_tiny['label'] = reviews_tiny.apply(get_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "(SubSet, OldData) = AllData.randomSplit([0.001,0.999], seed = 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "data": {
            "text/plain": [
              "6932"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "SubSet.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'DataFrame' object has no attribute 'apply'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m/Users/maico/Desktop/Proyectos/trabajofinal/nlp/use classifier spark.ipynb Celda 18\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/maico/Desktop/Proyectos/trabajofinal/nlp/use%20classifier%20spark.ipynb#X55sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m SubSet\u001b[39m.\u001b[39;49mapply(get_label)\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/dataframe.py:1988\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1978\u001b[0m \u001b[39m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001b[39;00m\n\u001b[1;32m   1979\u001b[0m \n\u001b[1;32m   1980\u001b[0m \u001b[39m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1985\u001b[0m \u001b[39m[Row(age=2), Row(age=5)]\u001b[39;00m\n\u001b[1;32m   1986\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1987\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns:\n\u001b[0;32m-> 1988\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m   1989\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name)\n\u001b[1;32m   1990\u001b[0m     )\n\u001b[1;32m   1991\u001b[0m jc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jdf\u001b[39m.\u001b[39mapply(name)\n\u001b[1;32m   1992\u001b[0m \u001b[39mreturn\u001b[39;00m Column(jc)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'apply'"
          ]
        }
      ],
      "source": [
        "SubSet.apply(get_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Dataset Count: 4831\n",
            "Test Dataset Count: 2101\n"
          ]
        }
      ],
      "source": [
        "(trainingData, testData) = SubSet.randomSplit([0.7, 0.3], seed = 100)\n",
        "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
        "print(\"Test Dataset Count: \" + str(testData.count()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbZsPrgyl8HC"
      },
      "source": [
        "## ClassifierDL with Universal Sentence Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ek2RfNmsl_q7",
        "outputId": "2821fd3a-af06-46be-c456-b33a61dfe73a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tfhub_use_lg download started this may take some time.\n",
            "Approximate size to download 753.3 MB\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "# actual content is inside description column\n",
        "document = DocumentAssembler()\\\n",
        "                .setInputCol(\"text\")\\\n",
        "                .setOutputCol(\"document\")\n",
        "\n",
        "# we can also use sentece detector here if we want to train on and get predictions for each sentence\n",
        "use = UniversalSentenceEncoder.pretrained(\"tfhub_use_lg\", \"en\") \\\n",
        "                .setInputCols(\"document\") \\\n",
        "                .setOutputCol(\"sentence_embeddings\")\n",
        "\n",
        "# the classes/labels/categories are in category column\n",
        "classsifierdl = ClassifierDLApproach()\\\n",
        "                .setInputCols([\"sentence_embeddings\"])\\\n",
        "                .setOutputCol(\"class\")\\\n",
        "                .setLabelColumn(\"stars\")\\\n",
        "                .setMaxEpochs(3)\\\n",
        "                .setLr(0.01)\\\n",
        "                .setBatchSize(8)\\\n",
        "                .setEnableOutputLogs(True)\n",
        "\n",
        "use_clf_pipeline = Pipeline(stages = [document,\n",
        "                                    use,\n",
        "                                    classsifierdl])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "TVWWZ8NWHs3U"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/root/annotator_logs': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# remove the existing logs\n",
        "! rm -r /root/annotator_logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7EqPl_zJ2N_",
        "outputId": "a162dfa1-c68d-434f-acd6-6b65cd1e571d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-11-21 03:44:59.839198: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/f63c9d3ee71e_classifier_dl4229645102276336813\n",
            "2022-11-21 03:44:59.925132: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
            "2022-11-21 03:44:59.925239: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /tmp/f63c9d3ee71e_classifier_dl4229645102276336813\n",
            "2022-11-21 03:44:59.925502: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-21 03:44:59.927081: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-21 03:44:59.928201: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-21 03:44:59.929342: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-21 03:44:59.930411: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-21 03:44:59.931470: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 70502 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:00:05.0, compute capability: 8.0\n",
            "2022-11-21 03:45:00.508553: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
            "2022-11-21 03:45:01.374167: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/f63c9d3ee71e_classifier_dl4229645102276336813\n",
            "2022-11-21 03:45:01.573159: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 1733983 microseconds.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training started - epochs: 3 - learning_rate: 0.01 - batch_size: 8 - training_examples: 4831 - classes: 5\n",
            "Epoch 1/3 - 1.38s - loss: 884.22864 - acc: 0.4609986 - batches: 604\n",
            "Epoch 2/3 - 1.09s - loss: 883.5244 - acc: 0.46224236 - batches: 604\n",
            "Epoch 3/3 - 1.04s - loss: 883.5244 - acc: 0.46224236 - batches: 604\n",
            "CPU times: user 165 ms, sys: 62 ms, total: 227 ms\n",
            "Wall time: 1min 41s\n"
          ]
        }
      ],
      "source": [
        "%%time \n",
        "use_pipelineModel = use_clf_pipeline.fit(trainingData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZTuse48tTI1",
        "outputId": "76f51fa7-ac48-4e04-a9c5-eda229c51c02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['ClassifierDLApproach_53d031fb416b.log']"
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "log_files = os.listdir(\"/root/annotator_logs\")\n",
        "log_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sYhRd-Ds4Sj",
        "outputId": "1dafd807-f3a3-4721-9b08-fbca0f4df35f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training started - epochs: 3 - learning_rate: 0.01 - batch_size: 8 - training_examples: 4831 - classes: 5\n",
            "Epoch 0/3 - 1.38s - loss: 884.22864 - acc: 0.4609986 - batches: 604\n",
            "Epoch 1/3 - 1.09s - loss: 883.5244 - acc: 0.46224236 - batches: 604\n",
            "Epoch 2/3 - 1.04s - loss: 883.5244 - acc: 0.46224236 - batches: 604\n",
            "\n"
          ]
        }
      ],
      "source": [
        "with open(\"/root/annotator_logs/\"+log_files[0], \"r\") as log_file :\n",
        "    print(log_file.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-11-21 03:45:10.650754: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-21 03:45:10.653240: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-21 03:45:10.655734: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-21 03:45:10.656934: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-21 03:45:10.658028: I external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-21 03:45:10.659229: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 70502 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:00:05.0, compute capability: 8.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "preds = use_pipelineModel.transform(testData)\n",
        "\n",
        "preds_df = preds.select('stars','text',\"class.result\").toPandas()\n",
        "\n",
        "preds_df['result'] = preds_df['result'].apply(lambda x : x[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.00      0.00      0.00       333\n",
            "         2.0       0.00      0.00      0.00       163\n",
            "         3.0       0.00      0.00      0.00       205\n",
            "         4.0       0.00      0.00      0.00       467\n",
            "         5.0       0.44      1.00      0.62       933\n",
            "\n",
            "    accuracy                           0.44      2101\n",
            "   macro avg       0.09      0.20      0.12      2101\n",
            "weighted avg       0.20      0.44      0.27      2101\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "print (classification_report(preds_df['stars'], preds_df['result'].astype(float)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9tXlaLYpwdG"
      },
      "source": [
        "## Getting prediction from Trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iNERYucrncR5"
      },
      "outputs": [],
      "source": [
        "from sparknlp.base import LightPipeline\n",
        "\n",
        "light_model = LightPipeline(use_pipelineModel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WBztNjY14FKn",
        "outputId": "95732565-8842-487d-818a-5a9aa12df027"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Row(text='A country town feel inside of New Jersey? Go figure! A gift shop full of knick knacs that your paddywhack cousins adorn their walls with at home. A solid breakfast menu that is perfect for a quick stop or a take out on the go. Enjoyed the service and the escape.'),\n",
              " Row(text='Avoid.  The owners are laughing at you.  Didn\\'t want to wait 45 min for The Boardwalk Grill,  the Hut was playing loud, poorly covered music, so we dropped into Scully\\'s - despite the foul water smell outside.  Service was fine, but all aspects of the food were bad.  Just bad...no heart in this menu at all.   I could get better, fresher seafood in Des Moines for the same price.  \"Battered fish\" in the F & C we\\'re frozen, not fresh & not good.  Fries were cold, though 75% of the menu is fried.  Like Long John Silver\\'s, but without the flavor.')]"
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testData.select('text').take(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lDlkv_Af4Ie8",
        "outputId": "a6248e23-3f50-40c2-eceb-3f15103c9dcc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['5.0']"
            ]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text='''\n",
        "Disgusting and ugly place. Won't come back ever. \n",
        "'''\n",
        "result = light_model.annotate(text)\n",
        "\n",
        "result['class']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "u3OTJAYq4MwR",
        "outputId": "66f04048-1abc-4341-b0b6-cb0a7d475e2e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'document': ['the soccer games will be postponed.'],\n",
              " 'sentence_embeddings': ['the soccer games will be postponed.'],\n",
              " 'class': ['5.0']}"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "light_model.annotate('the soccer games will be postponed.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xN9YozVEw14g"
      },
      "source": [
        "## Saving & loading back the trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hKkC3gtfvLkP",
        "outputId": "53e807f3-0ac7-4fb8-ad8a-23c02dc90ff1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ClassifierDLModel_2b9a9179f5ce"
            ]
          },
          "execution_count": 150,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "use_pipelineModel.stages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vfL95dDGu8i_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: metadata/ (stored 0%)\n",
            "  adding: metadata/part-00000 (deflated 21%)\n",
            "  adding: metadata/.part-00000.crc (stored 0%)\n",
            "  adding: metadata/_SUCCESS (stored 0%)\n",
            "  adding: metadata/._SUCCESS.crc (stored 0%)\n",
            "  adding: stages/ (stored 0%)\n",
            "  adding: stages/2_ClassifierDLModel_2b9a9179f5ce/ (stored 0%)\n",
            "  adding: stages/2_ClassifierDLModel_2b9a9179f5ce/metadata/ (stored 0%)\n",
            "  adding: stages/2_ClassifierDLModel_2b9a9179f5ce/metadata/part-00000 (deflated 37%)\n",
            "  adding: stages/2_ClassifierDLModel_2b9a9179f5ce/metadata/.part-00000.crc (stored 0%)\n",
            "  adding: stages/2_ClassifierDLModel_2b9a9179f5ce/metadata/_SUCCESS (stored 0%)\n",
            "  adding: stages/2_ClassifierDLModel_2b9a9179f5ce/metadata/._SUCCESS.crc (stored 0%)\n",
            "  adding: stages/2_ClassifierDLModel_2b9a9179f5ce/fields/ (stored 0%)\n",
            "  adding: stages/2_ClassifierDLModel_2b9a9179f5ce/fields/datasetParams/ (stored 0%)\n",
            "  adding: stages/2_ClassifierDLModel_2b9a9179f5ce/fields/datasetParams/part-00005 (deflated 26%)\n",
            "  adding: stages/2_ClassifierDLModel_2b9a9179f5ce/fields/datasetParams/part-00000 (deflated 27%)\n",
            "  adding: stages/2_ClassifierDLModel_2b9a9179f5ce/fields/datasetParams/.part-00000.crc (stored 0%)\n",
            "  adding: stages/2_ClassifierDLModel_2b9a9179f5ce/fields/datasetParams/part-00008 (deflated 27%)\n",
            "  adding: stages/2_ClassifierDLModel_2b9a9179f5ce/fields/datasetParams/part-00004 (deflated 26%)\n",
            "  adding: stages/2_ClassifierDLModel_2b9a9179f5ce/fields/datasetParams/.part-00007.crc (stored 0%)\n",
            "  adding: stages/2_ClassifierDLModel_2b9a9179f5ce/fields/datasetParams/.part-00001.crc (stored 0%)\n",
            "  adding: stages/2_ClassifierDLModel_2b9a9179f5ce/fields/datasetParams/part-00006 (deflated 26%)\n",
            "  adding: stages/2_ClassifierDLModel_2b9a9179f5ce/fields/datasetParams/.part-00005.crc (stored 0%)\n",
            "  adding: stages/2_ClassifierDLModel_2b9a9179f5ce/fields/datasetParams/.part-00008.crc (stored 0%)\n",
            "  adding: stages/2_ClassifierDLModel_2b9a9179f5ce/fields/datasetParams/.part-00009.crc (stored 0%)\n",
            "  adding: stages/2_ClassifierDLModel_2b9a9179f5ce/fields/datasetParams/part-00009 (deflated 32%)\n",
            "  adding: stages/2_ClassifierDLModel_2b9a9179f5ce/fields/datasetParams/part-00007 (deflated 27%)\n",
            "  adding: stages/2_ClassifierDLModel_2b9a9179f5ce/fields/datasetParams/_SUCCESS (stored 0%)\n",
            "  adding: stages/2_ClassifierDLModel_2b9a9179f5ce/fields/datasetParams/.part-00003.crc (stored 0%)\n",
            "  adding: stages/2_ClassifierDLModel_2b9a9179f5ce/fields/datasetParams/part-00003 (deflated 27%)\n",
            "  adding: stages/2_ClassifierDLModel_2b9a9179f5ce/fields/datasetParams/part-00001 (deflated 27%)\n",
            "  adding: stages/2_ClassifierDLModel_2b9a9179f5ce/fields/datasetParams/.part-00002.crc (stored 0%)\n",
            "  adding: stages/2_ClassifierDLModel_2b9a9179f5ce/fields/datasetParams/.part-00004.crc (stored 0%)\n",
            "  adding: stages/2_ClassifierDLModel_2b9a9179f5ce/fields/datasetParams/._SUCCESS.crc (stored 0%)\n",
            "  adding: stages/2_ClassifierDLModel_2b9a9179f5ce/fields/datasetParams/.part-00006.crc (stored 0%)\n",
            "  adding: stages/2_ClassifierDLModel_2b9a9179f5ce/fields/datasetParams/part-00002 (deflated 27%)\n",
            "  adding: stages/2_ClassifierDLModel_2b9a9179f5ce/classifierdl_tensorflow (deflated 65%)\n",
            "  adding: stages/2_ClassifierDLModel_2b9a9179f5ce/.classifierdl_tensorflow.crc (deflated 51%)\n",
            "  adding: stages/0_DocumentAssembler_6e2ecc69406b/ (stored 0%)\n",
            "  adding: stages/0_DocumentAssembler_6e2ecc69406b/metadata/ (stored 0%)\n",
            "  adding: stages/0_DocumentAssembler_6e2ecc69406b/metadata/part-00000 (deflated 33%)\n",
            "  adding: stages/0_DocumentAssembler_6e2ecc69406b/metadata/.part-00000.crc (stored 0%)\n",
            "  adding: stages/0_DocumentAssembler_6e2ecc69406b/metadata/_SUCCESS (stored 0%)\n",
            "  adding: stages/0_DocumentAssembler_6e2ecc69406b/metadata/._SUCCESS.crc (stored 0%)\n",
            "  adding: stages/1_UNIVERSAL_SENTENCE_ENCODER_5e0d8b922c74/ (stored 0%)\n",
            "  adding: stages/1_UNIVERSAL_SENTENCE_ENCODER_5e0d8b922c74/metadata/ (stored 0%)\n",
            "  adding: stages/1_UNIVERSAL_SENTENCE_ENCODER_5e0d8b922c74/metadata/part-00000 (deflated 30%)\n",
            "  adding: stages/1_UNIVERSAL_SENTENCE_ENCODER_5e0d8b922c74/metadata/.part-00000.crc (stored 0%)\n",
            "  adding: stages/1_UNIVERSAL_SENTENCE_ENCODER_5e0d8b922c74/metadata/_SUCCESS (stored 0%)\n",
            "  adding: stages/1_UNIVERSAL_SENTENCE_ENCODER_5e0d8b922c74/metadata/._SUCCESS.crc (stored 0%)\n",
            "  adding: stages/1_UNIVERSAL_SENTENCE_ENCODER_5e0d8b922c74/use_tensorflow (deflated 8%)\n",
            "  adding: stages/1_UNIVERSAL_SENTENCE_ENCODER_5e0d8b922c74/.use_tensorflow.crc (deflated 0%)\n"
          ]
        }
      ],
      "source": [
        "# Save a Spark NLP pipeline\n",
        "use_pipelineModel.save('MyModel1')\n",
        "\n",
        "# cd into saved dir and zip\n",
        "! cd ./MyModel1 ; zip -r MyModel1.zip *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#docs_infra: no_execute\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
