{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordcloud\n",
      "  Downloading wordcloud-1.8.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (458 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m458.6/458.6 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.9/dist-packages (from wordcloud) (1.23.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from wordcloud) (3.5.2)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from wordcloud) (9.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud) (4.34.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud) (1.4.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.14.0)\n",
      "Installing collected packages: wordcloud\n",
      "Successfully installed wordcloud-1.8.2.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.7)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk) (4.64.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting spacy-streamlit\n",
      "  Downloading spacy_streamlit-1.0.4-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: spacy<4.0.0,>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy-streamlit) (3.4.3)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from spacy-streamlit) (1.4.3)\n",
      "Collecting streamlit>=0.86.0\n",
      "  Downloading streamlit-1.15.0-py2.py3-none-any.whl (9.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-streamlit) (3.1.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-streamlit) (0.9.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-streamlit) (3.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-streamlit) (2.0.6)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-streamlit) (1.0.2)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-streamlit) (0.4.2)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-streamlit) (8.1.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-streamlit) (0.6.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-streamlit) (3.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-streamlit) (4.64.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-streamlit) (63.1.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-streamlit) (1.0.7)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-streamlit) (2.4.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-streamlit) (3.0.10)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-streamlit) (1.23.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-streamlit) (1.9.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-streamlit) (2.0.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-streamlit) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-streamlit) (21.3)\n",
      "Collecting validators>=0.2\n",
      "  Downloading validators-0.20.0.tar.gz (30 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting semver\n",
      "  Downloading semver-3.0.0.dev3-py3-none-any.whl (16 kB)\n",
      "Collecting pydeck>=0.1.dev5\n",
      "  Downloading pydeck-0.8.0-py2.py3-none-any.whl (4.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.9/dist-packages (from streamlit>=0.86.0->spacy-streamlit) (6.2)\n",
      "Collecting pympler>=0.9\n",
      "  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.9/dist-packages (from streamlit>=0.86.0->spacy-streamlit) (8.1.3)\n",
      "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.9/dist-packages (from streamlit>=0.86.0->spacy-streamlit) (5.2.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from streamlit>=0.86.0->spacy-streamlit) (9.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.9/dist-packages (from streamlit>=0.86.0->spacy-streamlit) (4.12.0)\n",
      "Collecting altair>=3.2.0\n",
      "  Downloading altair-4.2.0-py3-none-any.whl (812 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.8/812.8 kB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting toml\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting watchdog\n",
      "  Downloading watchdog-2.1.9-py3-none-manylinux2014_x86_64.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting blinker>=1.0.0\n",
      "  Downloading blinker-1.5-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: pyarrow>=4.0 in /usr/local/lib/python3.9/dist-packages (from streamlit>=0.86.0->spacy-streamlit) (8.0.0)\n",
      "Collecting rich>=10.11.0\n",
      "  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.5/237.5 kB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19 in /usr/local/lib/python3.9/dist-packages (from streamlit>=0.86.0->spacy-streamlit) (3.1.27)\n",
      "Collecting tzlocal>=1.1\n",
      "  Downloading tzlocal-4.2-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: protobuf<4,>=3.12 in /usr/local/lib/python3.9/dist-packages (from streamlit>=0.86.0->spacy-streamlit) (3.19.4)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/dist-packages (from streamlit>=0.86.0->spacy-streamlit) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.9/dist-packages (from streamlit>=0.86.0->spacy-streamlit) (4.3.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->spacy-streamlit) (2022.1)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.9/dist-packages (from altair>=3.2.0->streamlit>=0.86.0->spacy-streamlit) (0.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.9/dist-packages (from altair>=3.2.0->streamlit>=0.86.0->spacy-streamlit) (4.7.2)\n",
      "Collecting toolz\n",
      "  Downloading toolz-0.12.0-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from gitpython!=3.1.19->streamlit>=0.86.0->spacy-streamlit) (4.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=1.4->streamlit>=0.86.0->spacy-streamlit) (3.8.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from packaging>=20.0->spacy<4.0.0,>=3.0.0->spacy-streamlit) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from pathy>=0.3.5->spacy<4.0.0,>=3.0.0->spacy-streamlit) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<4.0.0,>=3.0.0->spacy-streamlit) (2.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil->streamlit>=0.86.0->spacy-streamlit) (1.14.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-streamlit) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-streamlit) (1.26.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-streamlit) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-streamlit) (2.8)\n",
      "Collecting commonmark<0.10.0,>=0.9.0\n",
      "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.9/dist-packages (from rich>=10.11.0->streamlit>=0.86.0->spacy-streamlit) (2.12.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4.0.0,>=3.0.0->spacy-streamlit) (0.7.8)\n",
      "Collecting pytz-deprecation-shim\n",
      "  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.9/dist-packages (from validators>=0.2->streamlit>=0.86.0->spacy-streamlit) (5.1.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit>=0.86.0->spacy-streamlit) (5.0.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit>=0.86.0->spacy-streamlit) (0.18.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit>=0.86.0->spacy-streamlit) (18.2.0)\n",
      "Collecting tzdata\n",
      "  Downloading tzdata-2022.6-py2.py3-none-any.whl (338 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m338.8/338.8 kB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: validators\n",
      "  Building wheel for validators (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19580 sha256=fed044a59ec010ba7c783e965e61ab16e74f957c6ed3eb565151dd70ff4155d1\n",
      "  Stored in directory: /root/.cache/pip/wheels/2d/f0/a8/1094fca7a7e5d0d12ff56e0c64675d72aa5cc81a5fc200e849\n",
      "Successfully built validators\n",
      "Installing collected packages: commonmark, watchdog, validators, tzdata, toolz, toml, semver, rich, pympler, blinker, pytz-deprecation-shim, pydeck, tzlocal, altair, streamlit, spacy-streamlit\n",
      "Successfully installed altair-4.2.0 blinker-1.5 commonmark-0.9.1 pydeck-0.8.0 pympler-1.0.1 pytz-deprecation-shim-0.1.0.post0 rich-12.6.0 semver-3.0.0.dev3 spacy-streamlit-1.0.4 streamlit-1.15.0 toml-0.10.2 toolz-0.12.0 tzdata-2022.6 tzlocal-4.2 validators-0.20.0 watchdog-2.1.9\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting en-core-web-lg==3.4.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.4.1/en_core_web_lg-3.4.1-py3-none-any.whl (587.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.9/dist-packages (from en-core-web-lg==3.4.1) (3.4.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.0.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.1.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.0.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.4.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.23.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.28.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.3.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.0.7)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (8.1.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.9.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (4.64.0)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (21.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.9.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.6.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (63.1.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.0.10)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.0.7)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (4.3.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.26.10)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2019.11.28)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.7.8)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.1.1)\n",
      "Installing collected packages: en-core-web-lg\n",
      "Successfully installed en-core-web-lg-3.4.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "#### SETTING CUDA SUPPORT FOR SPACY\n",
    "!pip install -U 'spacy[cuda-autodetect,transformers,lookups]'\n",
    "\n",
    "#### CHECKING CUDA SUPPORT AND VERSION\n",
    "#import torch\n",
    "#torch.cuda.is_available()\n",
    "#!nvcc --version\n",
    "#import cupy\n",
    "#cupy.show_config()\n",
    "#import spacy\n",
    "#spacy.require_gpu()\n",
    "\n",
    "##### INSTALLATION OF THE REST OF LIBRARIES FOR NLP\n",
    "!pip install wordcloud\n",
    "!pip install nltk\n",
    "!pip install spacy-streamlit --pre\n",
    "!python -m spacy download en_core_web_lg\n",
    "#!python -m spacy init fill-config ./configs/base_config.cfg ./configs/config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting findspark\n",
      "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: findspark\n",
      "Successfully installed findspark-2.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Get:1 https://deb.nodesource.com/node_16.x focal InRelease [4583 B]\n",
      "Get:2 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]      \u001b[0m\u001b[33m\n",
      "Get:3 http://archive.ubuntu.com/ubuntu focal InRelease [265 kB]                \u001b[0m\n",
      "Get:4 https://deb.nodesource.com/node_16.x focal/main amd64 Packages [774 B]   \u001b[0m\u001b[33m\n",
      "Get:5 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease [18.1 kB] \u001b[0m\u001b[33m\n",
      "Get:6 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 Packages [29.5 kB]\u001b[33m\u001b[33m\u001b[33m\u001b[33m\n",
      "Get:7 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [1712 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]        \u001b[0m\n",
      "Get:9 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]     \u001b[0m\u001b[33mm\n",
      "Get:10 http://archive.ubuntu.com/ubuntu focal/universe amd64 Packages [11.3 MB]\n",
      "Get:11 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [965 kB]\n",
      "Get:12 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [27.5 kB]\n",
      "Get:13 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2312 kB]33m\n",
      "Get:14 http://archive.ubuntu.com/ubuntu focal/multiverse amd64 Packages [177 kB][0m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\n",
      "Get:15 http://archive.ubuntu.com/ubuntu focal/restricted amd64 Packages [33.4 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu focal/main amd64 Packages [1275 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [30.2 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1262 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [2781 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [1829 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu focal-backports/main amd64 Packages [84.3 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu focal-backports/universe amd64 Packages [31.5 kB]\n",
      "Fetched 24.5 MB in 2s (10.7 MB/s)[33m                        \u001b[0m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "102 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  ca-certificates-java fonts-dejavu-extra java-common libatk-wrapper-java\n",
      "  libatk-wrapper-java-jni libfontenc1 libice-dev libnspr4 libnss3 libpcsclite1\n",
      "  libpthread-stubs0-dev libsm-dev libx11-dev libxau-dev libxcb1-dev\n",
      "  libxdmcp-dev libxkbfile1 libxmuu1 libxt-dev libxtst6 libxxf86dga1\n",
      "  openjdk-17-jdk-headless openjdk-17-jre openjdk-17-jre-headless x11-utils\n",
      "  x11proto-core-dev x11proto-dev xorg-sgml-doctools xtrans-dev\n",
      "Suggested packages:\n",
      "  default-jre libice-doc pcscd libsm-doc libx11-doc libxcb-doc libxt-doc\n",
      "  openjdk-17-demo openjdk-17-source visualvm libnss-mdns fonts-ipafont-gothic\n",
      "  fonts-ipafont-mincho fonts-wqy-microhei | fonts-wqy-zenhei fonts-indic\n",
      "  mesa-utils\n",
      "The following NEW packages will be installed:\n",
      "  ca-certificates-java fonts-dejavu-extra java-common libatk-wrapper-java\n",
      "  libatk-wrapper-java-jni libfontenc1 libice-dev libnspr4 libnss3 libpcsclite1\n",
      "  libpthread-stubs0-dev libsm-dev libx11-dev libxau-dev libxcb1-dev\n",
      "  libxdmcp-dev libxkbfile1 libxmuu1 libxt-dev libxtst6 libxxf86dga1\n",
      "  openjdk-17-jdk openjdk-17-jdk-headless openjdk-17-jre\n",
      "  openjdk-17-jre-headless x11-utils x11proto-core-dev x11proto-dev\n",
      "  xorg-sgml-doctools xtrans-dev\n",
      "0 upgraded, 30 newly installed, 0 to remove and 102 not upgraded.\n",
      "Need to get 292 MB of archives.\n",
      "After this operation, 466 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu focal/main amd64 libxmuu1 amd64 2:1.1.3-0ubuntu1 [9728 B]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu focal/main amd64 java-common all 0.72 [6816 B]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu focal/main amd64 libnspr4 amd64 2:4.25-1 [107 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libnss3 amd64 2:3.49.1-1ubuntu1.8 [1256 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu focal/main amd64 libpcsclite1 amd64 1.8.26-3 [22.0 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 openjdk-17-jre-headless amd64 17.0.5+8-2ubuntu1~20.04 [43.6 MB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu focal/main amd64 ca-certificates-java all 20190405ubuntu1 [12.2 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu focal/main amd64 fonts-dejavu-extra all 2.37-1 [1953 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu focal/main amd64 libfontenc1 amd64 1:1.1.4-0ubuntu1 [14.0 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu focal/main amd64 libxkbfile1 amd64 1:1.1.0-1 [65.3 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu focal/main amd64 libxtst6 amd64 2:1.2.3-1 [12.8 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu focal/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu1 [12.0 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu focal/main amd64 x11-utils amd64 7.7+5 [199 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu focal/main amd64 libatk-wrapper-java all 0.37.1-1 [53.0 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu focal/main amd64 libatk-wrapper-java-jni amd64 0.37.1-1 [45.1 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu focal/main amd64 xorg-sgml-doctools all 1:1.11-1 [12.9 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu focal/main amd64 x11proto-dev all 2019.2-1ubuntu1 [594 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu focal/main amd64 x11proto-core-dev all 2019.2-1ubuntu1 [2620 B]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu focal/main amd64 libice-dev amd64 2:1.0.10-0ubuntu1 [47.8 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu focal/main amd64 libpthread-stubs0-dev amd64 0.4-1 [5384 B]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu focal/main amd64 libsm-dev amd64 2:1.2.3-1 [17.0 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu focal/main amd64 libxau-dev amd64 1:1.0.9-0ubuntu1 [9552 B]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu focal/main amd64 libxdmcp-dev amd64 1:1.1.3-0ubuntu1 [25.3 kB]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu focal/main amd64 xtrans-dev all 1.4.0-1 [68.9 kB]\n",
      "Get:25 http://archive.ubuntu.com/ubuntu focal/main amd64 libxcb1-dev amd64 1.14-2 [80.5 kB]\n",
      "Get:26 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libx11-dev amd64 2:1.6.9-2ubuntu1.2 [647 kB]\n",
      "Get:27 http://archive.ubuntu.com/ubuntu focal/main amd64 libxt-dev amd64 1:1.1.5-1 [395 kB]\n",
      "Get:28 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 openjdk-17-jre amd64 17.0.5+8-2ubuntu1~20.04 [166 kB]\n",
      "Get:29 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 openjdk-17-jdk-headless amd64 17.0.5+8-2ubuntu1~20.04 [243 MB]\n",
      "Get:30 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 openjdk-17-jdk amd64 17.0.5+8-2ubuntu1~20.04 [10.5 kB]\n",
      "Fetched 292 MB in 9s (34.3 MB/s)                                               \u001b[0m\u001b[33m\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package libxmuu1:amd64.\n",
      "(Reading database ... 78556 files and directories currently installed.)\n",
      "Preparing to unpack .../00-libxmuu1_2%3a1.1.3-0ubuntu1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8Unpacking libxmuu1:amd64 (2:1.1.3-0ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  2%]\u001b[49m\u001b[39m [..........................................................] \u001b8Selecting previously unselected package java-common.\n",
      "Preparing to unpack .../01-java-common_0.72_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  2%]\u001b[49m\u001b[39m [#.........................................................] \u001b8Unpacking java-common (0.72) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  3%]\u001b[49m\u001b[39m [#.........................................................] \u001b8Selecting previously unselected package libnspr4:amd64.\n",
      "Preparing to unpack .../02-libnspr4_2%3a4.25-1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  4%]\u001b[49m\u001b[39m [##........................................................] \u001b8Unpacking libnspr4:amd64 (2:4.25-1) ...\n",
      "Selecting previously unselected package libnss3:amd64.\n",
      "Preparing to unpack .../03-libnss3_2%3a3.49.1-1ubuntu1.8_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  6%]\u001b[49m\u001b[39m [###.......................................................] \u001b8Unpacking libnss3:amd64 (2:3.49.1-1ubuntu1.8) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  7%]\u001b[49m\u001b[39m [###.......................................................] \u001b8Selecting previously unselected package libpcsclite1:amd64.\n",
      "Preparing to unpack .../04-libpcsclite1_1.8.26-3_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  7%]\u001b[49m\u001b[39m [####......................................................] \u001b8Unpacking libpcsclite1:amd64 (1.8.26-3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  8%]\u001b[49m\u001b[39m [####......................................................] \u001b8Selecting previously unselected package openjdk-17-jre-headless:amd64.\n",
      "Preparing to unpack .../05-openjdk-17-jre-headless_17.0.5+8-2ubuntu1~20.04_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  9%]\u001b[49m\u001b[39m [#####.....................................................] \u001b8Unpacking openjdk-17-jre-headless:amd64 (17.0.5+8-2ubuntu1~20.04) ...\n",
      "Selecting previously unselected package ca-certificates-java.\n",
      "Preparing to unpack .../06-ca-certificates-java_20190405ubuntu1_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 11%]\u001b[49m\u001b[39m [######....................................................] \u001b8Unpacking ca-certificates-java (20190405ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 12%]\u001b[49m\u001b[39m [######....................................................] \u001b8Selecting previously unselected package fonts-dejavu-extra.\n",
      "Preparing to unpack .../07-fonts-dejavu-extra_2.37-1_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 12%]\u001b[49m\u001b[39m [#######...................................................] \u001b8Unpacking fonts-dejavu-extra (2.37-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 13%]\u001b[49m\u001b[39m [#######...................................................] \u001b8Selecting previously unselected package libfontenc1:amd64.\n",
      "Preparing to unpack .../08-libfontenc1_1%3a1.1.4-0ubuntu1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 14%]\u001b[49m\u001b[39m [########..................................................] \u001b8Unpacking libfontenc1:amd64 (1:1.1.4-0ubuntu1) ...\n",
      "Selecting previously unselected package libxkbfile1:amd64.\n",
      "Preparing to unpack .../09-libxkbfile1_1%3a1.1.0-1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 16%]\u001b[49m\u001b[39m [#########.................................................] \u001b8Unpacking libxkbfile1:amd64 (1:1.1.0-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 17%]\u001b[49m\u001b[39m [#########.................................................] \u001b8Selecting previously unselected package libxtst6:amd64.\n",
      "Preparing to unpack .../10-libxtst6_2%3a1.2.3-1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 17%]\u001b[49m\u001b[39m [##########................................................] \u001b8Unpacking libxtst6:amd64 (2:1.2.3-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 18%]\u001b[49m\u001b[39m [##########................................................] \u001b8Selecting previously unselected package libxxf86dga1:amd64.\n",
      "Preparing to unpack .../11-libxxf86dga1_2%3a1.1.5-0ubuntu1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 19%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu1) ...\n",
      "Selecting previously unselected package x11-utils.\n",
      "Preparing to unpack .../12-x11-utils_7.7+5_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 21%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Unpacking x11-utils (7.7+5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 21%]\u001b[49m\u001b[39m [############..............................................] \u001b8Selecting previously unselected package libatk-wrapper-java.\n",
      "Preparing to unpack .../13-libatk-wrapper-java_0.37.1-1_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 22%]\u001b[49m\u001b[39m [############..............................................] \u001b8Unpacking libatk-wrapper-java (0.37.1-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 23%]\u001b[49m\u001b[39m [#############.............................................] \u001b8Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
      "Preparing to unpack .../14-libatk-wrapper-java-jni_0.37.1-1_amd64.deb ...\n",
      "Unpacking libatk-wrapper-java-jni:amd64 (0.37.1-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 25%]\u001b[49m\u001b[39m [##############............................................] \u001b8Selecting previously unselected package xorg-sgml-doctools.\n",
      "Preparing to unpack .../15-xorg-sgml-doctools_1%3a1.11-1_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 26%]\u001b[49m\u001b[39m [##############............................................] \u001b8Unpacking xorg-sgml-doctools (1:1.11-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 26%]\u001b[49m\u001b[39m [###############...........................................] \u001b8Selecting previously unselected package x11proto-dev.\n",
      "Preparing to unpack .../16-x11proto-dev_2019.2-1ubuntu1_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 27%]\u001b[49m\u001b[39m [###############...........................................] \u001b8Unpacking x11proto-dev (2019.2-1ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 28%]\u001b[49m\u001b[39m [################..........................................] \u001b8Selecting previously unselected package x11proto-core-dev.\n",
      "Preparing to unpack .../17-x11proto-core-dev_2019.2-1ubuntu1_all.deb ...\n",
      "Unpacking x11proto-core-dev (2019.2-1ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 30%]\u001b[49m\u001b[39m [#################.........................................] \u001b8Selecting previously unselected package libice-dev:amd64.\n",
      "Preparing to unpack .../18-libice-dev_2%3a1.0.10-0ubuntu1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 31%]\u001b[49m\u001b[39m [#################.........................................] \u001b8Unpacking libice-dev:amd64 (2:1.0.10-0ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 31%]\u001b[49m\u001b[39m [##################........................................] \u001b8Selecting previously unselected package libpthread-stubs0-dev:amd64.\n",
      "Preparing to unpack .../19-libpthread-stubs0-dev_0.4-1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 32%]\u001b[49m\u001b[39m [##################........................................] \u001b8Unpacking libpthread-stubs0-dev:amd64 (0.4-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 33%]\u001b[49m\u001b[39m [###################.......................................] \u001b8Selecting previously unselected package libsm-dev:amd64.\n",
      "Preparing to unpack .../20-libsm-dev_2%3a1.2.3-1_amd64.deb ...\n",
      "Unpacking libsm-dev:amd64 (2:1.2.3-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 35%]\u001b[49m\u001b[39m [####################......................................] \u001b8Selecting previously unselected package libxau-dev:amd64.\n",
      "Preparing to unpack .../21-libxau-dev_1%3a1.0.9-0ubuntu1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 36%]\u001b[49m\u001b[39m [####################......................................] \u001b8Unpacking libxau-dev:amd64 (1:1.0.9-0ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 36%]\u001b[49m\u001b[39m [#####################.....................................] \u001b8Selecting previously unselected package libxdmcp-dev:amd64.\n",
      "Preparing to unpack .../22-libxdmcp-dev_1%3a1.1.3-0ubuntu1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 37%]\u001b[49m\u001b[39m [#####################.....................................] \u001b8Unpacking libxdmcp-dev:amd64 (1:1.1.3-0ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 38%]\u001b[49m\u001b[39m [######################....................................] \u001b8Selecting previously unselected package xtrans-dev.\n",
      "Preparing to unpack .../23-xtrans-dev_1.4.0-1_all.deb ...\n",
      "Unpacking xtrans-dev (1.4.0-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 40%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Selecting previously unselected package libxcb1-dev:amd64.\n",
      "Preparing to unpack .../24-libxcb1-dev_1.14-2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 40%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Unpacking libxcb1-dev:amd64 (1.14-2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 41%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Selecting previously unselected package libx11-dev:amd64.\n",
      "Preparing to unpack .../25-libx11-dev_2%3a1.6.9-2ubuntu1.2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 42%]\u001b[49m\u001b[39m [########################..................................] \u001b8Unpacking libx11-dev:amd64 (2:1.6.9-2ubuntu1.2) ...\n",
      "Selecting previously unselected package libxt-dev:amd64.\n",
      "Preparing to unpack .../26-libxt-dev_1%3a1.1.5-1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 44%]\u001b[49m\u001b[39m [#########################.................................] \u001b8Unpacking libxt-dev:amd64 (1:1.1.5-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 45%]\u001b[49m\u001b[39m [#########################.................................] \u001b8Selecting previously unselected package openjdk-17-jre:amd64.\n",
      "Preparing to unpack .../27-openjdk-17-jre_17.0.5+8-2ubuntu1~20.04_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 45%]\u001b[49m\u001b[39m [##########################................................] \u001b8Unpacking openjdk-17-jre:amd64 (17.0.5+8-2ubuntu1~20.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 46%]\u001b[49m\u001b[39m [##########################................................] \u001b8Selecting previously unselected package openjdk-17-jdk-headless:amd64.\n",
      "Preparing to unpack .../28-openjdk-17-jdk-headless_17.0.5+8-2ubuntu1~20.04_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 47%]\u001b[49m\u001b[39m [###########################...............................] \u001b8Unpacking openjdk-17-jdk-headless:amd64 (17.0.5+8-2ubuntu1~20.04) ...\n",
      "Selecting previously unselected package openjdk-17-jdk:amd64.\n",
      "Preparing to unpack .../29-openjdk-17-jdk_17.0.5+8-2ubuntu1~20.04_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 49%]\u001b[49m\u001b[39m [############################..............................] \u001b8Unpacking openjdk-17-jdk:amd64 (17.0.5+8-2ubuntu1~20.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 50%]\u001b[49m\u001b[39m [############################..............................] \u001b8Setting up java-common (0.72) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 50%]\u001b[49m\u001b[39m [#############################.............................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 51%]\u001b[49m\u001b[39m [#############################.............................] \u001b8Setting up libxtst6:amd64 (2:1.2.3-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 52%]\u001b[49m\u001b[39m [##############################............................] \u001b8Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 54%]\u001b[49m\u001b[39m [###############################...........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 55%]\u001b[49m\u001b[39m [###############################...........................] \u001b8Setting up libpthread-stubs0-dev:amd64 (0.4-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 55%]\u001b[49m\u001b[39m [################################..........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 56%]\u001b[49m\u001b[39m [################################..........................] \u001b8Setting up xtrans-dev (1.4.0-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 57%]\u001b[49m\u001b[39m [#################################.........................] \u001b8Setting up libfontenc1:amd64 (1:1.1.4-0ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 59%]\u001b[49m\u001b[39m [##################################........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 60%]\u001b[49m\u001b[39m [##################################........................] \u001b8Setting up libnspr4:amd64 (2:4.25-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 60%]\u001b[49m\u001b[39m [##################################........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 61%]\u001b[49m\u001b[39m [###################################.......................] \u001b8Setting up libpcsclite1:amd64 (1.8.26-3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 63%]\u001b[49m\u001b[39m [####################################......................] \u001b8Setting up fonts-dejavu-extra (2.37-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 64%]\u001b[49m\u001b[39m [####################################......................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 64%]\u001b[49m\u001b[39m [#####################################.....................] \u001b8Setting up xorg-sgml-doctools (1:1.11-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 65%]\u001b[49m\u001b[39m [#####################################.....................] \u001b8Setting up libxkbfile1:amd64 (1:1.1.0-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 66%]\u001b[49m\u001b[39m [######################################....................] \u001b8Setting up libxmuu1:amd64 (2:1.1.3-0ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 68%]\u001b[49m\u001b[39m [#######################################...................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 69%]\u001b[49m\u001b[39m [#######################################...................] \u001b8Setting up libnss3:amd64 (2:3.49.1-1ubuntu1.8) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 69%]\u001b[49m\u001b[39m [########################################..................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 70%]\u001b[49m\u001b[39m [########################################..................] \u001b8Setting up x11-utils (7.7+5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 71%]\u001b[49m\u001b[39m [#########################################.................] \u001b8Setting up libatk-wrapper-java (0.37.1-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 73%]\u001b[49m\u001b[39m [##########################################................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 74%]\u001b[49m\u001b[39m [##########################################................] \u001b8Setting up libatk-wrapper-java-jni:amd64 (0.37.1-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 74%]\u001b[49m\u001b[39m [###########################################...............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 75%]\u001b[49m\u001b[39m [###########################################...............] \u001b8Setting up openjdk-17-jre-headless:amd64 (17.0.5+8-2ubuntu1~20.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 76%]\u001b[49m\u001b[39m [############################################..............] \u001b8update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/java to provide /usr/bin/java (java) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jpackage to provide /usr/bin/jpackage (jpackage) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/keytool to provide /usr/bin/keytool (keytool) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/rmiregistry to provide /usr/bin/rmiregistry (rmiregistry) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/lib/jexec to provide /usr/bin/jexec (jexec) in auto mode\n",
      "Setting up ca-certificates-java (20190405ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 78%]\u001b[49m\u001b[39m [#############################################.............] \u001b8head: cannot open '/etc/ssl/certs/java/cacerts' for reading: No such file or directory\n",
      "Adding debian:Autoridad_de_Certificacion_Firmaprofesional_CIF_A62634068.pem\n",
      "Adding debian:Trustwave_Global_ECC_P256_Certification_Authority.pem\n",
      "Adding debian:GTS_Root_R2.pem\n",
      "Adding debian:Starfield_Root_Certificate_Authority_-_G2.pem\n",
      "Adding debian:Hellenic_Academic_and_Research_Institutions_ECC_RootCA_2015.pem\n",
      "Adding debian:Certigna_Root_CA.pem\n",
      "Adding debian:CA_Disig_Root_R2.pem\n",
      "Adding debian:AC_RAIZ_FNMT-RCM.pem\n",
      "Adding debian:SwissSign_Gold_CA_-_G2.pem\n",
      "Adding debian:emSign_ECC_Root_CA_-_G3.pem\n",
      "Adding debian:GlobalSign_ECC_Root_CA_-_R4.pem\n",
      "Adding debian:NetLock_Arany_=Class_Gold=_Főtanúsítvány.pem\n",
      "Adding debian:certSIGN_ROOT_CA.pem\n",
      "Adding debian:TrustCor_RootCert_CA-1.pem\n",
      "Adding debian:SecureSign_RootCA11.pem\n",
      "Adding debian:Amazon_Root_CA_2.pem\n",
      "Adding debian:GlobalSign_Root_CA_-_R6.pem\n",
      "Adding debian:DigiCert_Trusted_Root_G4.pem\n",
      "Adding debian:Hellenic_Academic_and_Research_Institutions_RootCA_2011.pem\n",
      "Adding debian:GDCA_TrustAUTH_R5_ROOT.pem\n",
      "Adding debian:COMODO_RSA_Certification_Authority.pem\n",
      "Adding debian:D-TRUST_Root_Class_3_CA_2_2009.pem\n",
      "Adding debian:Certigna.pem\n",
      "Adding debian:ACCVRAIZ1.pem\n",
      "Adding debian:QuoVadis_Root_CA_2_G3.pem\n",
      "Adding debian:Certum_Trusted_Network_CA.pem\n",
      "Adding debian:Go_Daddy_Class_2_CA.pem\n",
      "Adding debian:TeliaSonera_Root_CA_v1.pem\n",
      "Adding debian:Network_Solutions_Certificate_Authority.pem\n",
      "Adding debian:Baltimore_CyberTrust_Root.pem\n",
      "Adding debian:DigiCert_Global_Root_G3.pem\n",
      "Adding debian:T-TeleSec_GlobalRoot_Class_2.pem\n",
      "Adding debian:AffirmTrust_Premium_ECC.pem\n",
      "Adding debian:GlobalSign_Root_CA.pem\n",
      "Adding debian:EC-ACC.pem\n",
      "Adding debian:GTS_Root_R1.pem\n",
      "Adding debian:GlobalSign_Root_CA_-_R2.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority.pem\n",
      "Adding debian:emSign_Root_CA_-_C1.pem\n",
      "Adding debian:Cybertrust_Global_Root.pem\n",
      "Adding debian:Secure_Global_CA.pem\n",
      "Adding debian:Amazon_Root_CA_4.pem\n",
      "Adding debian:E-Tugra_Certification_Authority.pem\n",
      "Adding debian:NAVER_Global_Root_Certification_Authority.pem\n",
      "Adding debian:ePKI_Root_Certification_Authority.pem\n",
      "Adding debian:Certum_Trusted_Network_CA_2.pem\n",
      "Adding debian:D-TRUST_Root_Class_3_CA_2_EV_2009.pem\n",
      "Adding debian:QuoVadis_Root_CA_3_G3.pem\n",
      "Adding debian:QuoVadis_Root_CA_2.pem\n",
      "Adding debian:TWCA_Root_Certification_Authority.pem\n",
      "Adding debian:COMODO_Certification_Authority.pem\n",
      "Adding debian:emSign_Root_CA_-_G1.pem\n",
      "Adding debian:AffirmTrust_Commercial.pem\n",
      "Adding debian:Buypass_Class_3_Root_CA.pem\n",
      "Adding debian:QuoVadis_Root_CA_1_G3.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority_-_G2.pem\n",
      "Adding debian:DigiCert_Assured_ID_Root_G2.pem\n",
      "Adding debian:TUBITAK_Kamu_SM_SSL_Kok_Sertifikasi_-_Surum_1.pem\n",
      "Adding debian:USERTrust_RSA_Certification_Authority.pem\n",
      "Adding debian:Go_Daddy_Root_Certificate_Authority_-_G2.pem\n",
      "Adding debian:Security_Communication_Root_CA.pem\n",
      "Adding debian:GTS_Root_R3.pem\n",
      "Adding debian:TrustCor_ECA-1.pem\n",
      "Adding debian:QuoVadis_Root_CA_3.pem\n",
      "Adding debian:OISTE_WISeKey_Global_Root_GB_CA.pem\n",
      "Adding debian:IdenTrust_Public_Sector_Root_CA_1.pem\n",
      "Adding debian:SZAFIR_ROOT_CA2.pem\n",
      "Adding debian:IdenTrust_Commercial_Root_CA_1.pem\n",
      "Adding debian:SSL.com_Root_Certification_Authority_RSA.pem\n",
      "Adding debian:Microsoft_RSA_Root_Certificate_Authority_2017.pem\n",
      "Adding debian:ISRG_Root_X1.pem\n",
      "Adding debian:DigiCert_Assured_ID_Root_CA.pem\n",
      "Adding debian:Buypass_Class_2_Root_CA.pem\n",
      "Adding debian:SSL.com_EV_Root_Certification_Authority_ECC.pem\n",
      "Adding debian:SSL.com_Root_Certification_Authority_ECC.pem\n",
      "Adding debian:e-Szigno_Root_CA_2017.pem\n",
      "Adding debian:GlobalSign_ECC_Root_CA_-_R5.pem\n",
      "Adding debian:SSL.com_EV_Root_Certification_Authority_RSA_R2.pem\n",
      "Adding debian:TrustCor_RootCert_CA-2.pem\n",
      "Adding debian:Microsoft_ECC_Root_Certificate_Authority_2017.pem\n",
      "Adding debian:Staat_der_Nederlanden_EV_Root_CA.pem\n",
      "Adding debian:Actalis_Authentication_Root_CA.pem\n",
      "Adding debian:AffirmTrust_Premium.pem\n",
      "Adding debian:T-TeleSec_GlobalRoot_Class_3.pem\n",
      "Adding debian:Hongkong_Post_Root_CA_1.pem\n",
      "Adding debian:Entrust.net_Premium_2048_Secure_Server_CA.pem\n",
      "Adding debian:Hongkong_Post_Root_CA_3.pem\n",
      "Adding debian:AffirmTrust_Networking.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority_-_G4.pem\n",
      "Adding debian:DigiCert_High_Assurance_EV_Root_CA.pem\n",
      "Adding debian:GlobalSign_Root_CA_-_R3.pem\n",
      "Adding debian:Microsec_e-Szigno_Root_CA_2009.pem\n",
      "Adding debian:USERTrust_ECC_Certification_Authority.pem\n",
      "Adding debian:Hellenic_Academic_and_Research_Institutions_RootCA_2015.pem\n",
      "Adding debian:DigiCert_Global_Root_CA.pem\n",
      "Adding debian:Comodo_AAA_Services_root.pem\n",
      "Adding debian:UCA_Extended_Validation_Root.pem\n",
      "Adding debian:Trustwave_Global_ECC_P384_Certification_Authority.pem\n",
      "Adding debian:Izenpe.com.pem\n",
      "Adding debian:Atos_TrustedRoot_2011.pem\n",
      "Adding debian:Starfield_Services_Root_Certificate_Authority_-_G2.pem\n",
      "Adding debian:XRamp_Global_CA_Root.pem\n",
      "Adding debian:Amazon_Root_CA_1.pem\n",
      "Adding debian:Starfield_Class_2_CA.pem\n",
      "Adding debian:GTS_Root_R4.pem\n",
      "Adding debian:CFCA_EV_ROOT.pem\n",
      "Adding debian:OISTE_WISeKey_Global_Root_GC_CA.pem\n",
      "Adding debian:SecureTrust_CA.pem\n",
      "Adding debian:COMODO_ECC_Certification_Authority.pem\n",
      "Adding debian:emSign_ECC_Root_CA_-_C3.pem\n",
      "Adding debian:DigiCert_Assured_ID_Root_G3.pem\n",
      "Adding debian:certSIGN_Root_CA_G2.pem\n",
      "Adding debian:SwissSign_Silver_CA_-_G2.pem\n",
      "Adding debian:Security_Communication_RootCA2.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority_-_EC1.pem\n",
      "Adding debian:TWCA_Global_Root_CA.pem\n",
      "Adding debian:UCA_Global_G2_Root.pem\n",
      "Adding debian:Trustwave_Global_Certification_Authority.pem\n",
      "Adding debian:Amazon_Root_CA_3.pem\n",
      "Adding debian:DigiCert_Global_Root_G2.pem\n",
      "Adding debian:ANF_Secure_Server_Root_CA.pem\n",
      "Adding debian:GLOBALTRUST_2020.pem\n",
      "Adding debian:GlobalSign_Root_R46.pem\n",
      "Adding debian:AC_RAIZ_FNMT-RCM_SERVIDORES_SEGUROS.pem\n",
      "Adding debian:Certum_EC-384_CA.pem\n",
      "Adding debian:Certum_Trusted_Root_CA.pem\n",
      "Adding debian:GlobalSign_Root_E46.pem\n",
      "done.\n",
      "Setting up openjdk-17-jre:amd64 (17.0.5+8-2ubuntu1~20.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 79%]\u001b[49m\u001b[39m [#############################################.............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 79%]\u001b[49m\u001b[39m [##############################################............] \u001b8Setting up openjdk-17-jdk-headless:amd64 (17.0.5+8-2ubuntu1~20.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 80%]\u001b[49m\u001b[39m [##############################################............] \u001b8update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jar to provide /usr/bin/jar (jar) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jarsigner to provide /usr/bin/jarsigner (jarsigner) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javac to provide /usr/bin/javac (javac) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javadoc to provide /usr/bin/javadoc (javadoc) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javap to provide /usr/bin/javap (javap) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jcmd to provide /usr/bin/jcmd (jcmd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdb to provide /usr/bin/jdb (jdb) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdeprscan to provide /usr/bin/jdeprscan (jdeprscan) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdeps to provide /usr/bin/jdeps (jdeps) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jfr to provide /usr/bin/jfr (jfr) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jimage to provide /usr/bin/jimage (jimage) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jinfo to provide /usr/bin/jinfo (jinfo) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jlink to provide /usr/bin/jlink (jlink) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jmap to provide /usr/bin/jmap (jmap) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jmod to provide /usr/bin/jmod (jmod) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jps to provide /usr/bin/jps (jps) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jrunscript to provide /usr/bin/jrunscript (jrunscript) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jshell to provide /usr/bin/jshell (jshell) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstack to provide /usr/bin/jstack (jstack) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstat to provide /usr/bin/jstat (jstat) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstatd to provide /usr/bin/jstatd (jstatd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/serialver to provide /usr/bin/serialver (serialver) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jhsdb to provide /usr/bin/jhsdb (jhsdb) in auto mode\n",
      "Setting up openjdk-17-jdk:amd64 (17.0.5+8-2ubuntu1~20.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 82%]\u001b[49m\u001b[39m [###############################################...........] \u001b8update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 83%]\u001b[49m\u001b[39m [###############################################...........] \u001b8Processing triggers for ca-certificates (20211016~20.04.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 83%]\u001b[49m\u001b[39m [################################################..........] \u001b8Updating certificates in /etc/ssl/certs...\n",
      "0 added, 0 removed; done.\n",
      "Running hooks in /etc/ca-certificates/update.d...\n",
      "\n",
      "done.\n",
      "done.\n",
      "Processing triggers for sgml-base (1.29.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 84%]\u001b[49m\u001b[39m [################################################..........] \u001b8Setting up x11proto-dev (2019.2-1ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 85%]\u001b[49m\u001b[39m [#################################################.........] \u001b8Processing triggers for fontconfig (2.13.1-2ubuntu3) ...\n",
      "Processing triggers for mime-support (3.64ubuntu1) ...\n",
      "Setting up libxau-dev:amd64 (1:1.0.9-0ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 87%]\u001b[49m\u001b[39m [##################################################........] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 88%]\u001b[49m\u001b[39m [##################################################........] \u001b8Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
      "Setting up libice-dev:amd64 (2:1.0.10-0ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 88%]\u001b[49m\u001b[39m [###################################################.......] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 89%]\u001b[49m\u001b[39m [###################################################.......] \u001b8Setting up libsm-dev:amd64 (2:1.2.3-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 90%]\u001b[49m\u001b[39m [####################################################......] \u001b8Processing triggers for libc-bin (2.31-0ubuntu9.7) ...\n",
      "Processing triggers for man-db (2.9.1-1) ...\n",
      "Setting up libxdmcp-dev:amd64 (1:1.1.3-0ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 92%]\u001b[49m\u001b[39m [#####################################################.....] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 93%]\u001b[49m\u001b[39m [#####################################################.....] \u001b8Setting up x11proto-core-dev (2019.2-1ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 93%]\u001b[49m\u001b[39m [######################################################....] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 94%]\u001b[49m\u001b[39m [######################################################....] \u001b8Setting up libxcb1-dev:amd64 (1.14-2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 95%]\u001b[49m\u001b[39m [#######################################################...] \u001b8Setting up libx11-dev:amd64 (2:1.6.9-2ubuntu1.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 97%]\u001b[49m\u001b[39m [########################################################..] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 98%]\u001b[49m\u001b[39m [########################################################..] \u001b8Setting up libxt-dev:amd64 (1:1.1.5-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 98%]\u001b[49m\u001b[39m [#########################################################.] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 99%]\u001b[49m\u001b[39m [#########################################################.] \u001b8\n",
      "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[Jspark-3.3.1-bin-hadoop3/\n",
      "spark-3.3.1-bin-hadoop3/LICENSE\n",
      "spark-3.3.1-bin-hadoop3/NOTICE\n",
      "spark-3.3.1-bin-hadoop3/R/\n",
      "spark-3.3.1-bin-hadoop3/R/lib/\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/DESCRIPTION\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/INDEX\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/Meta/\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/Meta/Rd.rds\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/Meta/features.rds\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/Meta/hsearch.rds\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/Meta/links.rds\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/Meta/nsInfo.rds\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/Meta/package.rds\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/Meta/vignette.rds\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/NAMESPACE\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/R/\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/R/SparkR\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/R/SparkR.rdb\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/R/SparkR.rdx\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/doc/\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/doc/index.html\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/doc/sparkr-vignettes.R\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/doc/sparkr-vignettes.Rmd\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/doc/sparkr-vignettes.html\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/help/\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/help/AnIndex\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/help/SparkR.rdb\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/help/SparkR.rdx\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/help/aliases.rds\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/help/paths.rds\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/html/\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/html/00Index.html\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/html/R.css\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/profile/\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/profile/general.R\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/profile/shell.R\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/tests/\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/tests/testthat/\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/tests/testthat/test_basic.R\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/worker/\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/worker/daemon.R\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/worker/worker.R\n",
      "spark-3.3.1-bin-hadoop3/R/lib/sparkr.zip\n",
      "spark-3.3.1-bin-hadoop3/README.md\n",
      "spark-3.3.1-bin-hadoop3/RELEASE\n",
      "spark-3.3.1-bin-hadoop3/bin/\n",
      "spark-3.3.1-bin-hadoop3/bin/beeline\n",
      "spark-3.3.1-bin-hadoop3/bin/beeline.cmd\n",
      "spark-3.3.1-bin-hadoop3/bin/docker-image-tool.sh\n",
      "spark-3.3.1-bin-hadoop3/bin/find-spark-home\n",
      "spark-3.3.1-bin-hadoop3/bin/find-spark-home.cmd\n",
      "spark-3.3.1-bin-hadoop3/bin/load-spark-env.cmd\n",
      "spark-3.3.1-bin-hadoop3/bin/load-spark-env.sh\n",
      "spark-3.3.1-bin-hadoop3/bin/pyspark\n",
      "spark-3.3.1-bin-hadoop3/bin/pyspark.cmd\n",
      "spark-3.3.1-bin-hadoop3/bin/pyspark2.cmd\n",
      "spark-3.3.1-bin-hadoop3/bin/run-example\n",
      "spark-3.3.1-bin-hadoop3/bin/run-example.cmd\n",
      "spark-3.3.1-bin-hadoop3/bin/spark-class\n",
      "spark-3.3.1-bin-hadoop3/bin/spark-class.cmd\n",
      "spark-3.3.1-bin-hadoop3/bin/spark-class2.cmd\n",
      "spark-3.3.1-bin-hadoop3/bin/spark-shell\n",
      "spark-3.3.1-bin-hadoop3/bin/spark-shell.cmd\n",
      "spark-3.3.1-bin-hadoop3/bin/spark-shell2.cmd\n",
      "spark-3.3.1-bin-hadoop3/bin/spark-sql\n",
      "spark-3.3.1-bin-hadoop3/bin/spark-sql.cmd\n",
      "spark-3.3.1-bin-hadoop3/bin/spark-sql2.cmd\n",
      "spark-3.3.1-bin-hadoop3/bin/spark-submit\n",
      "spark-3.3.1-bin-hadoop3/bin/spark-submit.cmd\n",
      "spark-3.3.1-bin-hadoop3/bin/spark-submit2.cmd\n",
      "spark-3.3.1-bin-hadoop3/bin/sparkR\n",
      "spark-3.3.1-bin-hadoop3/bin/sparkR.cmd\n",
      "spark-3.3.1-bin-hadoop3/bin/sparkR2.cmd\n",
      "spark-3.3.1-bin-hadoop3/conf/\n",
      "spark-3.3.1-bin-hadoop3/conf/fairscheduler.xml.template\n",
      "spark-3.3.1-bin-hadoop3/conf/log4j2.properties.template\n",
      "spark-3.3.1-bin-hadoop3/conf/metrics.properties.template\n",
      "spark-3.3.1-bin-hadoop3/conf/spark-defaults.conf.template\n",
      "spark-3.3.1-bin-hadoop3/conf/spark-env.sh.template\n",
      "spark-3.3.1-bin-hadoop3/conf/workers.template\n",
      "spark-3.3.1-bin-hadoop3/data/\n",
      "spark-3.3.1-bin-hadoop3/data/graphx/\n",
      "spark-3.3.1-bin-hadoop3/data/graphx/followers.txt\n",
      "spark-3.3.1-bin-hadoop3/data/graphx/users.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/als/\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/als/sample_movielens_ratings.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/als/test.data\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/gmm_data.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/images/\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/images/license.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/kittens/\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/kittens/54893.jpg\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/kittens/DP153539.jpg\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/kittens/DP802813.jpg\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/kittens/not-image.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/license.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/multi-channel/\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/multi-channel/BGRA.png\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/multi-channel/chr30.4.184.jpg\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/multi-channel/grayscale.jpg\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/kmeans_data.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/pagerank_data.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/pic_data.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/ridge-data/\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/ridge-data/lpsa.data\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/sample_binary_classification_data.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/sample_fpgrowth.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/sample_isotonic_regression_libsvm_data.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/sample_kmeans_data.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/sample_lda_data.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/sample_lda_libsvm_data.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/sample_libsvm_data.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/sample_linear_regression_data.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/sample_movielens_data.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/sample_multiclass_classification_data.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/sample_svm_data.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/streaming_kmeans_data_test.txt\n",
      "spark-3.3.1-bin-hadoop3/data/streaming/\n",
      "spark-3.3.1-bin-hadoop3/data/streaming/AFINN-111.txt\n",
      "spark-3.3.1-bin-hadoop3/examples/\n",
      "spark-3.3.1-bin-hadoop3/examples/jars/\n",
      "spark-3.3.1-bin-hadoop3/examples/jars/scopt_2.12-3.7.1.jar\n",
      "spark-3.3.1-bin-hadoop3/examples/jars/spark-examples_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/examples/src/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaTC.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFMClassifierExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFMRegressorExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaUnivariateFeatureSelectorExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVarianceThresholdSelectorExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedScalar.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/hive/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredComplexSessionization.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/als.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/avro_inputformat.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/kmeans.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/logistic_regression.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/__init__,py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/aft_survival_regression.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/als_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/binarizer_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/bisecting_k_means_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/bucketizer_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/chi_square_test_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/chisq_selector_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/correlation_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/count_vectorizer_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/cross_validator.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/dataframe_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/dct_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/decision_tree_classification_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/decision_tree_regression_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/elementwise_product_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/estimator_transformer_param_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/feature_hasher_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/fm_classifier_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/fm_regressor_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/fpgrowth_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/gaussian_mixture_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/generalized_linear_regression_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/imputer_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/index_to_string_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/interaction_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/isotonic_regression_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/kmeans_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/lda_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/linear_regression_with_elastic_net.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/linearsvc.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/logistic_regression_summary_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/logistic_regression_with_elastic_net.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/max_abs_scaler_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/min_hash_lsh_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/min_max_scaler_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/multilayer_perceptron_classification.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/n_gram_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/naive_bayes_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/normalizer_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/one_vs_rest_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/onehot_encoder_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/pca_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/pipeline_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/polynomial_expansion_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/power_iteration_clustering_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/prefixspan_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/quantile_discretizer_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/random_forest_classifier_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/random_forest_regressor_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/rformula_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/robust_scaler_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/sql_transformer.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/standard_scaler_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/stopwords_remover_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/string_indexer_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/summarizer_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/tf_idf_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/tokenizer_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/train_validation_split.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/univariate_feature_selector_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/variance_threshold_selector_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/vector_assembler_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/vector_indexer_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/vector_size_hint_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/vector_slicer_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/word2vec_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/binary_classification_metrics_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/bisecting_k_means_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/correlations.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/correlations_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/decision_tree_classification_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/decision_tree_regression_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/elementwise_product_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/fpgrowth_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/gaussian_mixture_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/gaussian_mixture_model.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/gradient_boosting_classification_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/gradient_boosting_regression_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/hypothesis_testing_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/isotonic_regression_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/k_means_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/kernel_density_estimation_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/kmeans.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/linear_regression_with_sgd_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/logistic_regression.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/multi_class_metrics_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/multi_label_metrics_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/naive_bayes_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/normalizer_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/pca_rowmatrix_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/power_iteration_clustering_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/random_forest_classification_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/random_forest_regression_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/random_rdd_generation.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/ranking_metrics_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/recommendation_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/regression_metrics_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/sampled_rdds.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/standard_scaler_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/stratified_sampling_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/streaming_k_means_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/streaming_linear_regression_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/summary_statistics_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/svd_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/svm_with_sgd_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/tf_idf_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/word2vec.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/word2vec_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/pagerank.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/parquet_inputformat.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/pi.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/sort.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/arrow.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/basic.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/datasource.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/hive.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/streaming/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/streaming/__init__,py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/streaming/structured_network_wordcount.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/streaming/structured_sessionization.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/status_api_demo.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/streaming/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/streaming/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/streaming/hdfs_wordcount.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/streaming/network_wordcount.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/streaming/network_wordjoinsentiments.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/streaming/queue_stream.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/streaming/recoverable_network_wordcount.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/streaming/sql_network_wordcount.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/streaming/stateful_network_wordcount.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/transitive_closure.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/wordcount.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/RSparkSQLExample.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/data-manipulation.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/dataframe.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/als.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/bisectingKmeans.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/decisionTree.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/fmClassifier.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/fmRegressor.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/fpm.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/gaussianMixture.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/gbt.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/glm.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/isoreg.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/kmeans.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/kstest.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/lda.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/lm_with_elastic_net.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/logit.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/ml.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/mlp.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/naiveBayes.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/powerIterationClustering.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/prefixSpan.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/randomForest.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/survreg.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/svmLinear.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/streaming/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/streaming/structured_network_wordcount.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/META-INF/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/META-INF/services/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/META-INF/services/org.apache.spark.sql.SparkSessionExtensionsProvider\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/META-INF/services/org.apache.spark.sql.jdbc.JdbcConnectionProvider\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/dir1/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/dir1/dir2/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/dir1/dir2/file2.parquet\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/dir1/file1.parquet\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/dir1/file3.json\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/employees.json\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/full_user.avsc\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/kv1.txt\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/people.csv\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/people.json\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/people.txt\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/user.avsc\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/users.avro\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/users.orc\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/users.parquet\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/MiniReadWriteTest.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/AgeExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithLoader.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithoutLoader.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/SparkSessionExtensionsTest.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FMClassifierExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FMRegressorExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/UnivariateFeatureSelectorExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VarianceThresholdSelectorExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/pythonconverters/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedScalar.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/hive/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/ExampleJdbcConnectionProvider.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredComplexSessionization.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scripts/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scripts/getGpusResources.sh\n",
      "spark-3.3.1-bin-hadoop3/jars/\n",
      "spark-3.3.1-bin-hadoop3/jars/HikariCP-2.5.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/JLargeArrays-1.5.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/JTransforms-3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/RoaringBitmap-0.9.25.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/ST4-4.0.4.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/activation-1.1.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/aircompressor-0.21.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/algebra_2.12-2.0.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/annotations-17.0.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/antlr-runtime-3.5.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/antlr4-runtime-4.8.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/aopalliance-repackaged-2.6.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/arpack-2.2.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/arpack_combined_all-0.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/arrow-format-7.0.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/arrow-memory-core-7.0.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/arrow-memory-netty-7.0.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/arrow-vector-7.0.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/audience-annotations-0.5.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/automaton-1.11-8.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/avro-1.11.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/avro-ipc-1.11.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/avro-mapred-1.11.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/blas-2.2.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/bonecp-0.8.0.RELEASE.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/breeze-macros_2.12-1.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/breeze_2.12-1.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/cats-kernel_2.12-2.1.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/chill-java-0.10.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/chill_2.12-0.10.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/commons-cli-1.5.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/commons-codec-1.15.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/commons-collections-3.2.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/commons-collections4-4.4.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/commons-compiler-3.0.16.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/commons-compress-1.21.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/commons-crypto-1.1.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/commons-dbcp-1.4.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/commons-io-2.11.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/commons-lang-2.6.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/commons-lang3-3.12.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/commons-logging-1.1.3.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/commons-math3-3.6.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/commons-pool-1.5.4.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/commons-text-1.9.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/compress-lzf-1.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/core-1.1.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/curator-client-2.13.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/curator-framework-2.13.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/curator-recipes-2.13.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/datanucleus-api-jdo-4.2.4.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/datanucleus-core-4.1.17.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/datanucleus-rdbms-4.1.19.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/derby-10.14.2.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/flatbuffers-java-1.12.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/generex-1.0.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/gson-2.2.4.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/guava-14.0.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hadoop-client-api-3.3.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hadoop-client-runtime-3.3.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hadoop-shaded-guava-1.1.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hadoop-yarn-server-web-proxy-3.3.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hive-beeline-2.3.9.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hive-cli-2.3.9.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hive-common-2.3.9.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hive-exec-2.3.9-core.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hive-jdbc-2.3.9.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hive-llap-common-2.3.9.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hive-metastore-2.3.9.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hive-serde-2.3.9.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hive-service-rpc-3.1.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hive-shims-0.23-2.3.9.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hive-shims-2.3.9.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hive-shims-common-2.3.9.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hive-shims-scheduler-2.3.9.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hive-storage-api-2.7.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hive-vector-code-gen-2.3.9.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hk2-api-2.6.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hk2-locator-2.6.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hk2-utils-2.6.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/httpclient-4.5.13.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/httpcore-4.4.14.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/istack-commons-runtime-3.0.8.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/ivy-2.5.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jackson-annotations-2.13.4.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jackson-core-2.13.4.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jackson-core-asl-1.9.13.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jackson-databind-2.13.4.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jackson-dataformat-yaml-2.13.4.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jackson-datatype-jsr310-2.13.4.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jackson-mapper-asl-1.9.13.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jackson-module-scala_2.12-2.13.4.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jakarta.annotation-api-1.3.5.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jakarta.inject-2.6.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jakarta.servlet-api-4.0.3.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jakarta.validation-api-2.0.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jakarta.ws.rs-api-2.1.6.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jakarta.xml.bind-api-2.3.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/janino-3.0.16.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/javassist-3.25.0-GA.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/javax.jdo-3.2.0-m3.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/javolution-5.5.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jaxb-runtime-2.3.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jcl-over-slf4j-1.7.32.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jdo-api-3.0.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jersey-client-2.36.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jersey-common-2.36.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jersey-container-servlet-2.36.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jersey-container-servlet-core-2.36.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jersey-hk2-2.36.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jersey-server-2.36.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jline-2.14.6.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/joda-time-2.10.13.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jodd-core-3.5.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jpam-1.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/json-1.8.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/json4s-ast_2.12-3.7.0-M11.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/json4s-core_2.12-3.7.0-M11.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/json4s-jackson_2.12-3.7.0-M11.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/json4s-scalap_2.12-3.7.0-M11.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jsr305-3.0.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jta-1.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jul-to-slf4j-1.7.32.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kryo-shaded-4.0.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-client-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-admissionregistration-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-apiextensions-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-apps-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-autoscaling-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-batch-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-certificates-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-common-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-coordination-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-core-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-discovery-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-events-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-extensions-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-flowcontrol-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-metrics-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-networking-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-node-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-policy-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-rbac-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-scheduling-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-storageclass-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/lapack-2.2.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/leveldbjni-all-1.8.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/libfb303-0.9.3.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/libthrift-0.12.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/log4j-1.2-api-2.17.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/log4j-api-2.17.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/log4j-core-2.17.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/log4j-slf4j-impl-2.17.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/logging-interceptor-3.12.12.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/lz4-java-1.8.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/mesos-1.4.3-shaded-protobuf.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/metrics-core-4.2.7.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/metrics-graphite-4.2.7.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/metrics-jmx-4.2.7.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/metrics-json-4.2.7.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/metrics-jvm-4.2.7.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/minlog-1.3.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/netty-all-4.1.74.Final.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/netty-buffer-4.1.74.Final.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/netty-codec-4.1.74.Final.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/netty-common-4.1.74.Final.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/netty-handler-4.1.74.Final.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/netty-resolver-4.1.74.Final.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/netty-tcnative-classes-2.0.48.Final.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/netty-transport-4.1.74.Final.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/netty-transport-classes-epoll-4.1.74.Final.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/netty-transport-classes-kqueue-4.1.74.Final.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/netty-transport-native-epoll-4.1.74.Final-linux-aarch_64.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/netty-transport-native-epoll-4.1.74.Final-linux-x86_64.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/netty-transport-native-kqueue-4.1.74.Final-osx-aarch_64.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/netty-transport-native-kqueue-4.1.74.Final-osx-x86_64.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/netty-transport-native-unix-common-4.1.74.Final.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/objenesis-3.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/okhttp-3.12.12.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/okio-1.14.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/opencsv-2.3.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/orc-core-1.7.6.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/orc-mapreduce-1.7.6.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/orc-shims-1.7.6.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/oro-2.0.8.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/osgi-resource-locator-1.0.3.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/paranamer-2.8.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/parquet-column-1.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/parquet-common-1.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/parquet-encoding-1.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/parquet-format-structures-1.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/parquet-hadoop-1.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/parquet-jackson-1.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/pickle-1.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/protobuf-java-2.5.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/py4j-0.10.9.5.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/rocksdbjni-6.20.3.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/scala-collection-compat_2.12-2.1.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/scala-compiler-2.12.15.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/scala-library-2.12.15.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/scala-parser-combinators_2.12-1.1.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/scala-reflect-2.12.15.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/scala-xml_2.12-1.2.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/shapeless_2.12-2.3.7.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/shims-0.9.25.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/slf4j-api-1.7.32.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/snakeyaml-1.31.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/snappy-java-1.1.8.4.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-catalyst_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-core_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-graphx_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-hive-thriftserver_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-hive_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-kubernetes_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-kvstore_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-launcher_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-mesos_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-mllib-local_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-mllib_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-network-common_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-network-shuffle_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-repl_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-sketch_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-sql_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-streaming_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-tags_2.12-3.3.1-tests.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-tags_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-unsafe_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-yarn_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spire-macros_2.12-0.17.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spire-platform_2.12-0.17.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spire-util_2.12-0.17.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spire_2.12-0.17.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/stax-api-1.0.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/stream-2.9.6.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/super-csv-2.2.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/threeten-extra-1.5.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/tink-1.6.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/transaction-api-1.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/univocity-parsers-2.9.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/velocity-1.5.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/xbean-asm9-shaded-4.20.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/xz-1.8.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/zjsonpatch-0.3.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/zookeeper-3.6.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/zookeeper-jute-3.6.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/zstd-jni-1.5.2-1.jar\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/Dockerfile\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/Dockerfile.java17\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/R/\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/R/Dockerfile\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/python/\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/python/Dockerfile\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/decom.sh\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/entrypoint.sh\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/tests/\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/tests/autoscale.py\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/tests/decommissioning.py\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/tests/decommissioning_cleanup.py\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/tests/py_container_checks.py\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/tests/pyfiles.py\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/tests/python_executable_check.py\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/tests/worker_memory_check.py\n",
      "spark-3.3.1-bin-hadoop3/licenses/\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-AnchorJS.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-CC0.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-JLargeArrays.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-JTransforms.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-antlr.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-arpack.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-automaton.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-blas.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-bootstrap.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-cloudpickle.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-d3.min.js.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-dagre-d3.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-datatables.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-dnsjava.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-f2j.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-graphlib-dot.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-istack-commons-runtime.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-jakarta-annotation-api\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-jakarta-ws-rs-api\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-jakarta.activation-api.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-jakarta.xml.bind-api.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-janino.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-javassist.html\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-javax-transaction-transaction-api.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-javolution.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-jaxb-runtime.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-jline.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-jodd.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-join.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-jquery.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-json-formatter.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-jsp-api.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-kryo.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-leveldbjni.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-machinist.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-matchMedia-polyfill.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-minlog.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-modernizr.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-mustache.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-netlib.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-paranamer.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-pmml-model.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-protobuf.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-py4j.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-pyrolite.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-re2j.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-reflectasm.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-respond.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-sbt-launch-lib.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-scala.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-scopt.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-slf4j.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-sorttable.js.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-spire.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-vis-timeline.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-xmlenc.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-zstd-jni.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-zstd.txt\n",
      "spark-3.3.1-bin-hadoop3/python/\n",
      "spark-3.3.1-bin-hadoop3/python/.coveragerc\n",
      "spark-3.3.1-bin-hadoop3/python/.gitignore\n",
      "spark-3.3.1-bin-hadoop3/python/MANIFEST.in\n",
      "spark-3.3.1-bin-hadoop3/python/README.md\n",
      "spark-3.3.1-bin-hadoop3/python/dist/\n",
      "spark-3.3.1-bin-hadoop3/python/docs/\n",
      "spark-3.3.1-bin-hadoop3/python/docs/Makefile\n",
      "spark-3.3.1-bin-hadoop3/python/docs/make.bat\n",
      "spark-3.3.1-bin-hadoop3/python/docs/make2.bat\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/_static/\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/_static/copybutton.js\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/_static/css/\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/_static/css/pyspark.css\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/_templates/\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/_templates/autosummary/\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/_templates/autosummary/class.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/_templates/autosummary/class_with_docs.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/conf.py\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/development/\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/development/contributing.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/development/debugging.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/development/index.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/development/setting_ide.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/development/testing.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/getting_started/\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/getting_started/index.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/getting_started/install.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/getting_started/quickstart_df.ipynb\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/getting_started/quickstart_ps.ipynb\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/index.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/index.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/koalas_to_pyspark.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/pyspark_1.0_1.2_to_1.3.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/pyspark_1.4_to_1.5.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/pyspark_2.2_to_2.3.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/pyspark_2.3.0_to_2.3.1_above.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/pyspark_2.3_to_2.4.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/pyspark_2.4_to_3.0.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/pyspark_3.1_to_3.2.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/pyspark_3.2_to_3.3.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/index.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.ml.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.mllib.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/extensions.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/frame.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/general_functions.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/groupby.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/index.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/indexing.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/io.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/ml.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/series.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/window.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.resource.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/avro.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/catalog.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/column.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/configuration.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/core_classes.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/data_types.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/dataframe.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/functions.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/grouping.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/index.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/io.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/observation.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/row.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/spark_session.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/window.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/core_classes.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/index.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/io.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/query_management.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.streaming.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/arrow_pandas.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/index.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/best_practices.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/faq.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/from_to_dbms.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/index.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/options.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/pandas_pyspark.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/supported_pandas_api.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/transform_apply.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/typehints.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/types.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/python_packaging.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/sql/\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/sql/arrow_pandas.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/sql/index.rst\n",
      "spark-3.3.1-bin-hadoop3/python/lib/\n",
      "spark-3.3.1-bin-hadoop3/python/lib/PY4J_LICENSE.txt\n",
      "spark-3.3.1-bin-hadoop3/python/lib/py4j-0.10.9.5-src.zip\n",
      "spark-3.3.1-bin-hadoop3/python/lib/pyspark.zip\n",
      "spark-3.3.1-bin-hadoop3/python/mypy.ini\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/__pycache__/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/__pycache__/install.cpython-38.pyc\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/_globals.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/_typing.pyi\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/accumulators.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/broadcast.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/cloudpickle/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/cloudpickle/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/cloudpickle/cloudpickle.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/cloudpickle/cloudpickle_fast.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/cloudpickle/compat.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/conf.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/context.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/daemon.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/files.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/find_spark_home.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/install.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/instrumentation_utils.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/java_gateway.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/join.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/_typing.pyi\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/base.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/classification.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/clustering.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/common.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/evaluation.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/feature.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/fpm.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/functions.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/image.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/linalg/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/linalg/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/param/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/param/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/param/_shared_params_code_gen.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/param/shared.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/pipeline.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/recommendation.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/regression.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/stat.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_algorithms.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_base.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_evaluation.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_feature.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_image.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_linalg.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_param.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_persistence.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_pipeline.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_stat.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_training_summary.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_tuning.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_util.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_wrapper.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/typing/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_classification.yml\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_clustering.yaml\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_evaluation.yml\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_feature.yml\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_param.yml\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_readable.yml\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_regression.yml\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tree.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tuning.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/util.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/wrapper.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/_typing.pyi\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/classification.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/clustering.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/common.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/evaluation.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/feature.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/fpm.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/linalg/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/linalg/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/linalg/distributed.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/random.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/random.pyi\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/recommendation.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/recommendation.pyi\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/regression.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/stat/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/stat/KernelDensity.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/stat/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/stat/_statistics.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/stat/distribution.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/stat/test.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/tests/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/tests/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/tests/test_algorithms.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/tests/test_feature.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/tests/test_linalg.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/tests/test_stat.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/tests/test_streaming_algorithms.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/tests/test_util.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/tree.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/util.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/_typing.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/accessors.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/base.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/categorical.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/config.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/base.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/binary_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/boolean_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/categorical_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/complex_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/date_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/datetime_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/null_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/num_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/string_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/timedelta_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/udt_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/datetimes.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/exceptions.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/extensions.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/frame.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/generic.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/groupby.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/indexes/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/indexes/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/indexes/base.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/indexes/category.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/indexes/datetimes.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/indexes/multi.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/indexes/numeric.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/indexes/timedelta.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/indexing.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/internal.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/missing/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/missing/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/missing/common.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/missing/frame.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/missing/general_functions.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/missing/groupby.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/missing/indexes.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/missing/series.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/missing/window.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/ml.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/mlflow.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/namespace.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/numpy_compat.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/plot/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/plot/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/plot/core.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/plot/matplotlib.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/plot/plotly.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/series.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/spark/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/spark/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/spark/accessors.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/spark/functions.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/spark/utils.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/sql_formatter.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/sql_processor.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/strings.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_base.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_binary_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_boolean_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_categorical_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_complex_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_date_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_datetime_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_null_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_num_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_string_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_timedelta_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_udt_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/testing_utils.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_base.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_category.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_datetime.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_timedelta.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/plot/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/plot/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_frame_plot.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_frame_plot_matplotlib.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_frame_plot_plotly.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_series_plot.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_series_plot_matplotlib.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_series_plot_plotly.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_categorical.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_config.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_csv.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_dataframe.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_dataframe_conversion.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_dataframe_spark_io.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_default_index.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_expanding.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_extension.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_frame_spark.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_groupby.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_indexing.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_indexops_spark.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_internal.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_namespace.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_numpy_compat.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby_expanding.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby_rolling.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_repr.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_reshape.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_rolling.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_series.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_series_conversion.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_series_datetime.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_series_string.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_spark_functions.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_sql.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_stats.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_typedef.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_utils.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_window.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/typedef/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/typedef/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/typedef/typehints.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/usage_logging/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/usage_logging/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/usage_logging/usage_logger.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/utils.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/window.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/profiler.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/py.typed\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/python/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/python/pyspark/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/python/pyspark/shell.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/rdd.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/rddsampler.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/resource/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/resource/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/resource/information.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/resource/profile.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/resource/requests.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/resource/tests/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/resource/tests/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/resource/tests/test_resources.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/resultiterable.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/serializers.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/shell.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/shuffle.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/_typing.pyi\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/avro/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/avro/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/avro/functions.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/catalog.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/column.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/conf.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/context.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/dataframe.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/functions.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/group.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/observation.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/__init__.pyi\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/__init__.pyi\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/frame.pyi\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/series.pyi\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/conversion.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/functions.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/functions.pyi\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/group_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/map_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/serializers.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/typehints.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/types.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/utils.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/readwriter.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/session.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/sql_formatter.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/streaming.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_arrow.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_arrow_map.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_catalog.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_column.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_conf.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_context.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_dataframe.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_datasources.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_functions.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_group.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_cogrouped_map.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_grouped_map.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_map.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_udf.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_udf_grouped_agg.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_udf_scalar.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_udf_typehints.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_udf_typehints_with_future_annotations.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_udf_window.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_readwriter.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_serde.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_session.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_streaming.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_types.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_udf.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_udf_profiler.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_utils.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/typing/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_column.yml\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_dataframe.yml\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_functions.yml\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_readwriter.yml\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_session.yml\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_udf.yml\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/types.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/udf.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/utils.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/window.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/statcounter.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/status.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/storagelevel.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/context.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/dstream.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/kinesis.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/listener.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/tests/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/tests/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/tests/test_context.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/tests/test_dstream.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/tests/test_kinesis.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/tests/test_listener.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/util.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/taskcontext.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/testing/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/testing/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/testing/mllibutils.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/testing/mlutils.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/testing/pandasutils.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/testing/sqlutils.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/testing/streamingutils.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/testing/utils.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_appsubmit.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_broadcast.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_conf.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_context.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_daemon.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_install_spark.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_join.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_pin_thread.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_profiler.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_rdd.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_rddbarrier.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_readwrite.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_serializers.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_shuffle.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_statcounter.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_taskcontext.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_util.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_worker.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/typing/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/typing/test_context.yml\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/typing/test_core.yml\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/typing/test_rdd.yml\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/typing/test_resultiterable.yml\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/traceback_utils.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/util.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/version.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/worker.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark.egg-info/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark.egg-info/PKG-INFO\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark.egg-info/SOURCES.txt\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark.egg-info/dependency_links.txt\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark.egg-info/requires.txt\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark.egg-info/top_level.txt\n",
      "spark-3.3.1-bin-hadoop3/python/run-tests\n",
      "spark-3.3.1-bin-hadoop3/python/run-tests-with-coverage\n",
      "spark-3.3.1-bin-hadoop3/python/run-tests.py\n",
      "spark-3.3.1-bin-hadoop3/python/setup.cfg\n",
      "spark-3.3.1-bin-hadoop3/python/setup.py\n",
      "spark-3.3.1-bin-hadoop3/python/test_coverage/\n",
      "spark-3.3.1-bin-hadoop3/python/test_coverage/conf/\n",
      "spark-3.3.1-bin-hadoop3/python/test_coverage/conf/spark-defaults.conf\n",
      "spark-3.3.1-bin-hadoop3/python/test_coverage/coverage_daemon.py\n",
      "spark-3.3.1-bin-hadoop3/python/test_coverage/sitecustomize.py\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/SimpleHTTPServer.py\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/hello/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/hello/hello.txt\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/hello/sub_hello/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/hello/sub_hello/sub_hello.txt\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/ages.csv\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/ages_newlines.csv\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/_SUCCESS\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/c=0/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/c=0/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/c=0/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/c=1/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/c=1/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/c=1/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/_SUCCESS\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/_common_metadata\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/_metadata\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2014/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2014/month=9/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/.part-r-00008.gz.parquet.crc\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/part-r-00008.gz.parquet\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=10/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00002.gz.parquet.crc\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00004.gz.parquet.crc\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00002.gz.parquet\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00004.gz.parquet\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/.part-r-00005.gz.parquet.crc\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/part-r-00005.gz.parquet\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=9/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/.part-r-00007.gz.parquet.crc\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/part-r-00007.gz.parquet\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/people.json\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/people1.json\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/people_array.json\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/people_array_utf16le.json\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/streaming/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/streaming/text-test.txt\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/text-test.txt\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/userlib-0.1.zip\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/userlibrary.py\n",
      "spark-3.3.1-bin-hadoop3/sbin/\n",
      "spark-3.3.1-bin-hadoop3/sbin/decommission-slave.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/decommission-worker.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/slaves.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/spark-config.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/spark-daemon.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/spark-daemons.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/start-all.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/start-history-server.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/start-master.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/start-mesos-dispatcher.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/start-mesos-shuffle-service.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/start-slave.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/start-slaves.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/start-thriftserver.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/start-worker.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/start-workers.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/stop-all.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/stop-history-server.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/stop-master.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/stop-mesos-dispatcher.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/stop-mesos-shuffle-service.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/stop-slave.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/stop-slaves.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/stop-thriftserver.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/stop-worker.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/stop-workers.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/workers.sh\n",
      "spark-3.3.1-bin-hadoop3/yarn/\n",
      "spark-3.3.1-bin-hadoop3/yarn/spark-3.3.1-yarn-shuffle.jar\n",
      "Collecting pyspark\n",
      "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting py4j==0.10.9.5\n",
      "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845500 sha256=1e1081807884311e9cbdc410cb55a7ed8b83012e58713e86b317c2ee9de5e848\n",
      "  Stored in directory: /root/.cache/pip/wheels/51/c8/18/298a4ced8ebb3ab8a7d26a7198c0cc7035abb906bde94a4c4b\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#### INSTALLATION OF LIBRARIES FOR SPARK\n",
    "!pip install findspark\n",
    "!sudo apt update\n",
    "!sudo apt install openjdk-17-jdk -y\n",
    "#!curl -JLO 'https://apache.osuosl.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz'\n",
    "!tar xvf spark-3.3.1-bin-hadoop3.tgz\n",
    "!mv spark-3.3.1-bin-hadoop3 /opt/spark\n",
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DIRECTORY SETTING FOR SPARK \n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/opt/spark\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/20 23:00:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "##### IMPORTING LIBRARIES\n",
    "\n",
    "#### WORDCLOUD\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "#### BASIC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#### SPARK\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.pandas as ps\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"OFF\")\n",
    "\n",
    "#### NLP IMPORTING FOR PIPELINE\n",
    "from spacy import displacy\n",
    "from spacy.util import minibatch, compounding\n",
    "from typing import Set, List, Tuple\n",
    "from spacy.tokens import DocBin\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "#### CUSTOM FUNCTIONS\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/spark/python/pyspark/pandas/utils.py:975: PandasAPIOnSparkAdviceWarning: If `index_col` is not specified for `read_json`, the default index is attached which can cause additional overhead.\n",
      "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n",
      "[Stage 1:====================================================>    (37 + 3) / 40]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6990280, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#### SPARK DATAFRAME\n",
    "review = ps.read_json(\"./data/review.json\", lines=True)\n",
    "print(review.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3552, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### TAKING A TINY SAMPLE FOR TRAINING A MODEL AND DROPPING DUPLICATES\n",
    "sample = review.loc[:,['text', 'stars']].sample(frac=0.0005, random_state=1)\n",
    "sample.drop_duplicates(inplace=True)\n",
    "sample.drop_duplicates(subset='text', inplace=True)\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3657455</th>\n",
       "      <td>\"We went there for brunch on my [mom's/sister'...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919775</th>\n",
       "      <td>\"What's in Store\" is a costume jewelry and acc...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000653</th>\n",
       "      <td>$2 per person for tea?! $8 for that (somewhat ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5844865</th>\n",
       "      <td>$38 bucks  that's what I was charged. $38 buck...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5644683</th>\n",
       "      <td>$9.99 for full service wash including car wash...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text stars\n",
       "3657455  \"We went there for brunch on my [mom's/sister'...     3\n",
       "2919775  \"What's in Store\" is a costume jewelry and acc...     3\n",
       "1000653  $2 per person for tea?! $8 for that (somewhat ...     4\n",
       "5844865  $38 bucks  that's what I was charged. $38 buck...     2\n",
       "5644683  $9.99 for full service wash including car wash...     5"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    4.0\n",
       "2    3.0\n",
       "3    2.0\n",
       "4    5.0\n",
       "Name: stars, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['stars'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to create a spacy dataset\n",
    "def make_docs(data: List[Tuple[str, str]], target_file: str, cats: Set[str]):\n",
    "    docs = DocBin()\n",
    "    # Use nlp.pipe to efficiently process a large number of text inputs, \n",
    "    # the as_tuple arguments enables giving a list of tuples as input and \n",
    "    # reuse it in the loop, here for the labels\n",
    "    for doc, label in nlp.pipe(data, as_tuples=True):\n",
    "        # Encode the labels (assign 1 the subreddit)\n",
    "        for cat in cats:\n",
    "            doc.cats[cat] = 1 if cat == label else 0\n",
    "        docs.add(doc)\n",
    "    docs.to_disk(target_file)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/spark/python/pyspark/pandas/utils.py:975: PandasAPIOnSparkAdviceWarning: `to_list` loads all data into the driver's memory. It should only be used if the resulting list is expected to be small.\n",
      "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1.0', '4.0', '3.0', '2.0', '5.0']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### LABELS AS STRING AS NEEDED FOR SPACY\n",
    "cats = sample['stars'].unique().astype(str).tolist()\n",
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/spark/python/pyspark/pandas/utils.py:975: PandasAPIOnSparkAdviceWarning: `to_pandas` loads all data into the driver's memory. It should only be used if the resulting pandas DataFrame is expected to be small.\n",
      "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#### TRANSFORMING TO PANDAS TO CLEAN THE DATA\n",
    "sample = sample.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CLEANING THE DATA\n",
    "sample = trim_all_columns(sample)\n",
    "sample['text'] = normalize_column(sample, 'text')\n",
    "pattern = '|'.join(['\\n','\\r', '\\t' ,'\\xa0','\\u200b',','])\n",
    "sample['text'] = clean_values(sample['text'], pattern, value=' ')\n",
    "sample['stars'] = sample['stars'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3657455    \"We went there for brunch on my [mom's/sister'...\n",
       "2919775    \"What's in Store\" is a costume jewelry and acc...\n",
       "1000653    $2 per person for tea?! $8 for that (somewhat ...\n",
       "5844865    $38 bucks  that's what I was charged. $38 buck...\n",
       "5644683    $9.99 for full service wash including car wash...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### MAKING TEST TRAIN FOR SPACY MODELS\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(sample[\"text\"].values,\n",
    "                                    sample[\"stars\"].values, test_size=0.3, \n",
    "                                    stratify=sample[\"stars\"].values, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.tokens._serialize.DocBin at 0x7fd798c78250>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### CREATING SPACY DATASET\n",
    "make_docs(list(zip(X_train, y_train)), \"train.spacy\", cats=cats)\n",
    "make_docs(list(zip(X_valid, y_valid)), \"valid.spacy\", cats=cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thinc                             8.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep thinc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.4.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.1/en_core_web_sm-3.4.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.9/dist-packages (from en-core-web-sm==3.4.1) (3.4.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.4.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.7)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.23.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.64.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.6.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.9.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.6)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (21.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.6)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.10)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.4.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (63.1.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.9.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.7)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.1.2)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.3.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.26.10)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.8)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.8)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.1.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.4.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: assets/model\u001b[0m\n",
      "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['textcat_multilabel']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TEXTC...  CATS_SCORE  SCORE \n",
      "---  ------  -------------  ----------  ------\n",
      "  0       0           0.25       49.43    0.49\n",
      "  0     200          31.71       57.03    0.57\n",
      "  0     400          27.46       61.30    0.61\n",
      "  0     600          26.11       61.91    0.62\n",
      "  0     800          25.22       63.29    0.63\n",
      "  0    1000          28.17       64.93    0.65\n",
      "  0    1200          27.20       63.44    0.63\n",
      "  0    1400          24.37       65.62    0.66\n",
      "  1    1600          20.31       69.61    0.70\n",
      "  1    1800          16.01       70.09    0.70\n",
      "  1    2000          15.29       70.98    0.71\n",
      "  1    2200          14.61       74.69    0.75\n",
      "  2    2400           9.82       75.74    0.76\n",
      "  2    2600           9.63       75.76    0.76\n",
      "  3    2800           6.85       76.22    0.76\n",
      "  4    3000           5.79       75.89    0.76\n",
      "  4    3200           4.41       76.42    0.76\n",
      "  5    3400           3.84       76.29    0.76\n",
      "  5    3600           3.27       76.04    0.76\n",
      "  6    3800           2.55       75.81    0.76\n",
      "  7    4000           2.41       75.59    0.76\n",
      "  7    4200           1.90       76.15    0.76\n",
      "  8    4400           1.55       75.70    0.76\n",
      "  8    4600           1.56       75.31    0.75\n",
      "  9    4800           1.29       75.16    0.75\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "assets/model/model-last\n"
     ]
    }
   ],
   "source": [
    "#### TRAINING THE MODEL WITH SPACY CLI\n",
    "from spacy.cli.train import train as spacy_train\n",
    "\n",
    "config_path = \"./configs/config.cfg\"\n",
    "output_model_path = \"./assets/model\"\n",
    "spacy_train(\n",
    "    config_path,\n",
    "    output_path=output_model_path,\n",
    "    use_gpu = 0,\n",
    "    overrides={\n",
    "        \"paths.train\": \"train.spacy\",\n",
    "        \"paths.dev\": \"valid.spacy\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TESTING THE MODEL\n",
    "test = review.sample(frac=0.000005, random_state=3333)\n",
    "test = test.to_pandas()\n",
    "test = test[['text', 'stars']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "prueba1 = test['text'].sample().values[0]\n",
    "prueba2 = test['text'].sample().values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was disappointed.  The place was dirty and the made no apologies for how dirty it was.  I kindly asked them to clean the condiments area and they refused.   I hope they make some changes soon. Also... The bathroom had flies.\n",
      "Food was delicious. Drinks were delicious. Boudin balls were perfectly cooked and flavorful. I got the crab cake with poached egg (yum!). The same sauce is on it that the fried green tomato side was in so I was a little over the same taste after my meal but it was still good! I'll know for next time. Everyone else in our party had delicious brunch as well. Truffle Mac and cheese and cheese grits tasted similar so they just use the same cheese in both dishes.  The decor and ambiance of the place is very relaxing. Will be back!\n"
     ]
    }
   ],
   "source": [
    "print(prueba1)\n",
    "print(prueba2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3': 0.04205531254410744, '4': 0.04049293324351311, '2': 0.6316655278205872, '5': 0.0632324069738388, '1': 0.5240751504898071}\n",
      "{'3': 0.04304078221321106, '4': 0.005179326981306076, '2': 0.00015928283391986042, '5': 0.6787703633308411, '1': 1.00755369203398e-05}\n"
     ]
    }
   ],
   "source": [
    "#### LOADING THE MODEL AND TESTING\n",
    "trained_nlp = spacy.load(\"./assets/model/model-last\")\n",
    "# Perform the trained pipeline on this text\n",
    "doc1 = trained_nlp(prueba1)\n",
    "doc2 = trained_nlp(prueba2)\n",
    "# We can display the predicted categories\n",
    "print(doc1.cats)\n",
    "print(doc2.cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not tested yet things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy\n",
    "import spacy\n",
    "import multiprocessing as mp\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from thinc.api import set_gpu_allocator, require_gpu\n",
    "\n",
    "# A different method for flattening a list\n",
    "def flatten2d(list2d):\n",
    "    from functools import reduce\n",
    "    from operator import iconcat\n",
    "    return reduce(iconcat, list2d, [])\n",
    "\n",
    "def chunker(iterator, length, chunksize):\n",
    "    return (iterator[pos: pos + chunksize] for pos in range(0, length, chunksize))\n",
    "\n",
    "def process_entity(doc):\n",
    "    # I need lists of sentences for my use case,  but you could do other processing\n",
    "    return [s.text for s in doc.sents]\n",
    "\n",
    "def process_chunk(docs, rank):\n",
    "    with cupy.cuda.Device(rank):\n",
    "        set_gpu_allocator('pytorch')\n",
    "        require_gpu(rank)\n",
    "        nlp = spacy.load('en_core_web_sm', disable=['parser'])\n",
    "        nlp.add_pipe('sentencizer')\n",
    "        preprocess_pipe = []\n",
    "        for doc in nlp.pipe(docs, batch_size=20):\n",
    "            preprocess_pipe.append(process_entity(doc))\n",
    "        rank += 1\n",
    "        return preprocess_pipe\n",
    "\n",
    "def process_parallel(docs, jobs=2, chunksize=50):\n",
    "    executor = Parallel(n_jobs=jobs, prefer='threads')\n",
    "    do = delayed(process_chunk)\n",
    "    tasks = []\n",
    "    gpus = list(range(0, cupy.cuda.runtime.getDeviceCount()))\n",
    "    rank = 0\n",
    "    for chunk in chunker(docs, len(docs), chunksize):\n",
    "        tasks.append(do(chunk, rank))\n",
    "        rank = (rank + 1) % len(gpus)\n",
    "    result = executor(tasks)\n",
    "    return flatten2d(result)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    preprocessed = process_parallel(\n",
    "        docs = [\"This is a basic sentence. This is another one.\"]*100,\n",
    "        jobs=4,\n",
    "        chunksize=25\n",
    "    )\n",
    "    print(preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "import cupy\n",
    "from spacy.cli.train import train as spacy_train\n",
    "\n",
    "config_path = \"./configs/config.cfg\"\n",
    "output_model_path = \"./assets/model\"\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "if rank == 0:\n",
    "    data = [\"His friend Nicolas J. Smith is here with Bart Simpon and Fred.\"*100]\n",
    "else:\n",
    "    data = None\n",
    "\n",
    "unit = comm.scatter(data, root=0)\n",
    "\n",
    "with cupy.cuda.Device(rank):\n",
    "    import spacy\n",
    "    from thinc.api import set_gpu_allocator, require_gpu\n",
    "    set_gpu_allocator(\"pytorch\")\n",
    "    require_gpu(rank)\n",
    "    nlp = spacy.load('en_core_web_lg')\n",
    "    spacy_train(\n",
    "    config_path,\n",
    "    output_path=output_model_path,\n",
    "    use_gpu = 0,\n",
    "    overrides={\n",
    "        \"paths.train\": \"train.spacy\",\n",
    "        \"paths.dev\": \"valid.spacy\"\n",
    "    }\n",
    ")\n",
    "\n",
    "    tmp_list = []\n",
    "    for doc in nlp.pipe(unit):\n",
    "        res = \" \".join([t.text if not t.ent_type_ else t.ent_type_ for t in doc])\n",
    "        tmp_list.append(res)\n",
    "\n",
    "result = comm.gather(tmp_list, root=0)\n",
    "\n",
    "if comm.rank == 0:\n",
    "    print (result)\n",
    "else:\n",
    "    result = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
