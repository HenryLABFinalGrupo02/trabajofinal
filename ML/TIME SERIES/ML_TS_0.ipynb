{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 https://deb.nodesource.com/node_16.x focal InRelease [4583 B]\n",
      "Get:2 https://deb.nodesource.com/node_16.x focal/main amd64 Packages [774 B]   \u001b[0m\u001b[33m\u001b[33m\n",
      "Get:3 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease [18.1 kB] \u001b[0m\u001b[33m\u001b[33m\u001b[33m\n",
      "Get:4 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 Packages [29.5 kB]\u001b[33m\n",
      "Get:5 http://archive.ubuntu.com/ubuntu focal InRelease [265 kB]            \u001b[0m\u001b[0m\u001b[33m\n",
      "Get:6 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]        \u001b[0m\u001b[33m\n",
      "Get:7 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]      \u001b[0m\u001b[33m\n",
      "Get:8 http://archive.ubuntu.com/ubuntu focal/universe amd64 Packages [11.3 MB] \u001b[0m\u001b[33m\n",
      "Get:9 http://archive.ubuntu.com/ubuntu focal/restricted amd64 Packages [33.4 kB][0m\u001b[33m\u001b[33m\n",
      "Get:10 http://archive.ubuntu.com/ubuntu focal/main amd64 Packages [1275 kB] \u001b[0m[0m\u001b[33m\n",
      "Get:11 http://archive.ubuntu.com/ubuntu focal/multiverse amd64 Packages [177 kB][0m\u001b[33m\n",
      "Get:12 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [30.2 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [2786 kB]\u001b[33m\n",
      "Get:14 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1268 kB]m\n",
      "Get:15 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [1829 kB]\n",
      "Get:16 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]     \u001b[0m\n",
      "Get:17 http://archive.ubuntu.com/ubuntu focal-backports/main amd64 Packages [55.2 kB]33m\n",
      "Get:18 http://archive.ubuntu.com/ubuntu focal-backports/universe amd64 Packages [27.4 kB]\n",
      "Get:19 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2315 kB]\n",
      "Get:20 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [27.5 kB]\n",
      "Get:21 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [1712 kB]\n",
      "Get:22 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [967 kB]\n",
      "Fetched 24.5 MB in 4s (6036 kB/s)33m                      \u001b[0m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "104 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  ca-certificates-java fonts-dejavu-extra java-common libatk-wrapper-java\n",
      "  libatk-wrapper-java-jni libfontenc1 libice-dev libnspr4 libnss3 libpcsclite1\n",
      "  libpthread-stubs0-dev libsm-dev libx11-dev libxau-dev libxcb1-dev\n",
      "  libxdmcp-dev libxkbfile1 libxmuu1 libxt-dev libxtst6 libxxf86dga1\n",
      "  openjdk-17-jdk-headless openjdk-17-jre openjdk-17-jre-headless x11-utils\n",
      "  x11proto-core-dev x11proto-dev xorg-sgml-doctools xtrans-dev\n",
      "Suggested packages:\n",
      "  default-jre libice-doc pcscd libsm-doc libx11-doc libxcb-doc libxt-doc\n",
      "  openjdk-17-demo openjdk-17-source visualvm libnss-mdns fonts-ipafont-gothic\n",
      "  fonts-ipafont-mincho fonts-wqy-microhei | fonts-wqy-zenhei fonts-indic\n",
      "  mesa-utils\n",
      "The following NEW packages will be installed:\n",
      "  ca-certificates-java fonts-dejavu-extra java-common libatk-wrapper-java\n",
      "  libatk-wrapper-java-jni libfontenc1 libice-dev libnspr4 libnss3 libpcsclite1\n",
      "  libpthread-stubs0-dev libsm-dev libx11-dev libxau-dev libxcb1-dev\n",
      "  libxdmcp-dev libxkbfile1 libxmuu1 libxt-dev libxtst6 libxxf86dga1\n",
      "  openjdk-17-jdk openjdk-17-jdk-headless openjdk-17-jre\n",
      "  openjdk-17-jre-headless x11-utils x11proto-core-dev x11proto-dev\n",
      "  xorg-sgml-doctools xtrans-dev\n",
      "0 upgraded, 30 newly installed, 0 to remove and 104 not upgraded.\n",
      "Need to get 292 MB of archives.\n",
      "After this operation, 466 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu focal/main amd64 libxmuu1 amd64 2:1.1.3-0ubuntu1 [9728 B]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu focal/main amd64 java-common all 0.72 [6816 B]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu focal/main amd64 libnspr4 amd64 2:4.25-1 [107 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libnss3 amd64 2:3.49.1-1ubuntu1.8 [1256 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu focal/main amd64 libpcsclite1 amd64 1.8.26-3 [22.0 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 openjdk-17-jre-headless amd64 17.0.5+8-2ubuntu1~20.04 [43.6 MB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu focal/main amd64 ca-certificates-java all 20190405ubuntu1 [12.2 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu focal/main amd64 fonts-dejavu-extra all 2.37-1 [1953 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu focal/main amd64 libfontenc1 amd64 1:1.1.4-0ubuntu1 [14.0 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu focal/main amd64 libxkbfile1 amd64 1:1.1.0-1 [65.3 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu focal/main amd64 libxtst6 amd64 2:1.2.3-1 [12.8 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu focal/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu1 [12.0 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu focal/main amd64 x11-utils amd64 7.7+5 [199 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu focal/main amd64 libatk-wrapper-java all 0.37.1-1 [53.0 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu focal/main amd64 libatk-wrapper-java-jni amd64 0.37.1-1 [45.1 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu focal/main amd64 xorg-sgml-doctools all 1:1.11-1 [12.9 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu focal/main amd64 x11proto-dev all 2019.2-1ubuntu1 [594 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu focal/main amd64 x11proto-core-dev all 2019.2-1ubuntu1 [2620 B]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu focal/main amd64 libice-dev amd64 2:1.0.10-0ubuntu1 [47.8 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu focal/main amd64 libpthread-stubs0-dev amd64 0.4-1 [5384 B]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu focal/main amd64 libsm-dev amd64 2:1.2.3-1 [17.0 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu focal/main amd64 libxau-dev amd64 1:1.0.9-0ubuntu1 [9552 B]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu focal/main amd64 libxdmcp-dev amd64 1:1.1.3-0ubuntu1 [25.3 kB]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu focal/main amd64 xtrans-dev all 1.4.0-1 [68.9 kB]\n",
      "Get:25 http://archive.ubuntu.com/ubuntu focal/main amd64 libxcb1-dev amd64 1.14-2 [80.5 kB]\n",
      "Get:26 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libx11-dev amd64 2:1.6.9-2ubuntu1.2 [647 kB]\n",
      "Get:27 http://archive.ubuntu.com/ubuntu focal/main amd64 libxt-dev amd64 1:1.1.5-1 [395 kB]\n",
      "Get:28 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 openjdk-17-jre amd64 17.0.5+8-2ubuntu1~20.04 [166 kB]\n",
      "Get:29 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 openjdk-17-jdk-headless amd64 17.0.5+8-2ubuntu1~20.04 [243 MB]\n",
      "Get:30 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 openjdk-17-jdk amd64 17.0.5+8-2ubuntu1~20.04 [10.5 kB]\n",
      "Fetched 292 MB in 8s (35.7 MB/s)                                               \u001b[0m\u001b[33m\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package libxmuu1:amd64.\n",
      "(Reading database ... 78556 files and directories currently installed.)\n",
      "Preparing to unpack .../00-libxmuu1_2%3a1.1.3-0ubuntu1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8Unpacking libxmuu1:amd64 (2:1.1.3-0ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  2%]\u001b[49m\u001b[39m [..........................................................] \u001b8Selecting previously unselected package java-common.\n",
      "Preparing to unpack .../01-java-common_0.72_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  2%]\u001b[49m\u001b[39m [#.........................................................] \u001b8Unpacking java-common (0.72) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  3%]\u001b[49m\u001b[39m [#.........................................................] \u001b8Selecting previously unselected package libnspr4:amd64.\n",
      "Preparing to unpack .../02-libnspr4_2%3a4.25-1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  4%]\u001b[49m\u001b[39m [##........................................................] \u001b8Unpacking libnspr4:amd64 (2:4.25-1) ...\n",
      "Selecting previously unselected package libnss3:amd64.\n",
      "Preparing to unpack .../03-libnss3_2%3a3.49.1-1ubuntu1.8_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  6%]\u001b[49m\u001b[39m [###.......................................................] \u001b8Unpacking libnss3:amd64 (2:3.49.1-1ubuntu1.8) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  7%]\u001b[49m\u001b[39m [###.......................................................] \u001b8Selecting previously unselected package libpcsclite1:amd64.\n",
      "Preparing to unpack .../04-libpcsclite1_1.8.26-3_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  7%]\u001b[49m\u001b[39m [####......................................................] \u001b8Unpacking libpcsclite1:amd64 (1.8.26-3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  8%]\u001b[49m\u001b[39m [####......................................................] \u001b8Selecting previously unselected package openjdk-17-jre-headless:amd64.\n",
      "Preparing to unpack .../05-openjdk-17-jre-headless_17.0.5+8-2ubuntu1~20.04_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  9%]\u001b[49m\u001b[39m [#####.....................................................] \u001b8Unpacking openjdk-17-jre-headless:amd64 (17.0.5+8-2ubuntu1~20.04) ...\n",
      "Selecting previously unselected package ca-certificates-java.\n",
      "Preparing to unpack .../06-ca-certificates-java_20190405ubuntu1_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 11%]\u001b[49m\u001b[39m [######....................................................] \u001b8Unpacking ca-certificates-java (20190405ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 12%]\u001b[49m\u001b[39m [######....................................................] \u001b8Selecting previously unselected package fonts-dejavu-extra.\n",
      "Preparing to unpack .../07-fonts-dejavu-extra_2.37-1_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 12%]\u001b[49m\u001b[39m [#######...................................................] \u001b8Unpacking fonts-dejavu-extra (2.37-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 13%]\u001b[49m\u001b[39m [#######...................................................] \u001b8Selecting previously unselected package libfontenc1:amd64.\n",
      "Preparing to unpack .../08-libfontenc1_1%3a1.1.4-0ubuntu1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 14%]\u001b[49m\u001b[39m [########..................................................] \u001b8Unpacking libfontenc1:amd64 (1:1.1.4-0ubuntu1) ...\n",
      "Selecting previously unselected package libxkbfile1:amd64.\n",
      "Preparing to unpack .../09-libxkbfile1_1%3a1.1.0-1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 16%]\u001b[49m\u001b[39m [#########.................................................] \u001b8Unpacking libxkbfile1:amd64 (1:1.1.0-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 17%]\u001b[49m\u001b[39m [#########.................................................] \u001b8Selecting previously unselected package libxtst6:amd64.\n",
      "Preparing to unpack .../10-libxtst6_2%3a1.2.3-1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 17%]\u001b[49m\u001b[39m [##########................................................] \u001b8Unpacking libxtst6:amd64 (2:1.2.3-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 18%]\u001b[49m\u001b[39m [##########................................................] \u001b8Selecting previously unselected package libxxf86dga1:amd64.\n",
      "Preparing to unpack .../11-libxxf86dga1_2%3a1.1.5-0ubuntu1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 19%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu1) ...\n",
      "Selecting previously unselected package x11-utils.\n",
      "Preparing to unpack .../12-x11-utils_7.7+5_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 21%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Unpacking x11-utils (7.7+5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 21%]\u001b[49m\u001b[39m [############..............................................] \u001b8Selecting previously unselected package libatk-wrapper-java.\n",
      "Preparing to unpack .../13-libatk-wrapper-java_0.37.1-1_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 22%]\u001b[49m\u001b[39m [############..............................................] \u001b8Unpacking libatk-wrapper-java (0.37.1-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 23%]\u001b[49m\u001b[39m [#############.............................................] \u001b8Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
      "Preparing to unpack .../14-libatk-wrapper-java-jni_0.37.1-1_amd64.deb ...\n",
      "Unpacking libatk-wrapper-java-jni:amd64 (0.37.1-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 25%]\u001b[49m\u001b[39m [##############............................................] \u001b8Selecting previously unselected package xorg-sgml-doctools.\n",
      "Preparing to unpack .../15-xorg-sgml-doctools_1%3a1.11-1_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 26%]\u001b[49m\u001b[39m [##############............................................] \u001b8Unpacking xorg-sgml-doctools (1:1.11-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 26%]\u001b[49m\u001b[39m [###############...........................................] \u001b8Selecting previously unselected package x11proto-dev.\n",
      "Preparing to unpack .../16-x11proto-dev_2019.2-1ubuntu1_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 27%]\u001b[49m\u001b[39m [###############...........................................] \u001b8Unpacking x11proto-dev (2019.2-1ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 28%]\u001b[49m\u001b[39m [################..........................................] \u001b8Selecting previously unselected package x11proto-core-dev.\n",
      "Preparing to unpack .../17-x11proto-core-dev_2019.2-1ubuntu1_all.deb ...\n",
      "Unpacking x11proto-core-dev (2019.2-1ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 30%]\u001b[49m\u001b[39m [#################.........................................] \u001b8Selecting previously unselected package libice-dev:amd64.\n",
      "Preparing to unpack .../18-libice-dev_2%3a1.0.10-0ubuntu1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 31%]\u001b[49m\u001b[39m [#################.........................................] \u001b8Unpacking libice-dev:amd64 (2:1.0.10-0ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 31%]\u001b[49m\u001b[39m [##################........................................] \u001b8Selecting previously unselected package libpthread-stubs0-dev:amd64.\n",
      "Preparing to unpack .../19-libpthread-stubs0-dev_0.4-1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 32%]\u001b[49m\u001b[39m [##################........................................] \u001b8Unpacking libpthread-stubs0-dev:amd64 (0.4-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 33%]\u001b[49m\u001b[39m [###################.......................................] \u001b8Selecting previously unselected package libsm-dev:amd64.\n",
      "Preparing to unpack .../20-libsm-dev_2%3a1.2.3-1_amd64.deb ...\n",
      "Unpacking libsm-dev:amd64 (2:1.2.3-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 35%]\u001b[49m\u001b[39m [####################......................................] \u001b8Selecting previously unselected package libxau-dev:amd64.\n",
      "Preparing to unpack .../21-libxau-dev_1%3a1.0.9-0ubuntu1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 36%]\u001b[49m\u001b[39m [####################......................................] \u001b8Unpacking libxau-dev:amd64 (1:1.0.9-0ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 36%]\u001b[49m\u001b[39m [#####################.....................................] \u001b8Selecting previously unselected package libxdmcp-dev:amd64.\n",
      "Preparing to unpack .../22-libxdmcp-dev_1%3a1.1.3-0ubuntu1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 37%]\u001b[49m\u001b[39m [#####################.....................................] \u001b8Unpacking libxdmcp-dev:amd64 (1:1.1.3-0ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 38%]\u001b[49m\u001b[39m [######################....................................] \u001b8Selecting previously unselected package xtrans-dev.\n",
      "Preparing to unpack .../23-xtrans-dev_1.4.0-1_all.deb ...\n",
      "Unpacking xtrans-dev (1.4.0-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 40%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Selecting previously unselected package libxcb1-dev:amd64.\n",
      "Preparing to unpack .../24-libxcb1-dev_1.14-2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 40%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Unpacking libxcb1-dev:amd64 (1.14-2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 41%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Selecting previously unselected package libx11-dev:amd64.\n",
      "Preparing to unpack .../25-libx11-dev_2%3a1.6.9-2ubuntu1.2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 42%]\u001b[49m\u001b[39m [########################..................................] \u001b8Unpacking libx11-dev:amd64 (2:1.6.9-2ubuntu1.2) ...\n",
      "Selecting previously unselected package libxt-dev:amd64.\n",
      "Preparing to unpack .../26-libxt-dev_1%3a1.1.5-1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 44%]\u001b[49m\u001b[39m [#########################.................................] \u001b8Unpacking libxt-dev:amd64 (1:1.1.5-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 45%]\u001b[49m\u001b[39m [#########################.................................] \u001b8Selecting previously unselected package openjdk-17-jre:amd64.\n",
      "Preparing to unpack .../27-openjdk-17-jre_17.0.5+8-2ubuntu1~20.04_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 45%]\u001b[49m\u001b[39m [##########################................................] \u001b8Unpacking openjdk-17-jre:amd64 (17.0.5+8-2ubuntu1~20.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 46%]\u001b[49m\u001b[39m [##########################................................] \u001b8Selecting previously unselected package openjdk-17-jdk-headless:amd64.\n",
      "Preparing to unpack .../28-openjdk-17-jdk-headless_17.0.5+8-2ubuntu1~20.04_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 47%]\u001b[49m\u001b[39m [###########################...............................] \u001b8Unpacking openjdk-17-jdk-headless:amd64 (17.0.5+8-2ubuntu1~20.04) ...\n",
      "Selecting previously unselected package openjdk-17-jdk:amd64.\n",
      "Preparing to unpack .../29-openjdk-17-jdk_17.0.5+8-2ubuntu1~20.04_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 49%]\u001b[49m\u001b[39m [############################..............................] \u001b8Unpacking openjdk-17-jdk:amd64 (17.0.5+8-2ubuntu1~20.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 50%]\u001b[49m\u001b[39m [############################..............................] \u001b8Setting up java-common (0.72) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 50%]\u001b[49m\u001b[39m [#############################.............................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 51%]\u001b[49m\u001b[39m [#############################.............................] \u001b8Setting up libxtst6:amd64 (2:1.2.3-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 52%]\u001b[49m\u001b[39m [##############################............................] \u001b8Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 54%]\u001b[49m\u001b[39m [###############################...........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 55%]\u001b[49m\u001b[39m [###############################...........................] \u001b8Setting up libpthread-stubs0-dev:amd64 (0.4-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 55%]\u001b[49m\u001b[39m [################################..........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 56%]\u001b[49m\u001b[39m [################################..........................] \u001b8Setting up xtrans-dev (1.4.0-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 57%]\u001b[49m\u001b[39m [#################################.........................] \u001b8Setting up libfontenc1:amd64 (1:1.1.4-0ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 59%]\u001b[49m\u001b[39m [##################################........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 60%]\u001b[49m\u001b[39m [##################################........................] \u001b8Setting up libnspr4:amd64 (2:4.25-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 60%]\u001b[49m\u001b[39m [##################################........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 61%]\u001b[49m\u001b[39m [###################################.......................] \u001b8Setting up libpcsclite1:amd64 (1.8.26-3) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 63%]\u001b[49m\u001b[39m [####################################......................] \u001b8Setting up fonts-dejavu-extra (2.37-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 64%]\u001b[49m\u001b[39m [####################################......................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 64%]\u001b[49m\u001b[39m [#####################################.....................] \u001b8Setting up xorg-sgml-doctools (1:1.11-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 65%]\u001b[49m\u001b[39m [#####################################.....................] \u001b8Setting up libxkbfile1:amd64 (1:1.1.0-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 66%]\u001b[49m\u001b[39m [######################################....................] \u001b8Setting up libxmuu1:amd64 (2:1.1.3-0ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 68%]\u001b[49m\u001b[39m [#######################################...................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 69%]\u001b[49m\u001b[39m [#######################################...................] \u001b8Setting up libnss3:amd64 (2:3.49.1-1ubuntu1.8) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 69%]\u001b[49m\u001b[39m [########################################..................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 70%]\u001b[49m\u001b[39m [########################################..................] \u001b8Setting up x11-utils (7.7+5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 71%]\u001b[49m\u001b[39m [#########################################.................] \u001b8Setting up libatk-wrapper-java (0.37.1-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 73%]\u001b[49m\u001b[39m [##########################################................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 74%]\u001b[49m\u001b[39m [##########################################................] \u001b8Setting up libatk-wrapper-java-jni:amd64 (0.37.1-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 74%]\u001b[49m\u001b[39m [###########################################...............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 75%]\u001b[49m\u001b[39m [###########################################...............] \u001b8Setting up openjdk-17-jre-headless:amd64 (17.0.5+8-2ubuntu1~20.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 76%]\u001b[49m\u001b[39m [############################################..............] \u001b8update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/java to provide /usr/bin/java (java) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jpackage to provide /usr/bin/jpackage (jpackage) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/keytool to provide /usr/bin/keytool (keytool) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/rmiregistry to provide /usr/bin/rmiregistry (rmiregistry) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/lib/jexec to provide /usr/bin/jexec (jexec) in auto mode\n",
      "Setting up ca-certificates-java (20190405ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 78%]\u001b[49m\u001b[39m [#############################################.............] \u001b8head: cannot open '/etc/ssl/certs/java/cacerts' for reading: No such file or directory\n",
      "Adding debian:Autoridad_de_Certificacion_Firmaprofesional_CIF_A62634068.pem\n",
      "Adding debian:Trustwave_Global_ECC_P256_Certification_Authority.pem\n",
      "Adding debian:GTS_Root_R2.pem\n",
      "Adding debian:Starfield_Root_Certificate_Authority_-_G2.pem\n",
      "Adding debian:Hellenic_Academic_and_Research_Institutions_ECC_RootCA_2015.pem\n",
      "Adding debian:Certigna_Root_CA.pem\n",
      "Adding debian:CA_Disig_Root_R2.pem\n",
      "Adding debian:AC_RAIZ_FNMT-RCM.pem\n",
      "Adding debian:SwissSign_Gold_CA_-_G2.pem\n",
      "Adding debian:emSign_ECC_Root_CA_-_G3.pem\n",
      "Adding debian:GlobalSign_ECC_Root_CA_-_R4.pem\n",
      "Adding debian:NetLock_Arany_=Class_Gold=_Főtanúsítvány.pem\n",
      "Adding debian:certSIGN_ROOT_CA.pem\n",
      "Adding debian:TrustCor_RootCert_CA-1.pem\n",
      "Adding debian:SecureSign_RootCA11.pem\n",
      "Adding debian:Amazon_Root_CA_2.pem\n",
      "Adding debian:GlobalSign_Root_CA_-_R6.pem\n",
      "Adding debian:DigiCert_Trusted_Root_G4.pem\n",
      "Adding debian:Hellenic_Academic_and_Research_Institutions_RootCA_2011.pem\n",
      "Adding debian:GDCA_TrustAUTH_R5_ROOT.pem\n",
      "Adding debian:COMODO_RSA_Certification_Authority.pem\n",
      "Adding debian:D-TRUST_Root_Class_3_CA_2_2009.pem\n",
      "Adding debian:Certigna.pem\n",
      "Adding debian:ACCVRAIZ1.pem\n",
      "Adding debian:QuoVadis_Root_CA_2_G3.pem\n",
      "Adding debian:Certum_Trusted_Network_CA.pem\n",
      "Adding debian:Go_Daddy_Class_2_CA.pem\n",
      "Adding debian:TeliaSonera_Root_CA_v1.pem\n",
      "Adding debian:Network_Solutions_Certificate_Authority.pem\n",
      "Adding debian:Baltimore_CyberTrust_Root.pem\n",
      "Adding debian:DigiCert_Global_Root_G3.pem\n",
      "Adding debian:T-TeleSec_GlobalRoot_Class_2.pem\n",
      "Adding debian:AffirmTrust_Premium_ECC.pem\n",
      "Adding debian:GlobalSign_Root_CA.pem\n",
      "Adding debian:EC-ACC.pem\n",
      "Adding debian:GTS_Root_R1.pem\n",
      "Adding debian:GlobalSign_Root_CA_-_R2.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority.pem\n",
      "Adding debian:emSign_Root_CA_-_C1.pem\n",
      "Adding debian:Cybertrust_Global_Root.pem\n",
      "Adding debian:Secure_Global_CA.pem\n",
      "Adding debian:Amazon_Root_CA_4.pem\n",
      "Adding debian:E-Tugra_Certification_Authority.pem\n",
      "Adding debian:NAVER_Global_Root_Certification_Authority.pem\n",
      "Adding debian:ePKI_Root_Certification_Authority.pem\n",
      "Adding debian:Certum_Trusted_Network_CA_2.pem\n",
      "Adding debian:D-TRUST_Root_Class_3_CA_2_EV_2009.pem\n",
      "Adding debian:QuoVadis_Root_CA_3_G3.pem\n",
      "Adding debian:QuoVadis_Root_CA_2.pem\n",
      "Adding debian:TWCA_Root_Certification_Authority.pem\n",
      "Adding debian:COMODO_Certification_Authority.pem\n",
      "Adding debian:emSign_Root_CA_-_G1.pem\n",
      "Adding debian:AffirmTrust_Commercial.pem\n",
      "Adding debian:Buypass_Class_3_Root_CA.pem\n",
      "Adding debian:QuoVadis_Root_CA_1_G3.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority_-_G2.pem\n",
      "Adding debian:DigiCert_Assured_ID_Root_G2.pem\n",
      "Adding debian:TUBITAK_Kamu_SM_SSL_Kok_Sertifikasi_-_Surum_1.pem\n",
      "Adding debian:USERTrust_RSA_Certification_Authority.pem\n",
      "Adding debian:Go_Daddy_Root_Certificate_Authority_-_G2.pem\n",
      "Adding debian:Security_Communication_Root_CA.pem\n",
      "Adding debian:GTS_Root_R3.pem\n",
      "Adding debian:TrustCor_ECA-1.pem\n",
      "Adding debian:QuoVadis_Root_CA_3.pem\n",
      "Adding debian:OISTE_WISeKey_Global_Root_GB_CA.pem\n",
      "Adding debian:IdenTrust_Public_Sector_Root_CA_1.pem\n",
      "Adding debian:SZAFIR_ROOT_CA2.pem\n",
      "Adding debian:IdenTrust_Commercial_Root_CA_1.pem\n",
      "Adding debian:SSL.com_Root_Certification_Authority_RSA.pem\n",
      "Adding debian:Microsoft_RSA_Root_Certificate_Authority_2017.pem\n",
      "Adding debian:ISRG_Root_X1.pem\n",
      "Adding debian:DigiCert_Assured_ID_Root_CA.pem\n",
      "Adding debian:Buypass_Class_2_Root_CA.pem\n",
      "Adding debian:SSL.com_EV_Root_Certification_Authority_ECC.pem\n",
      "Adding debian:SSL.com_Root_Certification_Authority_ECC.pem\n",
      "Adding debian:e-Szigno_Root_CA_2017.pem\n",
      "Adding debian:GlobalSign_ECC_Root_CA_-_R5.pem\n",
      "Adding debian:SSL.com_EV_Root_Certification_Authority_RSA_R2.pem\n",
      "Adding debian:TrustCor_RootCert_CA-2.pem\n",
      "Adding debian:Microsoft_ECC_Root_Certificate_Authority_2017.pem\n",
      "Adding debian:Staat_der_Nederlanden_EV_Root_CA.pem\n",
      "Adding debian:Actalis_Authentication_Root_CA.pem\n",
      "Adding debian:AffirmTrust_Premium.pem\n",
      "Adding debian:T-TeleSec_GlobalRoot_Class_3.pem\n",
      "Adding debian:Hongkong_Post_Root_CA_1.pem\n",
      "Adding debian:Entrust.net_Premium_2048_Secure_Server_CA.pem\n",
      "Adding debian:Hongkong_Post_Root_CA_3.pem\n",
      "Adding debian:AffirmTrust_Networking.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority_-_G4.pem\n",
      "Adding debian:DigiCert_High_Assurance_EV_Root_CA.pem\n",
      "Adding debian:GlobalSign_Root_CA_-_R3.pem\n",
      "Adding debian:Microsec_e-Szigno_Root_CA_2009.pem\n",
      "Adding debian:USERTrust_ECC_Certification_Authority.pem\n",
      "Adding debian:Hellenic_Academic_and_Research_Institutions_RootCA_2015.pem\n",
      "Adding debian:DigiCert_Global_Root_CA.pem\n",
      "Adding debian:Comodo_AAA_Services_root.pem\n",
      "Adding debian:UCA_Extended_Validation_Root.pem\n",
      "Adding debian:Trustwave_Global_ECC_P384_Certification_Authority.pem\n",
      "Adding debian:Izenpe.com.pem\n",
      "Adding debian:Atos_TrustedRoot_2011.pem\n",
      "Adding debian:Starfield_Services_Root_Certificate_Authority_-_G2.pem\n",
      "Adding debian:XRamp_Global_CA_Root.pem\n",
      "Adding debian:Amazon_Root_CA_1.pem\n",
      "Adding debian:Starfield_Class_2_CA.pem\n",
      "Adding debian:GTS_Root_R4.pem\n",
      "Adding debian:CFCA_EV_ROOT.pem\n",
      "Adding debian:OISTE_WISeKey_Global_Root_GC_CA.pem\n",
      "Adding debian:SecureTrust_CA.pem\n",
      "Adding debian:COMODO_ECC_Certification_Authority.pem\n",
      "Adding debian:emSign_ECC_Root_CA_-_C3.pem\n",
      "Adding debian:DigiCert_Assured_ID_Root_G3.pem\n",
      "Adding debian:certSIGN_Root_CA_G2.pem\n",
      "Adding debian:SwissSign_Silver_CA_-_G2.pem\n",
      "Adding debian:Security_Communication_RootCA2.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority_-_EC1.pem\n",
      "Adding debian:TWCA_Global_Root_CA.pem\n",
      "Adding debian:UCA_Global_G2_Root.pem\n",
      "Adding debian:Trustwave_Global_Certification_Authority.pem\n",
      "Adding debian:Amazon_Root_CA_3.pem\n",
      "Adding debian:DigiCert_Global_Root_G2.pem\n",
      "Adding debian:ANF_Secure_Server_Root_CA.pem\n",
      "Adding debian:GLOBALTRUST_2020.pem\n",
      "Adding debian:GlobalSign_Root_R46.pem\n",
      "Adding debian:AC_RAIZ_FNMT-RCM_SERVIDORES_SEGUROS.pem\n",
      "Adding debian:Certum_EC-384_CA.pem\n",
      "Adding debian:Certum_Trusted_Root_CA.pem\n",
      "Adding debian:GlobalSign_Root_E46.pem\n",
      "done.\n",
      "Setting up openjdk-17-jre:amd64 (17.0.5+8-2ubuntu1~20.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 79%]\u001b[49m\u001b[39m [#############################################.............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 79%]\u001b[49m\u001b[39m [##############################################............] \u001b8Setting up openjdk-17-jdk-headless:amd64 (17.0.5+8-2ubuntu1~20.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 80%]\u001b[49m\u001b[39m [##############################################............] \u001b8update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jar to provide /usr/bin/jar (jar) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jarsigner to provide /usr/bin/jarsigner (jarsigner) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javac to provide /usr/bin/javac (javac) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javadoc to provide /usr/bin/javadoc (javadoc) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javap to provide /usr/bin/javap (javap) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jcmd to provide /usr/bin/jcmd (jcmd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdb to provide /usr/bin/jdb (jdb) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdeprscan to provide /usr/bin/jdeprscan (jdeprscan) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdeps to provide /usr/bin/jdeps (jdeps) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jfr to provide /usr/bin/jfr (jfr) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jimage to provide /usr/bin/jimage (jimage) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jinfo to provide /usr/bin/jinfo (jinfo) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jlink to provide /usr/bin/jlink (jlink) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jmap to provide /usr/bin/jmap (jmap) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jmod to provide /usr/bin/jmod (jmod) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jps to provide /usr/bin/jps (jps) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jrunscript to provide /usr/bin/jrunscript (jrunscript) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jshell to provide /usr/bin/jshell (jshell) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstack to provide /usr/bin/jstack (jstack) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstat to provide /usr/bin/jstat (jstat) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstatd to provide /usr/bin/jstatd (jstatd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/serialver to provide /usr/bin/serialver (serialver) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jhsdb to provide /usr/bin/jhsdb (jhsdb) in auto mode\n",
      "Setting up openjdk-17-jdk:amd64 (17.0.5+8-2ubuntu1~20.04) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 82%]\u001b[49m\u001b[39m [###############################################...........] \u001b8update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 83%]\u001b[49m\u001b[39m [###############################################...........] \u001b8Processing triggers for ca-certificates (20211016~20.04.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 83%]\u001b[49m\u001b[39m [################################################..........] \u001b8Updating certificates in /etc/ssl/certs...\n",
      "0 added, 0 removed; done.\n",
      "Running hooks in /etc/ca-certificates/update.d...\n",
      "\n",
      "done.\n",
      "done.\n",
      "Processing triggers for sgml-base (1.29.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 84%]\u001b[49m\u001b[39m [################################################..........] \u001b8Setting up x11proto-dev (2019.2-1ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 85%]\u001b[49m\u001b[39m [#################################################.........] \u001b8Processing triggers for fontconfig (2.13.1-2ubuntu3) ...\n",
      "Processing triggers for mime-support (3.64ubuntu1) ...\n",
      "Setting up libxau-dev:amd64 (1:1.0.9-0ubuntu1) ...\n",
      "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 87%]\u001b[49m\u001b[39m [##################################################........] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 88%]\u001b[49m\u001b[39m [##################################################........] \u001b8Setting up libice-dev:amd64 (2:1.0.10-0ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 88%]\u001b[49m\u001b[39m [###################################################.......] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 89%]\u001b[49m\u001b[39m [###################################################.......] \u001b8Setting up libsm-dev:amd64 (2:1.2.3-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 90%]\u001b[49m\u001b[39m [####################################################......] \u001b8Processing triggers for libc-bin (2.31-0ubuntu9.7) ...\n",
      "Processing triggers for man-db (2.9.1-1) ...\n",
      "Setting up libxdmcp-dev:amd64 (1:1.1.3-0ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 92%]\u001b[49m\u001b[39m [#####################################################.....] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 93%]\u001b[49m\u001b[39m [#####################################################.....] \u001b8Setting up x11proto-core-dev (2019.2-1ubuntu1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 93%]\u001b[49m\u001b[39m [######################################################....] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 94%]\u001b[49m\u001b[39m [######################################################....] \u001b8Setting up libxcb1-dev:amd64 (1.14-2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 95%]\u001b[49m\u001b[39m [#######################################################...] \u001b8Setting up libx11-dev:amd64 (2:1.6.9-2ubuntu1.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 97%]\u001b[49m\u001b[39m [########################################################..] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 98%]\u001b[49m\u001b[39m [########################################################..] \u001b8Setting up libxt-dev:amd64 (1:1.1.5-1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 98%]\u001b[49m\u001b[39m [#########################################################.] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 99%]\u001b[49m\u001b[39m [#########################################################.] \u001b8\n",
      "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[Jspark-3.3.1-bin-hadoop3/\n",
      "spark-3.3.1-bin-hadoop3/LICENSE\n",
      "spark-3.3.1-bin-hadoop3/NOTICE\n",
      "spark-3.3.1-bin-hadoop3/R/\n",
      "spark-3.3.1-bin-hadoop3/R/lib/\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/DESCRIPTION\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/INDEX\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/Meta/\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/Meta/Rd.rds\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/Meta/features.rds\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/Meta/hsearch.rds\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/Meta/links.rds\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/Meta/nsInfo.rds\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/Meta/package.rds\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/Meta/vignette.rds\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/NAMESPACE\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/R/\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/R/SparkR\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/R/SparkR.rdb\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/R/SparkR.rdx\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/doc/\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/doc/index.html\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/doc/sparkr-vignettes.R\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/doc/sparkr-vignettes.Rmd\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/doc/sparkr-vignettes.html\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/help/\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/help/AnIndex\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/help/SparkR.rdb\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/help/SparkR.rdx\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/help/aliases.rds\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/help/paths.rds\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/html/\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/html/00Index.html\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/html/R.css\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/profile/\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/profile/general.R\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/profile/shell.R\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/tests/\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/tests/testthat/\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/tests/testthat/test_basic.R\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/worker/\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/worker/daemon.R\n",
      "spark-3.3.1-bin-hadoop3/R/lib/SparkR/worker/worker.R\n",
      "spark-3.3.1-bin-hadoop3/R/lib/sparkr.zip\n",
      "spark-3.3.1-bin-hadoop3/README.md\n",
      "spark-3.3.1-bin-hadoop3/RELEASE\n",
      "spark-3.3.1-bin-hadoop3/bin/\n",
      "spark-3.3.1-bin-hadoop3/bin/beeline\n",
      "spark-3.3.1-bin-hadoop3/bin/beeline.cmd\n",
      "spark-3.3.1-bin-hadoop3/bin/docker-image-tool.sh\n",
      "spark-3.3.1-bin-hadoop3/bin/find-spark-home\n",
      "spark-3.3.1-bin-hadoop3/bin/find-spark-home.cmd\n",
      "spark-3.3.1-bin-hadoop3/bin/load-spark-env.cmd\n",
      "spark-3.3.1-bin-hadoop3/bin/load-spark-env.sh\n",
      "spark-3.3.1-bin-hadoop3/bin/pyspark\n",
      "spark-3.3.1-bin-hadoop3/bin/pyspark.cmd\n",
      "spark-3.3.1-bin-hadoop3/bin/pyspark2.cmd\n",
      "spark-3.3.1-bin-hadoop3/bin/run-example\n",
      "spark-3.3.1-bin-hadoop3/bin/run-example.cmd\n",
      "spark-3.3.1-bin-hadoop3/bin/spark-class\n",
      "spark-3.3.1-bin-hadoop3/bin/spark-class.cmd\n",
      "spark-3.3.1-bin-hadoop3/bin/spark-class2.cmd\n",
      "spark-3.3.1-bin-hadoop3/bin/spark-shell\n",
      "spark-3.3.1-bin-hadoop3/bin/spark-shell.cmd\n",
      "spark-3.3.1-bin-hadoop3/bin/spark-shell2.cmd\n",
      "spark-3.3.1-bin-hadoop3/bin/spark-sql\n",
      "spark-3.3.1-bin-hadoop3/bin/spark-sql.cmd\n",
      "spark-3.3.1-bin-hadoop3/bin/spark-sql2.cmd\n",
      "spark-3.3.1-bin-hadoop3/bin/spark-submit\n",
      "spark-3.3.1-bin-hadoop3/bin/spark-submit.cmd\n",
      "spark-3.3.1-bin-hadoop3/bin/spark-submit2.cmd\n",
      "spark-3.3.1-bin-hadoop3/bin/sparkR\n",
      "spark-3.3.1-bin-hadoop3/bin/sparkR.cmd\n",
      "spark-3.3.1-bin-hadoop3/bin/sparkR2.cmd\n",
      "spark-3.3.1-bin-hadoop3/conf/\n",
      "spark-3.3.1-bin-hadoop3/conf/fairscheduler.xml.template\n",
      "spark-3.3.1-bin-hadoop3/conf/log4j2.properties.template\n",
      "spark-3.3.1-bin-hadoop3/conf/metrics.properties.template\n",
      "spark-3.3.1-bin-hadoop3/conf/spark-defaults.conf.template\n",
      "spark-3.3.1-bin-hadoop3/conf/spark-env.sh.template\n",
      "spark-3.3.1-bin-hadoop3/conf/workers.template\n",
      "spark-3.3.1-bin-hadoop3/data/\n",
      "spark-3.3.1-bin-hadoop3/data/graphx/\n",
      "spark-3.3.1-bin-hadoop3/data/graphx/followers.txt\n",
      "spark-3.3.1-bin-hadoop3/data/graphx/users.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/als/\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/als/sample_movielens_ratings.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/als/test.data\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/gmm_data.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/images/\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/images/license.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/kittens/\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/kittens/54893.jpg\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/kittens/DP153539.jpg\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/kittens/DP802813.jpg\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/kittens/not-image.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/license.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/multi-channel/\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/multi-channel/BGRA.png\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/multi-channel/chr30.4.184.jpg\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/images/origin/multi-channel/grayscale.jpg\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/kmeans_data.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/pagerank_data.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/pic_data.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/ridge-data/\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/ridge-data/lpsa.data\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/sample_binary_classification_data.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/sample_fpgrowth.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/sample_isotonic_regression_libsvm_data.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/sample_kmeans_data.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/sample_lda_data.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/sample_lda_libsvm_data.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/sample_libsvm_data.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/sample_linear_regression_data.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/sample_movielens_data.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/sample_multiclass_classification_data.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/sample_svm_data.txt\n",
      "spark-3.3.1-bin-hadoop3/data/mllib/streaming_kmeans_data_test.txt\n",
      "spark-3.3.1-bin-hadoop3/data/streaming/\n",
      "spark-3.3.1-bin-hadoop3/data/streaming/AFINN-111.txt\n",
      "spark-3.3.1-bin-hadoop3/examples/\n",
      "spark-3.3.1-bin-hadoop3/examples/jars/\n",
      "spark-3.3.1-bin-hadoop3/examples/jars/scopt_2.12-3.7.1.jar\n",
      "spark-3.3.1-bin-hadoop3/examples/jars/spark-examples_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/examples/src/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaTC.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFMClassifierExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFMRegressorExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaUnivariateFeatureSelectorExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVarianceThresholdSelectorExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedScalar.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/hive/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredComplexSessionization.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/als.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/avro_inputformat.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/kmeans.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/logistic_regression.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/__init__,py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/aft_survival_regression.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/als_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/binarizer_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/bisecting_k_means_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/bucketizer_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/chi_square_test_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/chisq_selector_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/correlation_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/count_vectorizer_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/cross_validator.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/dataframe_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/dct_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/decision_tree_classification_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/decision_tree_regression_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/elementwise_product_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/estimator_transformer_param_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/feature_hasher_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/fm_classifier_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/fm_regressor_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/fpgrowth_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/gaussian_mixture_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/generalized_linear_regression_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/imputer_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/index_to_string_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/interaction_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/isotonic_regression_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/kmeans_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/lda_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/linear_regression_with_elastic_net.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/linearsvc.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/logistic_regression_summary_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/logistic_regression_with_elastic_net.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/max_abs_scaler_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/min_hash_lsh_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/min_max_scaler_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/multilayer_perceptron_classification.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/n_gram_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/naive_bayes_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/normalizer_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/one_vs_rest_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/onehot_encoder_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/pca_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/pipeline_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/polynomial_expansion_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/power_iteration_clustering_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/prefixspan_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/quantile_discretizer_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/random_forest_classifier_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/random_forest_regressor_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/rformula_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/robust_scaler_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/sql_transformer.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/standard_scaler_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/stopwords_remover_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/string_indexer_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/summarizer_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/tf_idf_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/tokenizer_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/train_validation_split.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/univariate_feature_selector_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/variance_threshold_selector_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/vector_assembler_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/vector_indexer_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/vector_size_hint_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/vector_slicer_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/ml/word2vec_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/binary_classification_metrics_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/bisecting_k_means_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/correlations.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/correlations_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/decision_tree_classification_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/decision_tree_regression_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/elementwise_product_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/fpgrowth_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/gaussian_mixture_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/gaussian_mixture_model.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/gradient_boosting_classification_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/gradient_boosting_regression_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/hypothesis_testing_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/isotonic_regression_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/k_means_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/kernel_density_estimation_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/kmeans.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/linear_regression_with_sgd_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/logistic_regression.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/multi_class_metrics_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/multi_label_metrics_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/naive_bayes_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/normalizer_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/pca_rowmatrix_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/power_iteration_clustering_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/random_forest_classification_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/random_forest_regression_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/random_rdd_generation.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/ranking_metrics_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/recommendation_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/regression_metrics_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/sampled_rdds.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/standard_scaler_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/stratified_sampling_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/streaming_k_means_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/streaming_linear_regression_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/summary_statistics_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/svd_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/svm_with_sgd_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/tf_idf_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/word2vec.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/mllib/word2vec_example.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/pagerank.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/parquet_inputformat.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/pi.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/sort.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/arrow.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/basic.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/datasource.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/hive.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/streaming/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/streaming/__init__,py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/streaming/structured_network_wordcount.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/sql/streaming/structured_sessionization.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/status_api_demo.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/streaming/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/streaming/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/streaming/hdfs_wordcount.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/streaming/network_wordcount.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/streaming/network_wordjoinsentiments.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/streaming/queue_stream.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/streaming/recoverable_network_wordcount.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/streaming/sql_network_wordcount.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/streaming/stateful_network_wordcount.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/transitive_closure.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/python/wordcount.py\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/RSparkSQLExample.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/data-manipulation.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/dataframe.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/als.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/bisectingKmeans.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/decisionTree.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/fmClassifier.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/fmRegressor.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/fpm.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/gaussianMixture.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/gbt.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/glm.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/isoreg.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/kmeans.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/kstest.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/lda.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/lm_with_elastic_net.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/logit.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/ml.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/mlp.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/naiveBayes.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/powerIterationClustering.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/prefixSpan.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/randomForest.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/survreg.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/ml/svmLinear.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/streaming/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/r/streaming/structured_network_wordcount.R\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/META-INF/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/META-INF/services/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/META-INF/services/org.apache.spark.sql.SparkSessionExtensionsProvider\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/META-INF/services/org.apache.spark.sql.jdbc.JdbcConnectionProvider\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/dir1/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/dir1/dir2/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/dir1/dir2/file2.parquet\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/dir1/file1.parquet\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/dir1/file3.json\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/employees.json\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/full_user.avsc\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/kv1.txt\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/people.csv\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/people.json\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/people.txt\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/user.avsc\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/users.avro\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/users.orc\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/resources/users.parquet\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/MiniReadWriteTest.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/AgeExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithLoader.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithoutLoader.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/SparkSessionExtensionsTest.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FMClassifierExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FMRegressorExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/UnivariateFeatureSelectorExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VarianceThresholdSelectorExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/pythonconverters/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedScalar.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/hive/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/ExampleJdbcConnectionProvider.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredComplexSessionization.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scripts/\n",
      "spark-3.3.1-bin-hadoop3/examples/src/main/scripts/getGpusResources.sh\n",
      "spark-3.3.1-bin-hadoop3/jars/\n",
      "spark-3.3.1-bin-hadoop3/jars/HikariCP-2.5.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/JLargeArrays-1.5.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/JTransforms-3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/RoaringBitmap-0.9.25.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/ST4-4.0.4.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/activation-1.1.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/aircompressor-0.21.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/algebra_2.12-2.0.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/annotations-17.0.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/antlr-runtime-3.5.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/antlr4-runtime-4.8.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/aopalliance-repackaged-2.6.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/arpack-2.2.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/arpack_combined_all-0.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/arrow-format-7.0.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/arrow-memory-core-7.0.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/arrow-memory-netty-7.0.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/arrow-vector-7.0.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/audience-annotations-0.5.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/automaton-1.11-8.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/avro-1.11.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/avro-ipc-1.11.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/avro-mapred-1.11.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/blas-2.2.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/bonecp-0.8.0.RELEASE.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/breeze-macros_2.12-1.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/breeze_2.12-1.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/cats-kernel_2.12-2.1.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/chill-java-0.10.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/chill_2.12-0.10.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/commons-cli-1.5.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/commons-codec-1.15.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/commons-collections-3.2.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/commons-collections4-4.4.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/commons-compiler-3.0.16.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/commons-compress-1.21.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/commons-crypto-1.1.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/commons-dbcp-1.4.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/commons-io-2.11.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/commons-lang-2.6.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/commons-lang3-3.12.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/commons-logging-1.1.3.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/commons-math3-3.6.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/commons-pool-1.5.4.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/commons-text-1.9.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/compress-lzf-1.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/core-1.1.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/curator-client-2.13.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/curator-framework-2.13.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/curator-recipes-2.13.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/datanucleus-api-jdo-4.2.4.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/datanucleus-core-4.1.17.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/datanucleus-rdbms-4.1.19.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/derby-10.14.2.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/flatbuffers-java-1.12.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/generex-1.0.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/gson-2.2.4.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/guava-14.0.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hadoop-client-api-3.3.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hadoop-client-runtime-3.3.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hadoop-shaded-guava-1.1.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hadoop-yarn-server-web-proxy-3.3.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hive-beeline-2.3.9.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hive-cli-2.3.9.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hive-common-2.3.9.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hive-exec-2.3.9-core.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hive-jdbc-2.3.9.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hive-llap-common-2.3.9.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hive-metastore-2.3.9.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hive-serde-2.3.9.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hive-service-rpc-3.1.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hive-shims-0.23-2.3.9.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hive-shims-2.3.9.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hive-shims-common-2.3.9.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hive-shims-scheduler-2.3.9.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hive-storage-api-2.7.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hive-vector-code-gen-2.3.9.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hk2-api-2.6.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hk2-locator-2.6.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/hk2-utils-2.6.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/httpclient-4.5.13.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/httpcore-4.4.14.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/istack-commons-runtime-3.0.8.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/ivy-2.5.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jackson-annotations-2.13.4.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jackson-core-2.13.4.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jackson-core-asl-1.9.13.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jackson-databind-2.13.4.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jackson-dataformat-yaml-2.13.4.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jackson-datatype-jsr310-2.13.4.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jackson-mapper-asl-1.9.13.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jackson-module-scala_2.12-2.13.4.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jakarta.annotation-api-1.3.5.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jakarta.inject-2.6.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jakarta.servlet-api-4.0.3.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jakarta.validation-api-2.0.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jakarta.ws.rs-api-2.1.6.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jakarta.xml.bind-api-2.3.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/janino-3.0.16.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/javassist-3.25.0-GA.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/javax.jdo-3.2.0-m3.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/javolution-5.5.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jaxb-runtime-2.3.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jcl-over-slf4j-1.7.32.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jdo-api-3.0.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jersey-client-2.36.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jersey-common-2.36.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jersey-container-servlet-2.36.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jersey-container-servlet-core-2.36.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jersey-hk2-2.36.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jersey-server-2.36.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jline-2.14.6.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/joda-time-2.10.13.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jodd-core-3.5.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jpam-1.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/json-1.8.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/json4s-ast_2.12-3.7.0-M11.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/json4s-core_2.12-3.7.0-M11.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/json4s-jackson_2.12-3.7.0-M11.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/json4s-scalap_2.12-3.7.0-M11.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jsr305-3.0.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jta-1.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/jul-to-slf4j-1.7.32.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kryo-shaded-4.0.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-client-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-admissionregistration-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-apiextensions-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-apps-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-autoscaling-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-batch-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-certificates-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-common-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-coordination-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-core-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-discovery-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-events-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-extensions-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-flowcontrol-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-metrics-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-networking-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-node-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-policy-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-rbac-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-scheduling-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/kubernetes-model-storageclass-5.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/lapack-2.2.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/leveldbjni-all-1.8.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/libfb303-0.9.3.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/libthrift-0.12.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/log4j-1.2-api-2.17.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/log4j-api-2.17.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/log4j-core-2.17.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/log4j-slf4j-impl-2.17.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/logging-interceptor-3.12.12.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/lz4-java-1.8.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/mesos-1.4.3-shaded-protobuf.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/metrics-core-4.2.7.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/metrics-graphite-4.2.7.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/metrics-jmx-4.2.7.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/metrics-json-4.2.7.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/metrics-jvm-4.2.7.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/minlog-1.3.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/netty-all-4.1.74.Final.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/netty-buffer-4.1.74.Final.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/netty-codec-4.1.74.Final.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/netty-common-4.1.74.Final.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/netty-handler-4.1.74.Final.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/netty-resolver-4.1.74.Final.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/netty-tcnative-classes-2.0.48.Final.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/netty-transport-4.1.74.Final.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/netty-transport-classes-epoll-4.1.74.Final.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/netty-transport-classes-kqueue-4.1.74.Final.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/netty-transport-native-epoll-4.1.74.Final-linux-aarch_64.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/netty-transport-native-epoll-4.1.74.Final-linux-x86_64.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/netty-transport-native-kqueue-4.1.74.Final-osx-aarch_64.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/netty-transport-native-kqueue-4.1.74.Final-osx-x86_64.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/netty-transport-native-unix-common-4.1.74.Final.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/objenesis-3.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/okhttp-3.12.12.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/okio-1.14.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/opencsv-2.3.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/orc-core-1.7.6.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/orc-mapreduce-1.7.6.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/orc-shims-1.7.6.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/oro-2.0.8.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/osgi-resource-locator-1.0.3.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/paranamer-2.8.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/parquet-column-1.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/parquet-common-1.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/parquet-encoding-1.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/parquet-format-structures-1.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/parquet-hadoop-1.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/parquet-jackson-1.12.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/pickle-1.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/protobuf-java-2.5.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/py4j-0.10.9.5.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/rocksdbjni-6.20.3.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/scala-collection-compat_2.12-2.1.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/scala-compiler-2.12.15.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/scala-library-2.12.15.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/scala-parser-combinators_2.12-1.1.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/scala-reflect-2.12.15.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/scala-xml_2.12-1.2.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/shapeless_2.12-2.3.7.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/shims-0.9.25.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/slf4j-api-1.7.32.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/snakeyaml-1.31.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/snappy-java-1.1.8.4.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-catalyst_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-core_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-graphx_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-hive-thriftserver_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-hive_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-kubernetes_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-kvstore_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-launcher_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-mesos_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-mllib-local_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-mllib_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-network-common_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-network-shuffle_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-repl_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-sketch_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-sql_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-streaming_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-tags_2.12-3.3.1-tests.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-tags_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-unsafe_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spark-yarn_2.12-3.3.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spire-macros_2.12-0.17.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spire-platform_2.12-0.17.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spire-util_2.12-0.17.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/spire_2.12-0.17.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/stax-api-1.0.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/stream-2.9.6.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/super-csv-2.2.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/threeten-extra-1.5.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/tink-1.6.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/transaction-api-1.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/univocity-parsers-2.9.1.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/velocity-1.5.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/xbean-asm9-shaded-4.20.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/xz-1.8.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/zjsonpatch-0.3.0.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/zookeeper-3.6.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/zookeeper-jute-3.6.2.jar\n",
      "spark-3.3.1-bin-hadoop3/jars/zstd-jni-1.5.2-1.jar\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/Dockerfile\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/Dockerfile.java17\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/R/\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/R/Dockerfile\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/python/\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/python/Dockerfile\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/decom.sh\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/dockerfiles/spark/entrypoint.sh\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/tests/\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/tests/autoscale.py\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/tests/decommissioning.py\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/tests/decommissioning_cleanup.py\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/tests/py_container_checks.py\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/tests/pyfiles.py\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/tests/python_executable_check.py\n",
      "spark-3.3.1-bin-hadoop3/kubernetes/tests/worker_memory_check.py\n",
      "spark-3.3.1-bin-hadoop3/licenses/\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-AnchorJS.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-CC0.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-JLargeArrays.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-JTransforms.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-antlr.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-arpack.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-automaton.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-blas.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-bootstrap.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-cloudpickle.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-d3.min.js.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-dagre-d3.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-datatables.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-dnsjava.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-f2j.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-graphlib-dot.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-istack-commons-runtime.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-jakarta-annotation-api\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-jakarta-ws-rs-api\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-jakarta.activation-api.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-jakarta.xml.bind-api.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-janino.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-javassist.html\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-javax-transaction-transaction-api.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-javolution.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-jaxb-runtime.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-jline.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-jodd.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-join.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-jquery.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-json-formatter.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-jsp-api.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-kryo.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-leveldbjni.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-machinist.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-matchMedia-polyfill.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-minlog.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-modernizr.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-mustache.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-netlib.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-paranamer.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-pmml-model.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-protobuf.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-py4j.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-pyrolite.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-re2j.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-reflectasm.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-respond.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-sbt-launch-lib.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-scala.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-scopt.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-slf4j.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-sorttable.js.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-spire.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-vis-timeline.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-xmlenc.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-zstd-jni.txt\n",
      "spark-3.3.1-bin-hadoop3/licenses/LICENSE-zstd.txt\n",
      "spark-3.3.1-bin-hadoop3/python/\n",
      "spark-3.3.1-bin-hadoop3/python/.coveragerc\n",
      "spark-3.3.1-bin-hadoop3/python/.gitignore\n",
      "spark-3.3.1-bin-hadoop3/python/MANIFEST.in\n",
      "spark-3.3.1-bin-hadoop3/python/README.md\n",
      "spark-3.3.1-bin-hadoop3/python/dist/\n",
      "spark-3.3.1-bin-hadoop3/python/docs/\n",
      "spark-3.3.1-bin-hadoop3/python/docs/Makefile\n",
      "spark-3.3.1-bin-hadoop3/python/docs/make.bat\n",
      "spark-3.3.1-bin-hadoop3/python/docs/make2.bat\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/_static/\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/_static/copybutton.js\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/_static/css/\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/_static/css/pyspark.css\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/_templates/\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/_templates/autosummary/\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/_templates/autosummary/class.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/_templates/autosummary/class_with_docs.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/conf.py\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/development/\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/development/contributing.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/development/debugging.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/development/index.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/development/setting_ide.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/development/testing.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/getting_started/\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/getting_started/index.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/getting_started/install.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/getting_started/quickstart_df.ipynb\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/getting_started/quickstart_ps.ipynb\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/index.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/index.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/koalas_to_pyspark.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/pyspark_1.0_1.2_to_1.3.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/pyspark_1.4_to_1.5.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/pyspark_2.2_to_2.3.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/pyspark_2.3.0_to_2.3.1_above.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/pyspark_2.3_to_2.4.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/pyspark_2.4_to_3.0.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/pyspark_3.1_to_3.2.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/migration_guide/pyspark_3.2_to_3.3.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/index.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.ml.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.mllib.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/extensions.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/frame.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/general_functions.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/groupby.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/index.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/indexing.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/io.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/ml.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/series.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/window.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.resource.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/avro.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/catalog.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/column.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/configuration.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/core_classes.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/data_types.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/dataframe.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/functions.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/grouping.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/index.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/io.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/observation.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/row.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/spark_session.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/window.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/core_classes.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/index.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/io.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/query_management.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/reference/pyspark.streaming.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/arrow_pandas.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/index.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/best_practices.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/faq.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/from_to_dbms.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/index.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/options.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/pandas_pyspark.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/supported_pandas_api.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/transform_apply.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/typehints.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/types.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/python_packaging.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/sql/\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/sql/arrow_pandas.rst\n",
      "spark-3.3.1-bin-hadoop3/python/docs/source/user_guide/sql/index.rst\n",
      "spark-3.3.1-bin-hadoop3/python/lib/\n",
      "spark-3.3.1-bin-hadoop3/python/lib/PY4J_LICENSE.txt\n",
      "spark-3.3.1-bin-hadoop3/python/lib/py4j-0.10.9.5-src.zip\n",
      "spark-3.3.1-bin-hadoop3/python/lib/pyspark.zip\n",
      "spark-3.3.1-bin-hadoop3/python/mypy.ini\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/__pycache__/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/__pycache__/install.cpython-38.pyc\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/_globals.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/_typing.pyi\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/accumulators.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/broadcast.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/cloudpickle/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/cloudpickle/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/cloudpickle/cloudpickle.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/cloudpickle/cloudpickle_fast.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/cloudpickle/compat.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/conf.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/context.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/daemon.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/files.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/find_spark_home.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/install.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/instrumentation_utils.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/java_gateway.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/join.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/_typing.pyi\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/base.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/classification.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/clustering.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/common.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/evaluation.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/feature.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/fpm.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/functions.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/image.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/linalg/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/linalg/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/param/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/param/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/param/_shared_params_code_gen.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/param/shared.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/pipeline.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/recommendation.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/regression.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/stat.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_algorithms.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_base.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_evaluation.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_feature.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_image.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_linalg.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_param.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_persistence.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_pipeline.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_stat.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_training_summary.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_tuning.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_util.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/test_wrapper.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/typing/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_classification.yml\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_clustering.yaml\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_evaluation.yml\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_feature.yml\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_param.yml\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_readable.yml\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_regression.yml\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tree.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/tuning.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/util.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/ml/wrapper.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/_typing.pyi\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/classification.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/clustering.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/common.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/evaluation.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/feature.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/fpm.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/linalg/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/linalg/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/linalg/distributed.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/random.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/random.pyi\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/recommendation.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/recommendation.pyi\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/regression.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/stat/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/stat/KernelDensity.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/stat/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/stat/_statistics.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/stat/distribution.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/stat/test.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/tests/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/tests/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/tests/test_algorithms.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/tests/test_feature.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/tests/test_linalg.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/tests/test_stat.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/tests/test_streaming_algorithms.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/tests/test_util.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/tree.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/mllib/util.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/_typing.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/accessors.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/base.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/categorical.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/config.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/base.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/binary_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/boolean_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/categorical_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/complex_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/date_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/datetime_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/null_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/num_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/string_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/timedelta_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/udt_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/datetimes.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/exceptions.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/extensions.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/frame.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/generic.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/groupby.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/indexes/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/indexes/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/indexes/base.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/indexes/category.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/indexes/datetimes.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/indexes/multi.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/indexes/numeric.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/indexes/timedelta.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/indexing.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/internal.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/missing/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/missing/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/missing/common.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/missing/frame.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/missing/general_functions.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/missing/groupby.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/missing/indexes.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/missing/series.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/missing/window.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/ml.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/mlflow.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/namespace.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/numpy_compat.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/plot/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/plot/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/plot/core.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/plot/matplotlib.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/plot/plotly.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/series.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/spark/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/spark/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/spark/accessors.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/spark/functions.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/spark/utils.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/sql_formatter.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/sql_processor.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/strings.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_base.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_binary_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_boolean_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_categorical_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_complex_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_date_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_datetime_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_null_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_num_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_string_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_timedelta_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_udt_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/testing_utils.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_base.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_category.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_datetime.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_timedelta.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/plot/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/plot/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_frame_plot.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_frame_plot_matplotlib.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_frame_plot_plotly.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_series_plot.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_series_plot_matplotlib.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_series_plot_plotly.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_categorical.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_config.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_csv.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_dataframe.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_dataframe_conversion.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_dataframe_spark_io.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_default_index.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_expanding.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_extension.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_frame_spark.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_groupby.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_indexing.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_indexops_spark.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_internal.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_namespace.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_numpy_compat.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby_expanding.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby_rolling.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_repr.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_reshape.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_rolling.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_series.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_series_conversion.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_series_datetime.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_series_string.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_spark_functions.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_sql.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_stats.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_typedef.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_utils.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/tests/test_window.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/typedef/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/typedef/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/typedef/typehints.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/usage_logging/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/usage_logging/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/usage_logging/usage_logger.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/utils.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/pandas/window.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/profiler.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/py.typed\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/python/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/python/pyspark/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/python/pyspark/shell.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/rdd.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/rddsampler.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/resource/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/resource/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/resource/information.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/resource/profile.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/resource/requests.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/resource/tests/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/resource/tests/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/resource/tests/test_resources.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/resultiterable.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/serializers.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/shell.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/shuffle.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/_typing.pyi\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/avro/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/avro/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/avro/functions.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/catalog.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/column.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/conf.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/context.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/dataframe.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/functions.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/group.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/observation.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/__init__.pyi\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/__init__.pyi\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/frame.pyi\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/series.pyi\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/conversion.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/functions.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/functions.pyi\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/group_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/map_ops.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/serializers.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/typehints.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/types.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/pandas/utils.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/readwriter.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/session.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/sql_formatter.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/streaming.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_arrow.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_arrow_map.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_catalog.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_column.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_conf.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_context.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_dataframe.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_datasources.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_functions.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_group.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_cogrouped_map.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_grouped_map.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_map.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_udf.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_udf_grouped_agg.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_udf_scalar.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_udf_typehints.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_udf_typehints_with_future_annotations.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_udf_window.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_readwriter.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_serde.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_session.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_streaming.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_types.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_udf.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_udf_profiler.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/test_utils.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/typing/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_column.yml\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_dataframe.yml\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_functions.yml\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_readwriter.yml\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_session.yml\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_udf.yml\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/types.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/udf.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/utils.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/sql/window.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/statcounter.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/status.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/storagelevel.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/context.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/dstream.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/kinesis.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/listener.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/tests/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/tests/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/tests/test_context.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/tests/test_dstream.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/tests/test_kinesis.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/tests/test_listener.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/streaming/util.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/taskcontext.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/testing/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/testing/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/testing/mllibutils.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/testing/mlutils.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/testing/pandasutils.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/testing/sqlutils.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/testing/streamingutils.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/testing/utils.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/__init__.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_appsubmit.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_broadcast.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_conf.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_context.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_daemon.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_install_spark.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_join.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_pin_thread.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_profiler.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_rdd.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_rddbarrier.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_readwrite.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_serializers.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_shuffle.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_statcounter.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_taskcontext.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_util.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/test_worker.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/typing/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/typing/test_context.yml\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/typing/test_core.yml\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/typing/test_rdd.yml\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/tests/typing/test_resultiterable.yml\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/traceback_utils.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/util.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/version.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark/worker.py\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark.egg-info/\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark.egg-info/PKG-INFO\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark.egg-info/SOURCES.txt\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark.egg-info/dependency_links.txt\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark.egg-info/requires.txt\n",
      "spark-3.3.1-bin-hadoop3/python/pyspark.egg-info/top_level.txt\n",
      "spark-3.3.1-bin-hadoop3/python/run-tests\n",
      "spark-3.3.1-bin-hadoop3/python/run-tests-with-coverage\n",
      "spark-3.3.1-bin-hadoop3/python/run-tests.py\n",
      "spark-3.3.1-bin-hadoop3/python/setup.cfg\n",
      "spark-3.3.1-bin-hadoop3/python/setup.py\n",
      "spark-3.3.1-bin-hadoop3/python/test_coverage/\n",
      "spark-3.3.1-bin-hadoop3/python/test_coverage/conf/\n",
      "spark-3.3.1-bin-hadoop3/python/test_coverage/conf/spark-defaults.conf\n",
      "spark-3.3.1-bin-hadoop3/python/test_coverage/coverage_daemon.py\n",
      "spark-3.3.1-bin-hadoop3/python/test_coverage/sitecustomize.py\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/SimpleHTTPServer.py\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/hello/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/hello/hello.txt\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/hello/sub_hello/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/hello/sub_hello/sub_hello.txt\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/ages.csv\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/ages_newlines.csv\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/_SUCCESS\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/c=0/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/c=0/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/c=0/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/c=1/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/c=1/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/c=1/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/_SUCCESS\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/_common_metadata\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/_metadata\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2014/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2014/month=9/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/.part-r-00008.gz.parquet.crc\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/part-r-00008.gz.parquet\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=10/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00002.gz.parquet.crc\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00004.gz.parquet.crc\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00002.gz.parquet\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00004.gz.parquet\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/.part-r-00005.gz.parquet.crc\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/part-r-00005.gz.parquet\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=9/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/.part-r-00007.gz.parquet.crc\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/part-r-00007.gz.parquet\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/people.json\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/people1.json\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/people_array.json\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/people_array_utf16le.json\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/streaming/\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/streaming/text-test.txt\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/sql/text-test.txt\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/userlib-0.1.zip\n",
      "spark-3.3.1-bin-hadoop3/python/test_support/userlibrary.py\n",
      "spark-3.3.1-bin-hadoop3/sbin/\n",
      "spark-3.3.1-bin-hadoop3/sbin/decommission-slave.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/decommission-worker.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/slaves.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/spark-config.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/spark-daemon.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/spark-daemons.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/start-all.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/start-history-server.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/start-master.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/start-mesos-dispatcher.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/start-mesos-shuffle-service.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/start-slave.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/start-slaves.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/start-thriftserver.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/start-worker.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/start-workers.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/stop-all.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/stop-history-server.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/stop-master.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/stop-mesos-dispatcher.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/stop-mesos-shuffle-service.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/stop-slave.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/stop-slaves.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/stop-thriftserver.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/stop-worker.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/stop-workers.sh\n",
      "spark-3.3.1-bin-hadoop3/sbin/workers.sh\n",
      "spark-3.3.1-bin-hadoop3/yarn/\n",
      "spark-3.3.1-bin-hadoop3/yarn/spark-3.3.1-yarn-shuffle.jar\n",
      "Collecting pyspark\n",
      "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting missingno\n",
      "  Downloading missingno-0.5.1-py3-none-any.whl (8.7 kB)\n",
      "Collecting findspark\n",
      "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting plotly\n",
      "  Downloading plotly-5.11.0-py2.py3-none-any.whl (15.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting wandb\n",
      "  Downloading wandb-0.13.5-py2.py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m111.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting koalas\n",
      "  Downloading koalas-1.8.2-py3-none-any.whl (390 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.8/390.8 kB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting py4j==0.10.9.5\n",
      "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from missingno) (1.8.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from missingno) (3.5.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from missingno) (1.23.1)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.9/dist-packages (from missingno) (0.11.2)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.1.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (5.9.1)\n",
      "Collecting promise<3,>=2.0\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.1.27)\n",
      "Collecting shortuuid>=0.5.0\n",
      "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: six>=1.13.0 in /usr/lib/python3/dist-packages (from wandb) (1.14.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (8.1.3)\n",
      "Requirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.19.4)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.11.1-py2.py3-none-any.whl (168 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.0/169.0 kB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting setproctitle\n",
      "  Downloading setproctitle-1.3.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (2.28.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from wandb) (5.4.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb) (63.1.0)\n",
      "Requirement already satisfied: pandas>=0.23.2 in /usr/local/lib/python3.9/dist-packages (from koalas) (1.4.3)\n",
      "Requirement already satisfied: pyarrow>=0.10 in /usr/local/lib/python3.9/dist-packages (from koalas) (8.0.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.23.2->koalas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.23.2->koalas) (2.8.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.10)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->missingno) (3.0.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->missingno) (9.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->missingno) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->missingno) (1.4.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->missingno) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->missingno) (4.34.4)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "Building wheels for collected packages: pyspark, promise, pathtools\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845500 sha256=abd81b3e20db6dd47edbd8ee37f405cc5fb5119deb8ee7216aae98c5697150cb\n",
      "  Stored in directory: /root/.cache/pip/wheels/51/c8/18/298a4ced8ebb3ab8a7d26a7198c0cc7035abb906bde94a4c4b\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21486 sha256=8b9c58cad782a63989abed87de2e70b077955026d9f217fa331776c39d801bee\n",
      "  Stored in directory: /root/.cache/pip/wheels/e1/e8/83/ddea66100678d139b14bc87692ece57c6a2a937956d2532608\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=0c6c65310ad7bfaa5d181469bd1cbfde1cb57d8332d4643fa4e12103ecbdbad6\n",
      "  Stored in directory: /root/.cache/pip/wheels/b7/0a/67/ada2a22079218c75a88361c0782855cc72aebc4d18d0289d05\n",
      "Successfully built pyspark promise pathtools\n",
      "Installing collected packages: py4j, pathtools, findspark, urllib3, tenacity, shortuuid, setproctitle, pyspark, promise, docker-pycreds, sentry-sdk, plotly, wandb, koalas, missingno\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.10\n",
      "    Uninstalling urllib3-1.26.10:\n",
      "      Successfully uninstalled urllib3-1.26.10\n",
      "Successfully installed docker-pycreds-0.4.0 findspark-2.0.1 koalas-1.8.2 missingno-0.5.1 pathtools-0.1.2 plotly-5.11.0 promise-2.3 py4j-0.10.9.5 pyspark-3.3.1 sentry-sdk-1.11.1 setproctitle-1.3.2 shortuuid-1.0.11 tenacity-8.1.0 urllib3-1.26.13 wandb-0.13.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#### INSTALLATION OF LIBRARIES\n",
    "!sudo apt update\n",
    "!sudo apt install openjdk-17-jdk -y\n",
    "#!curl -JLO 'https://apache.osuosl.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz'\n",
    "!tar xvf spark-3.3.1-bin-hadoop3.tgz\n",
    "!mv spark-3.3.1-bin-hadoop3 /opt/spark\n",
    "!pip install pyspark missingno findspark plotly wandb koalas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
      "WARNING:root:Found pyspark version \"3.3.1\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/30 12:03:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "#### LIBRARIES\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/opt/spark\"\n",
    "#### BASIC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#### SPARK\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.pandas as ps\n",
    "import databricks.koalas as ks\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "\n",
    "#### SETTINGS\n",
    "%matplotlib inline\n",
    "spark.sparkContext.setLogLevel(\"OFF\")\n",
    "ps.options.plotting.backend = 'matplotlib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "checkin = ks.read_json('./data/checkin.json', lines=True)\n",
    "review = ks.read_json('./data/review.json', lines=True)\n",
    "business = ks.read_json('./data/business.json', lines=True)\n",
    "tip = ks.read_json('./data/tip.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The key popular_brands_ids in the SQL statement was not found in global, local or parameters variables",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/maico/Desktop/Proyectos/trabajofinal/ML/TIME SERIES/ML_TS_1.ipynb Celda 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/maico/Desktop/Proyectos/trabajofinal/ML/TIME%20SERIES/ML_TS_1.ipynb#X51sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ks\u001b[39m.\u001b[39;49msql(\u001b[39m'''\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maico/Desktop/Proyectos/trabajofinal/ML/TIME%20SERIES/ML_TS_1.ipynb#X51sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m    select count(distinct(business_id)) as business_count\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maico/Desktop/Proyectos/trabajofinal/ML/TIME%20SERIES/ML_TS_1.ipynb#X51sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m    from \u001b[39;49m\u001b[39m{review}\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maico/Desktop/Proyectos/trabajofinal/ML/TIME%20SERIES/ML_TS_1.ipynb#X51sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m    where business_id in (select business_id from \u001b[39;49m\u001b[39m{popular_brands_ids}\u001b[39;49;00m\u001b[39m)\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maico/Desktop/Proyectos/trabajofinal/ML/TIME%20SERIES/ML_TS_1.ipynb#X51sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m'''\u001b[39;49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/databricks/koalas/sql.py:147\u001b[0m, in \u001b[0;36msql\u001b[0;34m(query, globals, locals, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39m# Highest order of precedence is the locals\u001b[39;00m\n\u001b[1;32m    146\u001b[0m _dict\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[0;32m--> 147\u001b[0m \u001b[39mreturn\u001b[39;00m SQLProcessor(_dict, query, default_session())\u001b[39m.\u001b[39;49mexecute()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/databricks/koalas/sql.py:248\u001b[0m, in \u001b[0;36mSQLProcessor.execute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    247\u001b[0m     \u001b[39mfor\u001b[39;00m (pre, inner, _, _) \u001b[39min\u001b[39;00m blocks:\n\u001b[0;32m--> 248\u001b[0m         var_next \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m inner \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert(inner)\n\u001b[1;32m    249\u001b[0m         res \u001b[39m=\u001b[39m res \u001b[39m+\u001b[39m pre \u001b[39m+\u001b[39m var_next\n\u001b[1;32m    250\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_normalized_statement \u001b[39m=\u001b[39m res\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/databricks/koalas/sql.py:269\u001b[0m, in \u001b[0;36mSQLProcessor._convert\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[39m# Analyze:\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_scope:\n\u001b[0;32m--> 269\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    270\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe key \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m in the SQL statement was not found in global,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    271\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m local or parameters variables\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(key)\n\u001b[1;32m    272\u001b[0m     )\n\u001b[1;32m    273\u001b[0m var \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_scope[key]\n\u001b[1;32m    274\u001b[0m fillin \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_var(var)\n",
      "\u001b[0;31mValueError\u001b[0m: The key popular_brands_ids in the SQL statement was not found in global, local or parameters variables"
     ]
    }
   ],
   "source": [
    "ks.sql('''\n",
    "    select count(distinct(business_id)) as business_count\n",
    "    from {review}\n",
    "    where business_id in (select business_id from {popular_brands_ids})\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>attributes</th>\n",
       "      <th>business_id</th>\n",
       "      <th>categories</th>\n",
       "      <th>city</th>\n",
       "      <th>hours</th>\n",
       "      <th>is_open</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>name</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>review_count</th>\n",
       "      <th>stars</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1616 Chapala St, Ste 2</td>\n",
       "      <td>(None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>Pns2l4eNsfO8kk83dixA6A</td>\n",
       "      <td>Doctors, Traditional Chinese Medicine, Naturop...</td>\n",
       "      <td>Santa Barbara</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>34.426679</td>\n",
       "      <td>-119.711197</td>\n",
       "      <td>Abby Rappoport, LAC, CMQ</td>\n",
       "      <td>93101</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87 Grasso Plaza Shopping Center</td>\n",
       "      <td>(None, None, None, None, None, None, None, Non...</td>\n",
       "      <td>mpf3x-BjTdTEA3yCZrAYPw</td>\n",
       "      <td>Shipping Centers, Local Services, Notaries, Ma...</td>\n",
       "      <td>Affton</td>\n",
       "      <td>(8:0-18:30, 0:0-0:0, 8:0-14:0, None, 8:0-18:30...</td>\n",
       "      <td>1</td>\n",
       "      <td>38.551126</td>\n",
       "      <td>-90.335695</td>\n",
       "      <td>The UPS Store</td>\n",
       "      <td>63123</td>\n",
       "      <td>15</td>\n",
       "      <td>3.0</td>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5255 E Broadway Blvd</td>\n",
       "      <td>(None, None, None, None, None, None, None, Tru...</td>\n",
       "      <td>tUFrWirKiKi_TAnsVWINQQ</td>\n",
       "      <td>Department Stores, Shopping, Fashion, Home &amp; G...</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>(8:0-23:0, 8:0-22:0, 8:0-23:0, 8:0-22:0, 8:0-2...</td>\n",
       "      <td>0</td>\n",
       "      <td>32.223236</td>\n",
       "      <td>-110.880452</td>\n",
       "      <td>Target</td>\n",
       "      <td>85711</td>\n",
       "      <td>22</td>\n",
       "      <td>3.5</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>935 Race St</td>\n",
       "      <td>(None, None, u'none', None, None, None, None, ...</td>\n",
       "      <td>MTSW4McQd7CbVtyjqoe9mw</td>\n",
       "      <td>Restaurants, Food, Bubble Tea, Coffee &amp; Tea, B...</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>(7:0-21:0, 7:0-20:0, 7:0-21:0, 7:0-21:0, 7:0-2...</td>\n",
       "      <td>1</td>\n",
       "      <td>39.955505</td>\n",
       "      <td>-75.155564</td>\n",
       "      <td>St Honore Pastries</td>\n",
       "      <td>19107</td>\n",
       "      <td>80</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101 Walnut St</td>\n",
       "      <td>(None, None, None, None, None, None, None, Tru...</td>\n",
       "      <td>mWMc6_wTdE0EUBKIGXDVfA</td>\n",
       "      <td>Brewpubs, Breweries, Food</td>\n",
       "      <td>Green Lane</td>\n",
       "      <td>(12:0-22:0, None, 12:0-22:0, 12:0-18:0, 16:0-2...</td>\n",
       "      <td>1</td>\n",
       "      <td>40.338183</td>\n",
       "      <td>-75.471659</td>\n",
       "      <td>Perkiomen Valley Brewery</td>\n",
       "      <td>18054</td>\n",
       "      <td>13</td>\n",
       "      <td>4.5</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           address                                                                                                                                                                                                                                                                                                                         attributes             business_id                                                                                                  categories           city                                                                   hours  is_open   latitude   longitude                      name postal_code  review_count  stars state\n",
       "0           1616 Chapala St, Ste 2                                                                                         (None, None, None, None, None, None, None, None, None, None, None, True, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None)  Pns2l4eNsfO8kk83dixA6A  Doctors, Traditional Chinese Medicine, Naturopathic/Holistic, Acupuncture, Health & Medical, Nutritionists  Santa Barbara                                                                    None        0  34.426679 -119.711197  Abby Rappoport, LAC, CMQ       93101             7    5.0    CA\n",
       "1  87 Grasso Plaza Shopping Center                                                                                         (None, None, None, None, None, None, None, None, None, True, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None)  mpf3x-BjTdTEA3yCZrAYPw                              Shipping Centers, Local Services, Notaries, Mailbox Centers, Printing Services         Affton   (8:0-18:30, 0:0-0:0, 8:0-14:0, None, 8:0-18:30, 8:0-18:30, 8:0-18:30)        1  38.551126  -90.335695             The UPS Store       63123            15    3.0    MO\n",
       "2             5255 E Broadway Blvd  (None, None, None, None, None, None, None, True, None, True, {'garage': False, 'street': False, 'validated': False, 'lot': True, 'valet': False}, False, False, False, None, None, False, None, None, None, None, None, False, False, None, None, None, False, None, None, False, None, 2, False, None, False, None, True, u'no')  tUFrWirKiKi_TAnsVWINQQ                          Department Stores, Shopping, Fashion, Home & Garden, Electronics, Furniture Stores         Tucson  (8:0-23:0, 8:0-22:0, 8:0-23:0, 8:0-22:0, 8:0-22:0, 8:0-22:0, 8:0-22:0)        0  32.223236 -110.880452                    Target       85711            22    3.5    AZ\n",
       "3                      935 Race St   (None, None, u'none', None, None, None, None, True, None, False, {'garage': False, 'street': True, 'validated': False, 'lot': False, 'valet': False}, False, True, None, None, None, None, None, None, None, None, None, None, None, None, None, None, False, None, None, False, None, 1, None, None, True, None, None, u'free')  MTSW4McQd7CbVtyjqoe9mw                                                       Restaurants, Food, Bubble Tea, Coffee & Tea, Bakeries   Philadelphia  (7:0-21:0, 7:0-20:0, 7:0-21:0, 7:0-21:0, 7:0-20:0, 7:0-20:0, 7:0-20:0)        1  39.955505  -75.155564        St Honore Pastries       19107            80    4.0    PA\n",
       "4                    101 Walnut St            (None, None, None, None, None, None, None, True, None, True, {'garage': None, 'street': None, 'validated': None, 'lot': True, 'valet': False}, None, False, None, None, None, None, None, None, True, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, True, None, True, None)  mWMc6_wTdE0EUBKIGXDVfA                                                                                   Brewpubs, Breweries, Food     Green Lane     (12:0-22:0, None, 12:0-22:0, 12:0-18:0, 16:0-22:0, None, 14:0-22:0)        1  40.338183  -75.471659  Perkiomen Valley Brewery       18054            13    4.5    PA"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_brands_names = ks.sql(\"select count(*), name from {business} group by name order by 1 desc limit 20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_brands_ids = ks.sql('''\n",
    "select business_id\n",
    "from {business}\n",
    "where name in (select name from {popular_brands_names})\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_popular = ks.sql('''\n",
    "select *\n",
    "from {checkin}\n",
    "where business_id in (select business_id from {popular_brands_ids})\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tip_popular = ks.sql('''\n",
    "select business_id, date\n",
    "from {tip}\n",
    "where business_id in (select business_id from {popular_brands_ids})\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_popular = ks.sql('''\n",
    "select business_id, date\n",
    "from {review}\n",
    "where business_id in (select business_id from {popular_brands_ids})\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(133399, 2)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_popular.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'databricks.koalas.frame.DataFrame'>\n",
      "Int64Index: 6492 entries, 0 to 6491\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   business_id  6492 non-null   object\n",
      " 1   date         6492 non-null   object\n",
      "dtypes: object(2)"
     ]
    }
   ],
   "source": [
    "checkin_popular.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_popular_spark = checkin_popular.to_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|          date_array|         business_id|\n",
      "+--------------------+--------------------+\n",
      "|[2011-07-29 16:37...|--lqIzK-ZVTtgwiQM...|\n",
      "|[2011-06-06 00:37...|-1zRvh3yjKAa2eYgg...|\n",
      "|[2010-10-25 05:37...|-2BDt9OdGiBONysWC...|\n",
      "|[2012-06-02 21:05...|-2CPhK6ik9ZBgFX_F...|\n",
      "|[2011-09-23 18:00...|-2mctVTqFR5-DDCXK...|\n",
      "|[2016-08-17 19:46...|-3725FZiIIYdwQtM4...|\n",
      "|[2011-03-26 01:57...|-3Xl8nSBSjaPpftsS...|\n",
      "|[2011-05-09 12:13...|-3dkEoYgH8AlUtBMZ...|\n",
      "|[2012-01-05 05:16...|-6E_cla4lotruNasI...|\n",
      "|[2010-06-14 03:35...|-6MEKOmFu6jckT3pr...|\n",
      "|[2010-02-13 16:06...|-6kIZWnXPuDC6JiQJ...|\n",
      "|[2010-03-27 16:44...|-6xYpkvG91ClVz31J...|\n",
      "|[2010-07-27 20:24...|-7Rx5jVeQmlVoAU_o...|\n",
      "|[2010-11-11 17:57...|-7UDKbg_8TL4LVuYR...|\n",
      "|[2011-10-24 15:18...|-7_Wl2UGiuA7I5Lh0...|\n",
      "|[2010-09-05 16:47...|-85kJMtb9wqNWDT8y...|\n",
      "|[2010-07-22 17:48...|-8wGpH3gYkwHKLcpc...|\n",
      "|[2012-05-30 15:36...|-99CauTgdResVER5N...|\n",
      "|[2010-08-31 00:40...|-9yzQQ0d_rcOD2Czd...|\n",
      "|[2010-07-23 22:51...|-A-5spZpPMjujSnG-...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split, col\n",
    "checkin_popular_spark_2 = checkin_popular_spark.select(split(col(\"date\"),\",\").alias(\"date_array\"),col(\"business_id\"))\n",
    "checkin_popular_spark_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- col: string (nullable = false)\n",
      "\n",
      "+--------------------+--------------------+\n",
      "|         business_id|                 col|\n",
      "+--------------------+--------------------+\n",
      "|--lqIzK-ZVTtgwiQM...| 2011-07-29 16:37:02|\n",
      "|--lqIzK-ZVTtgwiQM...| 2011-10-24 16:00:29|\n",
      "|--lqIzK-ZVTtgwiQM...| 2012-10-27 19:17:50|\n",
      "|--lqIzK-ZVTtgwiQM...| 2013-05-13 22:03:28|\n",
      "|--lqIzK-ZVTtgwiQM...| 2013-05-14 21:25:02|\n",
      "|--lqIzK-ZVTtgwiQM...| 2013-05-28 22:18:02|\n",
      "|--lqIzK-ZVTtgwiQM...| 2014-12-08 17:31:29|\n",
      "|--lqIzK-ZVTtgwiQM...| 2015-03-02 18:41:47|\n",
      "|--lqIzK-ZVTtgwiQM...| 2016-01-15 17:49:03|\n",
      "|--lqIzK-ZVTtgwiQM...| 2016-03-06 16:55:09|\n",
      "|--lqIzK-ZVTtgwiQM...| 2016-07-06 20:40:56|\n",
      "|--lqIzK-ZVTtgwiQM...| 2017-03-09 02:16:11|\n",
      "|--lqIzK-ZVTtgwiQM...| 2017-04-25 22:19:12|\n",
      "|--lqIzK-ZVTtgwiQM...| 2017-09-25 15:09:54|\n",
      "|--lqIzK-ZVTtgwiQM...| 2019-01-07 17:39:16|\n",
      "|--lqIzK-ZVTtgwiQM...| 2019-05-30 22:26:48|\n",
      "|--lqIzK-ZVTtgwiQM...| 2019-07-22 16:12:14|\n",
      "|--lqIzK-ZVTtgwiQM...| 2019-09-07 21:19:06|\n",
      "|--lqIzK-ZVTtgwiQM...| 2020-04-30 00:04:47|\n",
      "|--lqIzK-ZVTtgwiQM...| 2020-07-13 14:22:12|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "# using select function applying\n",
    "# explode on array column\n",
    "checkin_popular_spark_3 = checkin_popular_spark_2.select(checkin_popular_spark_2.business_id,explode(checkin_popular_spark_2.date_array))\n",
    " \n",
    "# printing the schema of the df2\n",
    "checkin_popular_spark_3.printSchema()\n",
    " \n",
    "# show df2\n",
    "checkin_popular_spark_3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_popular_normalized = checkin_popular_spark_3.to_koalas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--lqIzK-ZVTtgwiQM63XgQ</td>\n",
       "      <td>2011-07-29 16:37:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                  col\n",
       "0  --lqIzK-ZVTtgwiQM63XgQ  2011-07-29 16:37:02"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_popular_normalized.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/spark/python/pyspark/sql/pandas/functions.py:394: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  warnings.warn(\n",
      "WARNING:root:Found pyspark version \"3.3.1\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--lqIzK-ZVTtgwiQM63XgQ</td>\n",
       "      <td>2011-07-29 16:37:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                date\n",
       "0  --lqIzK-ZVTtgwiQM63XgQ 2011-07-29 16:37:02"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_popular_normalized['date'] = ks.to_datetime(checkin_popular_normalized['col'], format='%Y-%m-%d %H:%M:%S')\n",
    "checkin_popular_normalized = checkin_popular_normalized.drop('col', axis=1)\n",
    "checkin_popular_normalized.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/spark/python/pyspark/sql/pandas/functions.py:394: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "review_popular['date'] = ks.to_datetime(review_popular['date'], format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/spark/python/pyspark/sql/pandas/functions.py:394: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tip_popular['date'] = ks.to_datetime(tip_popular['date'], format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Found pyspark version \"3.3.1\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "checkin_p = checkin_popular_normalized.to_pandas()\n",
    "review_p = review_popular.to_pandas()\n",
    "tip_p = tip_popular.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_p.to_csv('./data/checkin_timeseries.csv', index=False)\n",
    "review_p.to_csv('./data/review_timeseries.csv', index=False)\n",
    "tip_p.to_csv('./data/tip_timeseries.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "checkin_p = pd.read_csv('../data/checkin_timeseries.csv', parse_dates=['date'])\n",
    "review_p = pd.read_csv('../data/review_timeseries.csv', parse_dates=['date'])\n",
    "tip_p = pd.read_csv('../data/tip_timeseries.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>month</th>\n",
       "      <th>business_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1/2010</td>\n",
       "      <td>29ThPh6IA69V-SfcwfV9Dg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1/2010</td>\n",
       "      <td>2Kqq7D6oj4FNF_9JmVjQJw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1/2010</td>\n",
       "      <td>2kt2oK-zgshowfiV3ZQl0Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1/2010</td>\n",
       "      <td>48hwr-F1xEFfHdTD1ueE2A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1/2010</td>\n",
       "      <td>6EskDOVYwOFPYHYt7SY-DQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count   month             business_id\n",
       "0      1  1/2010  29ThPh6IA69V-SfcwfV9Dg\n",
       "1      1  1/2010  2Kqq7D6oj4FNF_9JmVjQJw\n",
       "2      1  1/2010  2kt2oK-zgshowfiV3ZQl0Q\n",
       "3      2  1/2010  48hwr-F1xEFfHdTD1ueE2A\n",
       "4      2  1/2010  6EskDOVYwOFPYHYt7SY-DQ"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_p['m_y'] = checkin_p['date'].apply(lambda x: \"%d/%d\" % (x.month, x.year))\n",
    "checkin_p = pd.DataFrame(checkin_p.groupby(['m_y', 'business_id']).size())\n",
    "checkin_p['data'] = checkin_p.index\n",
    "checkin_p['month'] = checkin_p['data'].apply(lambda x: x[0])\n",
    "checkin_p['business_id'] = checkin_p['data'].apply(lambda x: x[1])\n",
    "checkin_p = checkin_p.drop('data', axis=1)\n",
    "checkin_p = checkin_p.reset_index(drop=True)\n",
    "checkin_p = checkin_p.rename(columns={0: 'count'})\n",
    "checkin_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>month</th>\n",
       "      <th>business_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1/2006</td>\n",
       "      <td>3yyRANNTMIyS2jgGHeEzxA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1/2006</td>\n",
       "      <td>K2G-FsUMEV1gqWsLWsKzGQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1/2006</td>\n",
       "      <td>aT0FhdLMRjUkJjjANFz7ZA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1/2007</td>\n",
       "      <td>1sZKO790Q6C4aV9PKmtWeA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1/2007</td>\n",
       "      <td>JyYT5phFLg3BESNL-WXf4Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count   month             business_id\n",
       "0      1  1/2006  3yyRANNTMIyS2jgGHeEzxA\n",
       "1      1  1/2006  K2G-FsUMEV1gqWsLWsKzGQ\n",
       "2      1  1/2006  aT0FhdLMRjUkJjjANFz7ZA\n",
       "3      1  1/2007  1sZKO790Q6C4aV9PKmtWeA\n",
       "4      1  1/2007  JyYT5phFLg3BESNL-WXf4Q"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_p['m_y'] = review_p['date'].apply(lambda x: \"%d/%d\" % (x.month, x.year))\n",
    "review_p = pd.DataFrame(review_p.groupby(['m_y', 'business_id']).size())\n",
    "review_p['data'] = review_p.index\n",
    "review_p['month'] = review_p['data'].apply(lambda x: x[0])\n",
    "review_p['business_id'] = review_p['data'].apply(lambda x: x[1])\n",
    "review_p = review_p.drop('data', axis=1)\n",
    "review_p = review_p.reset_index(drop=True)\n",
    "review_p = review_p.rename(columns={0: 'count'})\n",
    "review_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>month</th>\n",
       "      <th>business_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1/2010</td>\n",
       "      <td>2zSQu6_cLgWAVbZ2LbSLBA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1/2010</td>\n",
       "      <td>4bM_dsAYj4AxYL9NjVrp7A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1/2010</td>\n",
       "      <td>6EskDOVYwOFPYHYt7SY-DQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1/2010</td>\n",
       "      <td>OPhWuFj83RDS9O1qU21X8Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1/2010</td>\n",
       "      <td>WRh6AOkXFl1qtnlCYUUQ6Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count   month             business_id\n",
       "0      1  1/2010  2zSQu6_cLgWAVbZ2LbSLBA\n",
       "1      1  1/2010  4bM_dsAYj4AxYL9NjVrp7A\n",
       "2      1  1/2010  6EskDOVYwOFPYHYt7SY-DQ\n",
       "3      2  1/2010  OPhWuFj83RDS9O1qU21X8Q\n",
       "4      1  1/2010  WRh6AOkXFl1qtnlCYUUQ6Q"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tip_p['m_y'] = tip_p['date'].apply(lambda x: \"%d/%d\" % (x.month, x.year))\n",
    "tip_p = pd.DataFrame(tip_p.groupby(['m_y', 'business_id']).size())\n",
    "tip_p['data'] = tip_p.index\n",
    "tip_p['month'] = tip_p['data'].apply(lambda x: x[0])\n",
    "tip_p['business_id'] = tip_p['data'].apply(lambda x: x[1])\n",
    "tip_p = tip_p.drop('data', axis=1)\n",
    "tip_p = tip_p.reset_index(drop=True)\n",
    "tip_p = tip_p.rename(columns={0: 'count'})\n",
    "tip_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192996, 3)\n",
      "(110083, 3)\n",
      "(21724, 3)\n"
     ]
    }
   ],
   "source": [
    "print(checkin_p.shape)\n",
    "print(review_p.shape)\n",
    "print(tip_p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>business_id</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/2010</td>\n",
       "      <td>29ThPh6IA69V-SfcwfV9Dg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/2010</td>\n",
       "      <td>2Kqq7D6oj4FNF_9JmVjQJw</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/2010</td>\n",
       "      <td>2kt2oK-zgshowfiV3ZQl0Q</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/2010</td>\n",
       "      <td>48hwr-F1xEFfHdTD1ueE2A</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/2010</td>\n",
       "      <td>6EskDOVYwOFPYHYt7SY-DQ</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    month             business_id  total\n",
       "0  1/2010  29ThPh6IA69V-SfcwfV9Dg    1.0\n",
       "1  1/2010  2Kqq7D6oj4FNF_9JmVjQJw    1.0\n",
       "2  1/2010  2kt2oK-zgshowfiV3ZQl0Q    1.0\n",
       "3  1/2010  48hwr-F1xEFfHdTD1ueE2A    2.0\n",
       "4  1/2010  6EskDOVYwOFPYHYt7SY-DQ    3.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_count = pd.merge(checkin_p, review_p, on=['month', 'business_id'], how='outer')\n",
    "full_count = pd.merge(full_count, tip_p, on=['month', 'business_id'], how='outer')\n",
    "full_count = full_count.fillna(0)\n",
    "full_count['total'] = full_count['count_x'] + full_count['count_y'] + full_count['count']\n",
    "full_count = full_count.drop(['count_x', 'count_y', 'count'], axis=1)\n",
    "full_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_count.to_csv('./data/full_count.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_count_k = ks.from_pandas(full_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_brands_ids_and_names = ks.sql('''\n",
    "select business_id, name\n",
    "from {business}\n",
    "where name in (select name from {popular_brands_names})\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table = ks.sql('''\n",
    "select month, name, sum(total) as total\n",
    "from {full_count_k}\n",
    "join {popular_brands_ids_and_names} on {full_count_k}.business_id = {popular_brands_ids_and_names}.business_id\n",
    "group by month, name\n",
    "order by name, month\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table_pandas = final_table.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table_pandas.to_csv('./data/final_table_for_forecasting.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table_pandas['month'] = pd.to_datetime(final_table_pandas['month'], format='%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table_pandas.set_index('month', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>name</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>Burger King</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>Burger King</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>Burger King</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>Burger King</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>Burger King</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3359</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>Wendy's</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3360</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>Wendy's</td>\n",
       "      <td>149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3361</th>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>Wendy's</td>\n",
       "      <td>171.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3362</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>Wendy's</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3363</th>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>Wendy's</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3364 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          month         name  total\n",
       "0    2009-01-01  Burger King    2.0\n",
       "1    2010-01-01  Burger King    7.0\n",
       "2    2011-01-01  Burger King   33.0\n",
       "3    2012-01-01  Burger King   79.0\n",
       "4    2013-01-01  Burger King  130.0\n",
       "...         ...          ...    ...\n",
       "3359 2017-09-01      Wendy's  130.0\n",
       "3360 2018-09-01      Wendy's  149.0\n",
       "3361 2019-09-01      Wendy's  171.0\n",
       "3362 2020-09-01      Wendy's  134.0\n",
       "3363 2021-09-01      Wendy's  128.0\n",
       "\n",
       "[3364 rows x 3 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_table_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Starbucks</th>\n",
       "      <td>229914.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>McDonald's</th>\n",
       "      <td>59882.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wawa</th>\n",
       "      <td>48561.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dunkin'</th>\n",
       "      <td>46448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chick-fil-A</th>\n",
       "      <td>41966.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Walgreens</th>\n",
       "      <td>34151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CVS Pharmacy</th>\n",
       "      <td>28599.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taco Bell</th>\n",
       "      <td>25736.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wendy's</th>\n",
       "      <td>18853.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subway</th>\n",
       "      <td>17603.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jimmy John's</th>\n",
       "      <td>16442.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Burger King</th>\n",
       "      <td>15763.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US Post Office</th>\n",
       "      <td>15654.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The UPS Store</th>\n",
       "      <td>10961.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Domino's Pizza</th>\n",
       "      <td>10734.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Enterprise Rent-A-Car</th>\n",
       "      <td>9162.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pizza Hut</th>\n",
       "      <td>9042.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KFC</th>\n",
       "      <td>6656.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Papa John's Pizza</th>\n",
       "      <td>6121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Great Clips</th>\n",
       "      <td>5909.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          total\n",
       "name                           \n",
       "Starbucks              229914.0\n",
       "McDonald's              59882.0\n",
       "Wawa                    48561.0\n",
       "Dunkin'                 46448.0\n",
       "Chick-fil-A             41966.0\n",
       "Walgreens               34151.0\n",
       "CVS Pharmacy            28599.0\n",
       "Taco Bell               25736.0\n",
       "Wendy's                 18853.0\n",
       "Subway                  17603.0\n",
       "Jimmy John's            16442.0\n",
       "Burger King             15763.0\n",
       "US Post Office          15654.0\n",
       "The UPS Store           10961.0\n",
       "Domino's Pizza          10734.0\n",
       "Enterprise Rent-A-Car    9162.0\n",
       "Pizza Hut                9042.0\n",
       "KFC                      6656.0\n",
       "Papa John's Pizza        6121.0\n",
       "Great Clips              5909.0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_table_pandas.groupby('name').agg({'total': 'sum'}).sort_values(by='total', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_final_table = final_table_pandas.pivot_table(index='month', columns='name', values='total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_final_table.to_csv('./data/forecasting.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "final_table_pandas['2010-01-01':].plot(title = 'Total Review/Tips/Checkins Counts on Yelp for Top Brands')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3cea5bbf73bc3b494db0a8d4c59c841f216f2a2b25ad88b6d6d29f1c6d275726"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
